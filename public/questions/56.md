# Q56 Design Web Analytics Tool (Google Analytics)

> 来源校验（questions.ts）  
> `title`: Design Web Analytics Tool (Google Analytics)  
> `tags`: 数据采集, 实时分析, 报表, 用户行为, 漏斗分析  
> `keyPoints`: 数据采集SDK, 实时数据处理, 数据仓库, 报表生成, 漏斗分析  
> `learningCoreId`: 41（母题：Data Pipeline）

## 1. 三句话题目本质
1. 这题本质是“把用户行为数据稳定采集、处理并可查询分析”。
2. 难点是高吞吐采集、实时与离线口径一致、维度查询性能。
3. 高分回答需要覆盖：采集 SDK、处理链路、指标定义、报表 API 和数据治理。

## 2. 一个真实场景故事
一家内容平台营销投放后，运营发现“点击很多，注册很少”，但不同报表口径冲突严重。团队建设分析平台后，统一事件模型和漏斗定义，并引入实时指标+T+1 对账，业务决策从“拍脑袋”变成“可验证”。

## 3. 术语白话表（>=10）
1. Event：埋点事件。
2. Session：用户会话。
3. UV/PV：独立访客/页面浏览量。
4. Funnel：漏斗转化路径。
5. Cohort：分群分析。
6. Real-time Dashboard：实时看板。
7. ETL：抽取、转换、加载。
8. Late Event：迟到事件。
9. Dimension：维度（渠道、地区、设备）。
10. Metric：指标（点击率、转化率）。
11. Sampling：抽样查询。
12. Data Retention：数据保留策略。

## 4. 需求澄清（功能/非功能/不做范围/SLO）
### 4.1 功能需求
1. 前端/后端事件采集。
2. 实时指标看板（分钟级）。
3. 离线报表和漏斗分析。
4. 自定义维度过滤查询。
5. 导出与权限控制。

### 4.2 非功能需求
1. 高吞吐采集，低丢失。
2. 查询延迟可控。
3. 指标口径一致可追溯。
4. 成本可控（冷热分层）。

### 4.3 不做范围
1. 不做完整 BI 自助建模平台。
2. 不做通用机器学习训练平台。
3. 不做全量秒级明细回查。

### 4.4 SLO
1. 事件采集成功率 >= 99.9%。
2. 实时看板延迟 P95 <= 60s。
3. 查询 API P95 <= 2s（热点维度）。

## 5. 容量估算（数字推导）
1. 日活 2000 万，平均每人 30 事件/天 => 6 亿事件/天。
2. 平均事件 800B，日原始数据约 480GB。
3. 峰值写入约 2 万事件/s，活动时 5 倍。
4. 实时窗口聚合状态约 100GB（含维度）。
5. 热数据保留 30 天，冷数据归档 180 天。
6. 结论：必须流批结合 + 热冷分层 + 维度预聚合。

## 6. 架构（简版+完整版）
### 6.1 简版
`SDK -> Ingest API -> MQ -> Stream Processor -> OLAP`

### 6.2 完整版
1. SDK/Server Collector：采集事件。
2. Ingest Gateway：鉴权、限流、基础校验。
3. MQ（Kafka）：削峰与回放。
4. Stream Compute：实时聚合（分钟级）。
5. Batch ETL：离线修正与宽表。
6. OLAP Store：查询加速（ClickHouse/Druid）。
7. Data Lake：明细冷存归档。
8. Report API：指标查询与漏斗分析。

## 7. API 设计（请求/响应/错误码/幂等）
### 7.1 采集事件
`POST /api/analytics/v1/events`

请求：
```json
{
  "eventId": "e-20260224-001",
  "userId": "u1001",
  "event": "page_view",
  "ts": 1708768800,
  "props": {"page":"/home","channel":"adA"}
}
```

### 7.2 查询指标
`POST /api/analytics/v1/query`

响应：
```json
{
  "metric": "pv",
  "range": ["2026-02-24T10:00:00Z","2026-02-24T11:00:00Z"],
  "series": [{"t":"10:10","v":12345}]
}
```

### 7.3 漏斗查询
`POST /api/analytics/v1/funnel`

错误码：
1. `422_INVALID_EVENT_SCHEMA`
2. `409_DUPLICATE_EVENT_ID`
3. `429_INGEST_THROTTLED`
4. `503_QUERY_DEGRADED`

幂等规则：
1. `eventId` 去重，重复采集不重复计算。
2. 漏斗查询参数归一化后可缓存。

## 8. 数据模型（实体/索引/分片）
1. `raw_event(event_id, user_id, event_name, ts, props_json)`。
2. `rt_metric(metric, minute_bucket, dims_hash, value)`。
3. `funnel_fact(funnel_id, step, date, dims_hash, count)`。
4. `user_profile_dim(user_id, channel, region, device)`。
5. `query_audit(query_id, actor, metric, latency_ms, ts)`。

冷热：
1. 原始明细近 7 天热存可查。
2. 历史明细入 data lake 冷存。
3. 常用指标做预聚合热表。

## 9. 核心流程（正常/高峰/故障恢复）
### 9.1 正常流程
1. SDK 上报事件到 Ingest API。
2. 事件入 MQ，流处理实时聚合。
3. 报表 API 从 OLAP 返回结果。

### 9.2 高峰流程
1. Ingest 限流和批量压缩上报。
2. 非核心维度降采样。
3. 查询层开启结果缓存与慢查询熔断。

### 9.3 故障恢复流程
1. 流处理失败从 checkpoint 恢复。
2. MQ 回放补算缺失窗口。
3. 离线任务 T+1 校正实时误差。

## 10. 一致性与事务边界
1. 采集到 MQ 为可靠边界。
2. 实时看板最终一致，允许分钟级偏差。
3. 离线对账口径作为最终准确口径。
4. 同 eventId 全链路幂等。
5. 查询缓存可短暂过期但需标明时间。

## 11. 可用性与容错（含 RTO/RPO）
1. Ingest 多副本与就近接入。
2. MQ 多副本可回放。
3. 流处理 checkpoint 保证恢复。
4. RTO：实时聚合 15 分钟恢复。
5. RPO：采集后事件不丢，查询可延后。

## 12. 可观测性（指标+阈值+处置动作）
1. `ingest_success_rate < 99.9%`：扩容入口并排查 schema 错误。
2. `mq_lag > 500000`：扩容流处理消费者。
3. `rt_pipeline_delay_sec > 60`：降采样非核心维度。
4. `query_p95_ms > 2000`：启用预聚合缓存。
5. `funnel_gap_rate > 1%`：触发离线补算。
6. `late_event_ratio` 异常：调整 watermark 策略。

## 13. 安全与合规
1. 采集 token 与项目隔离。
2. PII 字段脱敏与最小采集原则。
3. 查询权限按组织和数据集隔离。
4. 审计记录所有导出操作。
5. 保留和删除策略符合法规。

## 14. 成本与取舍
1. 全量明细实时查询成本高。
2. 预聚合快但灵活性下降。
3. 抽样查询省成本但精度损失。
4. 取舍：核心指标全量，长尾维度抽样+离线补算。

## 15. Java 关键代码（>=5段）
### 15.1 核心算法：实时聚合键生成
```java
public String dimsKey(Event e) {
    return e.eventName() + "|" + e.props().getOrDefault("channel", "-") + "|" + e.props().getOrDefault("region", "-");
}
```

### 15.2 幂等去重
```java
public boolean accept(Event e) {
    if (dedupRepo.exists(e.eventId())) return false;
    dedupRepo.save(e.eventId(), Duration.ofDays(2));
    rawRepo.insert(e);
    return true;
}
```

### 15.3 重试退避/失败处理
```java
public void sendToMqWithRetry(Event e) {
    long wait = 20;
    for (int i = 0; i < 4; i++) {
        try { mq.send("analytics-events", e.eventId(), e); return; }
        catch (RuntimeException ex) {
            if (i == 3) { dlqRepo.save(e.eventId(), ex.getMessage()); return; }
            sleep(wait); wait = Math.min(wait * 2, 200);
        }
    }
}
```

### 15.4 一致性边界：ingest+outbox
```java
@Transactional
public void persistAndOutbox(Event e) {
    rawRepo.insert(e);
    outboxRepo.insert("ANALYTICS_EVENT", e.eventId());
}
```

### 15.5 观测触发/回滚判定
```java
public void guardRealtimePipeline() {
    long lag = metrics.gauge("mq_lag").longValue();
    if (lag > 500_000) {
        featureSwitch.enable("analytics_sampling_mode");
        alerting.fire("ANALYTICS_LAG_HIGH", "lag=" + lag);
    }
}
```

## 16. 前端功能代码（React JS，仅 API 协作）
### 16.1 指标查询 Hook（loading/error/done）
```javascript
import { useState } from "react";

export function useMetricQuery() {
  const [state, setState] = useState({ phase: "idle", data: null, error: "" });
  async function query(payload) {
    setState({ phase: "loading", data: null, error: "" });
    try {
      const res = await fetch("/api/analytics/v1/query", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(payload)
      });
      if (!res.ok) throw new Error(`HTTP_${res.status}`);
      setState({ phase: "done", data: await res.json(), error: "" });
    } catch (e) {
      setState({ phase: "error", data: null, error: String(e.message || e) });
    }
  }
  return { state, query };
}
```

### 16.2 漏斗查询重试（高峰退避）
```javascript
export async function queryFunnel(payload) {
  let delay = 200;
  for (let i = 0; i < 3; i++) {
    try {
      const res = await fetch("/api/analytics/v1/funnel", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(payload)
      });
      if (!res.ok) throw new Error(`HTTP_${res.status}`);
      return { ok: true, data: await res.json() };
    } catch (err) {
      if (i === 2) return { ok: false, error: String(err.message || err) };
      await new Promise((r) => setTimeout(r, delay));
      delay = Math.min(delay * 2, 1600);
    }
  }
}
```

## 17. 测试策略
1. 单元测试：去重、聚合、漏斗步骤计算。
2. 集成测试：采集->MQ->实时聚合->查询。
3. 压测：峰值采集与查询并发。
4. 故障测试：MQ 积压、流处理重启、OLAP 故障。
5. 对账测试：实时与离线口径差异。

## 18. 丰富例子（>=10）
1. 页面浏览 PV 实时更新。
2. 注册漏斗 3 步转化率计算。
3. 活动高峰采样策略自动启用。
4. 迟到事件在下一窗口补算。
5. 重复 eventId 不重复统计。
6. 地区维度查询命中预聚合。
7. 离线补算修正实时偏差。
8. 导出报表写审计记录。
9. 热维度缓存提升查询速度。
10. 冷数据归档后按需回读。
11. 某渠道异常流量触发告警。
12. 漏斗某步突降自动预警。

## 19. 面试追问 + 可复述回答
1. 为什么要流批结合？
回答：流处理保证实时，批处理保证最终准确。
2. 去重放在哪里？
回答：入口和计算层都做，防重复传播。
3. 为什么要冷热分层？
回答：热数据保证查询速度，冷数据控制存储成本。
4. 查询慢怎么办？
回答：预聚合、缓存、限维度、慢查询熔断。
5. 与母题 Q41 差异？
回答：Q56 更偏业务分析产品能力与报表 API。

## 20. 新手学习路线
1. 先实现事件采集和入队。
2. 做实时分钟聚合。
3. 接离线补算与漏斗查询。
4. 加权限、审计、导出。
5. 加冷热分层和成本治理。

## 21. 上场前 Checklist
1. 能讲清采集到报表链路。
2. 能说明实时与离线口径关系。
3. 能说出高峰降级策略。
4. 能解释 MQ 与幂等作用。
5. 能区分本题与 Q41。

## 22. 与母题差异（对应母题/共性/差异/新增知识/话术）
### 22.1 对应母题
Q41 Data Pipeline。

### 22.2 共性能力
1. 都是采集-处理-存储-查询链路。
2. 都需高吞吐和可观测。
3. 都依赖流批结合。

### 22.3 关键差异
1. Q41 偏通用管道；Q56 偏分析产品。
2. Q56 强调指标定义和漏斗查询。
3. Q56 更强调查询 API 体验。
4. Q56 更强调业务维度权限治理。
5. Q56 更强调报表口径解释性。

### 22.4 本题新增知识点（>=5）
1. 指标/维度产品化 API 设计。
2. 漏斗计算和口径治理。
3. 实时看板与离线对账机制。
4. 查询缓存与预聚合策略。
5. 分析数据冷热分层。
6. 分析导出审计控制。

### 22.5 面试差异话术
“Q41 是数据管道底座题；Q56 是基于管道的分析产品题，重点在指标可用性、查询体验和业务解释能力。”

---

## 单题自审（Q56）
### A. 完整性检查
1. 22 节完整：通过。
2. Java 代码段 5 段：通过。
3. React JS API 代码 2 段：通过。

### B. 易懂性检查
1. 术语白话 >=10：通过。
2. 正常/高峰/故障流程完整：通过。

### C. 专属性检查
1. 聚焦 Web Analytics：通过。
2. API/MQ/冷热分层/代码一致：通过。

### D. 工程落地检查
1. 阈值+动作完整：通过。
2. RTO/RPO 清晰：通过。

### E. 代码相关性检查
1. Java 五类点位覆盖：通过。
2. 前端查询 API 与退避重试体现：通过。

### F. 母题差异检查
1. 与 Q41 差异具体：通过。

### 自评分（100）
1. 完整性：20/20
2. 易懂性：19/20
3. 面试可讲性：19/20
4. 技术深度：19/20
5. 工程落地性：19/20
总分：96/100（通过）
