# Q8 AWS Scaling - 百万用户扩展系统（高频）

## 1. 三句话题目本质
1. 这题本质是“单体系统如何演进为可横向扩展、可容灾、可观测的云上架构”。  
2. 难点不是会用 AWS 服务名，而是把容量、瓶颈、故障恢复和成本权衡讲清楚。  
3. 面试官要听你怎么从“能跑”升级到“稳、快、省、可持续扩容”。  

## 2. 一个真实场景故事
你负责一个在线教育平台，从日活 5 万涨到 120 万。早期单机部署，晚高峰接口超时率 12%。你按“CDN -> 网关 -> 无状态服务 -> 缓存 -> 分库分片 -> 异步解耦”逐步改造后：  
1. 峰值流量提升 8 倍。  
2. P95 从 480ms 降到 130ms。  
3. 单区故障可在 10 分钟内恢复服务。  

## 3. 术语白话表（新手可懂）
1. Horizontal Scaling：横向扩容，加机器而不是加单机配置。  
2. Load Balancer：把流量分发到多台服务实例。  
3. Auto Scaling：根据流量自动加减实例。  
4. Stateless：无状态服务，任意实例都能接请求。  
5. Multi-AZ：同区域多可用区部署，抗机房故障。  
6. Read Replica：读副本，分担主库读压力。  
7. CDN：把静态内容放到离用户更近的节点。  
8. Circuit Breaker：下游异常时快速失败，避免雪崩。  
9. Backpressure：限流回压，避免系统被压垮。  
10. Blue/Green：蓝绿发布，降低发布风险。  
11. RTO：故障恢复时间目标。  
12. RPO：可接受的数据丢失时间窗口。  

## 4. 需求澄清（功能/非功能/不做范围/SLO）
### 4.1 功能需求
1. 支持用户登录、内容浏览、订单支付等核心能力。  
2. 支持峰值自动扩容与弹性缩容。  
3. 支持跨 AZ 高可用。  
4. 支持静态资源加速。  
5. 支持全链路监控与告警。  

### 4.2 非功能需求
1. 高可用（核心链路不中断）。  
2. 低延迟（高峰依旧可控）。  
3. 可扩展（用户量增长时可平滑扩容）。  
4. 可运维（发布、回滚、故障定位效率高）。  

### 4.3 不做范围
1. 不深挖具体 AWS 计费细则。  
2. 不做底层云厂商内核实现。  
3. 不做跨云厂商统一调度平台。  

### 4.4 SLO/SLA
1. 核心 API 可用性 >= 99.95%。  
2. API 延迟 P95 < 200ms。  
3. 错误率 < 0.5%（5 分钟窗口）。  

## 5. 容量估算（数字推导）
假设 DAU 100 万，峰值同时在线 10 万：  
1. 峰值请求 QPS 约 2 万/s。  
2. 静态资源占 70%，经 CDN 后回源约 6000/s。  
3. 动态请求若单实例可承载 250 QPS，需要约 80 个实例（含冗余）。  
4. 主库写入峰值 3000 TPS，读峰值 1.5 万 QPS，需读写分离。  
5. 日志按 1KB/请求，日写日志约 1.7TB，需冷热分层。  

## 6. 架构设计（简版+完整版）
### 6.1 简版
`CDN -> LB -> API Gateway -> 无状态服务集群 -> 缓存 -> 数据库/消息队列`

### 6.2 完整版
1. Edge 层：CDN + WAF + DDoS 防护。  
2. 入口层：ALB/NLB + API Gateway（鉴权、限流、路由）。  
3. 业务层：容器化无状态服务（多 AZ）。  
4. 缓存层：Redis Cluster（热点缓存、会话、限流计数）。  
5. 数据层：主库 + 读副本 + 分片策略。  
6. 异步层：MQ 做削峰和解耦。  
7. 运维层：CI/CD、蓝绿发布、自动回滚。  
8. 观测层：Metrics/Logs/Trace + 告警平台。  

## 7. API 设计（请求/响应/错误码/幂等）
1. `GET /v1/health`：健康探针。  
2. `POST /v1/scale/policy`：调整扩缩容策略（运维）。  
3. `GET /v1/system/capacity`：容量看板。  
4. `POST /v1/system/degrade`：触发降级开关。  

响应示例：
```json
{
  "service": "api-core",
  "instances": 96,
  "cpuAvg": 58.2,
  "p95Ms": 143,
  "errorRate": 0.18
}
```

错误码：`429_TRAFFIC_SHED`、`503_DEPENDENCY_DEGRADED`、`504_UPSTREAM_TIMEOUT`。  

## 8. 数据模型（实体、索引、分片分区）
1. `service_capacity_snapshot`：实例数、CPU、内存、QPS、时间戳。  
2. `autoscale_policy`：服务名、扩容阈值、缩容阈值、冷却时间。  
3. `degrade_rule`：功能开关、触发条件、优先级。  
4. `incident_timeline`：告警、动作、恢复时间。  
5. `traffic_profile`：分时段流量画像。  
6. 索引：按 `service + timestamp` 聚簇索引，便于趋势分析。  

## 9. 核心流程（正常/高峰/故障恢复）
1. 正常：流量进 CDN -> 网关鉴权限流 -> 服务处理 -> 缓存/数据库 -> 返回。  
2. 高峰：CPU 与队列滞后升高 -> Auto Scaling 扩容 -> 非核心接口降级 -> 峰值后自动缩容。  
3. 故障恢复：某 AZ 故障 -> 负载切流到健康 AZ -> 触发扩容补位 -> 事后回放与复盘。  

## 10. 一致性与事务边界
1. 用户会话尽量无状态，避免跨实例粘滞。  
2. 业务写操作保持主库一致，读操作可最终一致。  
3. 跨服务写入采用事件驱动与补偿任务。  
4. 核心交易链路保证幂等，防重试重复扣款。  

## 11. 可用性与容错
1. 多 AZ 部署 + 健康检查自动摘除。  
2. 下游慢时启用熔断和超时快速失败。  
3. 降级策略：关闭推荐、降低报表精度、只保核心交易。  
4. 限流分级：按租户、接口、用户等级分层限流。  
5. RTO 15 分钟，RPO 5 分钟。  

## 12. 可观测性（指标+阈值+处置）
关键指标：  
1. `api_p95_ms`  
2. `error_rate`  
3. `instance_cpu_utilization`  
4. `queue_lag`  
5. `cache_hit_ratio`  

告警阈值：  
1. P95 > 250ms（10分钟）-> P1。  
2. 错误率 > 1%（5分钟）-> P1。  
3. CPU > 80%（10分钟）-> P2（触发扩容）。  
4. 队列滞后 > 300s（10分钟）-> P1。  

处置：扩容 -> 降级 -> 限流 -> 回放补偿 -> 复盘。  

## 13. 安全与合规
1. 网关统一鉴权和签名校验。  
2. 全链路 TLS，加密传输。  
3. 最小权限 IAM，敏感操作双人审批。  
4. 审计日志不可篡改存储。  
5. WAF 规则防常见攻击（SQLi、XSS、CC）。  

## 14. 成本与取舍
1. 预留实例省钱但灵活性差，按需实例灵活但贵。  
2. 高冗余高可用但成本高，要按业务等级分层。  
3. 全量实时指标贵，可做采样 + 聚合。  
4. 频繁扩缩容会抖动，需合理冷却时间。  

## 15. Java 关键代码（贴题难点，充分细节）
### 15.1 扩缩容决策器
```java
public class AutoScaleDecider {
    public int decide(int current, double cpu, double p95, int min, int max) {
        if (cpu > 80 || p95 > 250) return Math.min(max, current + Math.max(2, current / 5));
        if (cpu < 35 && p95 < 120) return Math.max(min, current - Math.max(1, current / 10));
        return current;
    }
}
```

### 15.2 熔断器
```java
public class CircuitBreaker {
    private int failures = 0;
    private long openUntil = 0;

    public boolean allow() {
        return System.currentTimeMillis() >= openUntil;
    }

    public void onFailure() {
        failures++;
        if (failures >= 20) {
            openUntil = System.currentTimeMillis() + 10_000;
            failures = 0;
        }
    }

    public void onSuccess() { failures = 0; }
}
```

### 15.3 分级限流
```java
public class TierRateLimiter {
    private final Map<String, Integer> limits = Map.of("gold", 500, "silver", 200, "free", 50);

    public boolean allow(String tier, int currentQps) {
        int limit = limits.getOrDefault(tier, 50);
        return currentQps < limit;
    }
}
```

### 15.4 降级开关执行
```java
public class DegradeManager {
    private final Set<String> enabled = ConcurrentHashMap.newKeySet();

    public void enable(String feature) { enabled.add(feature); }
    public void disable(String feature) { enabled.remove(feature); }
    public boolean isEnabled(String feature) { return enabled.contains(feature); }
}
```

### 15.5 关键路径超时保护
```java
public class TimeoutExecutor {
    public <T> T runWithTimeout(Callable<T> task, long timeoutMs, T fallback) {
        ExecutorService es = Executors.newSingleThreadExecutor();
        Future<T> f = es.submit(task);
        try {
            return f.get(timeoutMs, TimeUnit.MILLISECONDS);
        } catch (Exception e) {
            f.cancel(true);
            return fallback;
        } finally {
            es.shutdown();
        }
    }
}
```

## 16. 前端功能代码（贴题控制台/运营页）
### 16.1 容量看板页（React + TS）
```tsx
type Capacity = { instances: number; cpuAvg: number; p95Ms: number; errorRate: number };

export function CapacityDashboard() {
  const [c, setC] = useState<Capacity | null>(null);
  useEffect(() => {
    fetch("/api/system/capacity").then(r => r.json()).then(setC);
  }, []);
  if (!c) return <div>loading...</div>;
  return <div>实例:{c.instances} CPU:{c.cpuAvg}% P95:{c.p95Ms}ms 错误率:{c.errorRate}%</div>;
}
```

### 16.2 降级开关页（React + TS）
```tsx
export function DegradeSwitchPanel() {
  const [feature, setFeature] = useState("recommendation");
  async function toggle(enable: boolean) {
    await fetch("/api/system/degrade", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ feature, enable })
    });
    alert(enable ? "已开启降级" : "已关闭降级");
  }
  return (
    <div>
      <input value={feature} onChange={e => setFeature(e.target.value)} />
      <button onClick={() => toggle(true)}>开启</button>
      <button onClick={() => toggle(false)}>关闭</button>
    </div>
  );
}
```

## 17. 测试策略
1. 单测：扩缩容决策、限流规则、熔断状态机。  
2. 集成：流量进入网关到服务响应全链路。  
3. 压测：2 万 QPS 峰值下扩容响应时间。  
4. 演练：单 AZ 故障、缓存故障、下游超时。  
5. 回归：每次发布验证降级策略和回滚路径。  

## 18. 丰富例子（面试可复述）
1. 从 1 万到 10 万并发如何平滑扩容。  
2. CDN 命中率下降导致回源暴增如何处理。  
3. 数据库读副本延迟飙升如何降级。  
4. 某 AZ 故障如何快速切流。  
5. 自动扩容触发过慢导致超时怎么优化。  
6. 过度扩容导致成本翻倍怎么治理。  
7. 发布后错误率上升如何秒级回滚。  
8. 热点接口如何单独限流而不伤全局。  
9. 消息队列积压如何保护核心链路。  
10. 观测系统误报如何减少告警噪音。  
11. 会话粘滞造成扩容无效如何改造。  
12. 跨区灾备演练如何验收。  

## 19. 面试追问+回答模板
1. 问：为什么要无状态化？  
答：无状态才能真正横向扩容和快速故障切换，避免单点会话依赖。  
2. 问：高峰时先做什么？  
答：先保核心链路，立刻扩容 + 降级非核心功能 + 分级限流。  
3. 问：如何证明架构可落地？  
答：给出容量推导、阈值、故障演练结果和回滚时长。  

## 20. 新手学习路线
1. 先理解负载均衡和无状态服务。  
2. 再学缓存和读写分离。  
3. 学自动扩缩容和限流熔断。  
4. 学可观测性和告警策略。  
5. 最后练故障演练与复盘。  

## 21. 上场前Checklist
1. 能讲清扩容触发条件。  
2. 能讲清高峰降级策略。  
3. 能给出 RTO/RPO 和告警阈值。  
4. 能讲清成本与性能取舍。  
5. 能讲出与母题的边界差异。  

## 22. 与母题差异（共性/差异/新增知识/话术）
### 22.1 对应母题
- 母题：`Q62 Container Orchestration`。  

### 22.2 共性能力
1. 都是云原生扩展能力。  
2. 都强调弹性、调度和高可用。  
3. 都需要可观测和自动化运维。  
4. 都关注故障恢复。  

### 22.3 关键差异
1. Q62 重点是容器编排平台设计；Q8 重点是业务系统扩展实践。  
2. Q8 更强调 CDN、网关、数据库、缓存等端到端链路。  
3. Q62 会深入调度器、控制面；Q8 关注业务容量治理。  
4. Q8 更偏“怎么把业务扛住”，Q62 更偏“平台如何调度资源”。  
5. Q8 需要更具体的高峰和降级策略。  

### 22.4 本题新增必补知识
1. 云上流量分层（CDN/网关/服务）。  
2. 扩缩容阈值设计。  
3. 高峰降级与回压策略。  
4. 多 AZ 容灾切换。  
5. 成本治理与容量规划。  

### 22.5 面试差异话术
1. “Q62 讲平台编排，Q8 讲业务如何在云上扩到百万用户。”  
2. “Q8 必须给出可操作阈值和故障动作，不只是讲组件名。”  
3. “这题核心是端到端容量治理，而不是单点技术炫技。”  
