# Q41：Data Pipeline（数据管道）系统设计 - 95分面试版

## 1. 三句话题目本质
1. 数据管道本质是把“业务世界里的原始事件”稳定搬运、清洗、加工成“可用于决策的数据资产”。  
2. 难点不是把数据跑通一次，而是长期保证“不乱、不丢、可追溯、可重放、口径一致”。  
3. 面试高分关键：采集-传输-计算-落地-质量-血缘-回放闭环要讲完整，并且说清 Exactly-once 的工程取舍。  

## 2. 一个真实场景故事
你在做电商 BI 平台。周一早上运营发现昨晚 GMV 看板少了 12%。  
排查后发现：
- 支付事件有一批延迟 20 分钟到达。
- 流任务重启后某个算子重复消费了一段数据。
- 质量规则没有及时报警，直到业务方发现才报错。

老板问你三件事：
1. 怎么保证以后这种错不再发生？
2. 出现错误后多久能定位到哪一层出了问题？
3. 能不能“一键重放”昨晚数据把报表修回来？

这就是数据管道题的核心：不仅要“算得出”，还要“算得准、查得到、修得快”。

## 3. 术语白话表（至少 10 项）
| 术语 | 白话解释 | 面试可复述 |
|---|---|---|
| Ingestion | 数据采集 | “把业务数据先接进来” |
| CDC | 数据库变更捕获 | “监听数据库 binlog 拿增量变更” |
| Streaming | 流处理 | “数据来一条处理一条” |
| Batch | 批处理 | “按小时/天集中处理” |
| Watermark | 水位线 | “告诉系统大概等到什么时候就不再等迟到数据” |
| Late Event | 迟到事件 | “该窗口已经算完才来的数据” |
| Exactly-once | 精确一次语义 | “既不丢也不重，工程实现复杂” |
| At-least-once | 至少一次语义 | “可能重复但不丢，需下游幂等” |
| Checkpoint | 状态快照点 | “作业挂了可从最近状态恢复” |
| DLQ | 死信队列 | “处理失败的坏消息先隔离” |
| Data Quality Rule | 数据质量规则 | “如空值率、唯一性、范围校验” |
| Lineage | 数据血缘 | “这张表/这个指标是从哪一步算来的” |
| Backfill | 回填/重算 | “历史数据修复后重新补算” |
| Schema Evolution | 结构演进 | “字段变化时怎么兼容老数据” |
| SLA/SLO | 服务目标 | “延迟、正确性、可用性的承诺” |

## 4. 需求澄清（功能/非功能/不做范围）
### 4.1 功能需求
- 支持多源采集：DB CDC、埋点日志、第三方回调、文件批量导入。
- 支持实时流处理与离线批处理。
- 支持多层落地：ODS（原始层）/DWD（明细层）/DWS（汇总层）。
- 支持数据质量校验、异常报警、坏数据隔离。
- 支持血缘追踪、任务审计、历史回放与重算。

### 4.2 非功能需求（SLO 示例）
- 实时链路端到端延迟：`P95 <= 3 分钟`。
- 关键指标准确率：`>= 99.99%`（经过质量规则校验）。
- 任务成功率：`>= 99.9%`。
- 管道可用性：`>= 99.95%`。
- 事件丢失率：`< 0.001%`（核心主题）。

### 4.3 Out of Scope（首版不做）
- 不做复杂跨云多活一致性。
- 不做全自动特征工程平台（先人工定义规则）。
- 不做全量秒级回溯（先支持小时/天级回放）。

## 5. 容量估算（含数字推导）
### 5.1 假设
- 事件吞吐：`2,500,000 events/s`
- 平均事件大小：`800B`
- 峰值系数：`3x`
- 实时窗口状态保留：`2 小时`

### 5.2 吞吐估算
- 平均入口流量：`2.5M * 800B ≈ 2GB/s`
- 峰值入口流量：`~6GB/s`
- 每日原始数据量：`2GB/s * 86400 ≈ 172.8TB/day`

### 5.3 消费与存储估算
- 若 Kafka 保留 3 天：`~518TB`（不含副本）
- 三副本后：`~1.5PB`
- 实时状态（窗口聚合）按 5% 估算：`~8TB` 状态存储预算

### 5.4 关键结论
- 必须分区并行和水平扩展，不存在“单机救火”。
- 状态后端（RocksDB/State Store）和 Checkpoint 存储必须独立容量规划。
- 质量规则和回放链路要独立于主链路，避免互相拖垮。

## 6. 架构（简版 + 完整版）
### 6.1 简版架构
```text
Sources -> Kafka -> Stream Compute -> Lake/Warehouse -> BI
                       |-> Quality -> Alert
                       |-> Lineage -> Metadata
```

### 6.2 完整版架构
```text
[Data Sources]
  - MySQL/Postgres (CDC)
  - App Event SDK
  - Payment Webhook
  - Batch Files (S3/HDFS)

        -> [Ingestion Layer]
            - Debezium/CDC Connector
            - HTTP Collector
            - File Ingestor

        -> [Message Bus: Kafka/Pulsar]
            - Topic Partitioning
            - Schema Registry (Avro/Protobuf)

        -> [Processing Layer]
            - Flink Streaming Jobs
            - Spark Batch Jobs
            - Rule Engine (Data Quality)

        -> [Storage Layer]
            - ODS (Raw, append-only)
            - DWD (Cleaned detail)
            - DWS (Aggregated metrics)
            - Serving DB (ClickHouse/OLAP)

        -> [Governance Layer]
            - Metadata Catalog
            - Data Lineage Graph
            - Access Control + Audit

        -> [Ops Layer]
            - Metrics/Logs/Trace
            - Alert + Runbook
            - Replay/Backfill Controller
```

## 7. API 设计（含请求/响应样例）
### 7.1 采集接口（埋点）
`POST /api/v1/events/collect`

Request:
```json
{
  "eventId": "evt_20260224_001",
  "source": "app",
  "eventType": "ORDER_PAID",
  "eventTime": "2026-02-24T10:15:00Z",
  "payload": {
    "orderId": "o_991",
    "userId": 12345,
    "amount": 399.00
  }
}
```

Response:
```json
{
  "accepted": true,
  "topic": "ods.order_events",
  "partition": 18,
  "offset": 1002334
}
```

### 7.2 任务状态接口
`GET /api/v1/pipelines/{pipelineId}/status`

Response:
```json
{
  "pipelineId": "gmv_stream_v4",
  "state": "RUNNING",
  "lagMsP95": 42000,
  "lastCheckpointTs": "2026-02-24T10:14:30Z",
  "qualityScore": 99.97
}
```

### 7.3 回放接口
`POST /api/v1/pipelines/{pipelineId}/replay`

Request:
```json
{
  "topic": "ods.order_events",
  "fromOffset": 1200000,
  "toOffset": 1300000,
  "reason": "fix missing paid events",
  "operator": "alice"
}
```

### 7.4 质量规则触发接口
`POST /api/v1/quality/checks/run`

Request:
```json
{
  "dataset": "dwd_order_paid",
  "rules": ["not_null(order_id)", "range(amount,0,100000)", "unique(event_id)"]
}
```

### 7.5 错误码语义
- `409_PIPELINE_STATE_CONFLICT`：任务当前状态不允许操作。
- `422_INVALID_SCHEMA_VERSION`：事件结构版本不兼容。
- `503_REPLAY_QUEUE_BUSY`：回放队列繁忙，稍后重试。

## 8. 数据模型（核心表/索引）
### 8.1 原始事件表（ODS）
```sql
CREATE TABLE ods_raw_event (
  event_id VARCHAR(64) NOT NULL,
  source VARCHAR(32) NOT NULL,
  event_type VARCHAR(64) NOT NULL,
  schema_version INT NOT NULL,
  payload JSON NOT NULL,
  event_time TIMESTAMP NOT NULL,
  ingest_time TIMESTAMP NOT NULL,
  partition_date DATE NOT NULL
);
```

### 8.2 清洗明细表（DWD）
```sql
CREATE TABLE dwd_order_paid (
  event_id VARCHAR(64) PRIMARY KEY,
  order_id VARCHAR(64) NOT NULL,
  user_id BIGINT NOT NULL,
  pay_amount DECIMAL(18,2) NOT NULL,
  pay_channel VARCHAR(32),
  event_time TIMESTAMP NOT NULL,
  process_time TIMESTAMP NOT NULL,
  dt DATE NOT NULL
);
CREATE INDEX idx_dwd_order_paid_dt ON dwd_order_paid(dt);
```

### 8.3 汇总指标表（DWS）
```sql
CREATE TABLE dws_gmv_5m (
  window_start TIMESTAMP NOT NULL,
  window_end TIMESTAMP NOT NULL,
  biz_line VARCHAR(32) NOT NULL,
  paid_order_cnt BIGINT NOT NULL,
  gmv DECIMAL(18,2) NOT NULL,
  PRIMARY KEY(window_start, biz_line)
);
```

### 8.4 质量检查结果表
```sql
CREATE TABLE data_quality_result (
  check_id BIGINT PRIMARY KEY,
  pipeline_id VARCHAR(64) NOT NULL,
  dataset VARCHAR(128) NOT NULL,
  rule_name VARCHAR(128) NOT NULL,
  status VARCHAR(16) NOT NULL, -- PASS/FAIL/WARN
  bad_count BIGINT NOT NULL,
  sample_records JSON,
  checked_at TIMESTAMP NOT NULL
);
CREATE INDEX idx_quality_dataset_time ON data_quality_result(dataset, checked_at DESC);
```

### 8.5 血缘关系表
```sql
CREATE TABLE data_lineage_edge (
  edge_id BIGINT PRIMARY KEY,
  upstream_asset VARCHAR(128) NOT NULL,
  transform_job VARCHAR(128) NOT NULL,
  downstream_asset VARCHAR(128) NOT NULL,
  created_at TIMESTAMP NOT NULL
);
```

## 9. 核心流程（至少 3 条）
### 9.1 正常流程（实时 GMV）
1. 订单支付事件通过 SDK/CDC 写入 Kafka。
2. Flink 作业消费事件，做去重、字段标准化、币种换算。
3. 写入 DWD 明细，并做 5 分钟窗口聚合写 DWS。
4. 质量规则检查通过后，BI 看板刷新。

### 9.2 高峰流程（大促）
1. 流量激增 3x，Kafka lag 上升。
2. 自动扩容消费者并提高关键 topic 权重。
3. 非核心链路（低优先报表）降频，保障 GMV 主链路。
4. 峰值后自动回收资源。

### 9.3 故障恢复流程（作业失败）
1. Flink 作业因算子异常退出。
2. 从最近 checkpoint 自动恢复。
3. 恢复期间数据暂存 Kafka，不丢消息。
4. 恢复后质量规则触发补检，确认指标一致。

### 9.4 回放修复流程（历史漏数）
1. 质量规则告警“订单支付记录少于预期”。
2. 运维在控制台触发 offset 区间回放。
3. 回放数据进入修复管道，幂等写入目标表。
4. 修复完成后标记回放任务并自动生成审计报告。

## 10. 一致性与事务边界（Exactly-once 取舍）
### 10.1 语义选择
- 核心链路（财务相关）：尽量 Exactly-once。
- 非核心链路（行为分析）：At-least-once + 幂等足够。

### 10.2 工程实现建议
- Kafka source + Flink checkpoint + sink 两阶段提交（2PC）可实现端到端 EOS。
- 如果 sink 不支持 2PC，则采用幂等键（`event_id`）+ UPSERT。

### 10.3 一致性边界
- 实时看板与离线对账允许短时间差异（分钟级）。
- T+1 财务对账必须收敛到一致。

### 10.4 面试可复述结论
“Exactly-once 不是信仰，是成本问题。关键指标值得做，不关键链路做幂等可接受。”

## 11. 可用性与容错
### 11.1 常见故障
- Kafka broker 异常导致消费延迟。
- 状态后端爆盘导致 checkpoint 失败。
- 下游仓库写入限流。
- Schema 变更不兼容导致解析失败。

### 11.2 容错策略
- 多 broker 多副本，关键 topic 提高 ISR 策略。
- Checkpoint 存储多副本与生命周期清理。
- 下游写入失败进入重试队列和 DLQ。
- Schema Registry 强制向后兼容策略。

### 11.3 RTO / RPO
- 实时作业 RTO：`<= 10 分钟`
- 核心指标 RPO：`<= 1 分钟`
- 非核心分析 RPO：`<= 15 分钟`

## 12. 可观测性（指标 + 告警阈值）
### 12.1 采集与消息层
- `ingest_qps`
- `kafka_produce_error_rate`
- `consumer_lag`

阈值示例：
- `consumer_lag > 5,000,000` 持续 10 分钟 -> P1
- `kafka_produce_error_rate > 0.5%` 持续 5 分钟 -> P1

### 12.2 计算层
- `pipeline_latency_p95_ms`
- `checkpoint_duration_ms`
- `job_restart_count`

阈值示例：
- `pipeline_latency_p95_ms > 180000`（3分钟）持续 10 分钟 -> P1
- `checkpoint_duration_ms > 60000` 持续 15 分钟 -> P2
- `job_restart_count >= 3/10min` -> P1

### 12.3 质量层
- `quality_fail_rate`
- `null_ratio_by_field`
- `duplicate_event_ratio`

阈值示例：
- `quality_fail_rate > 1%` -> P1
- `duplicate_event_ratio > 0.2%` -> P1

## 13. 安全与合规
- PII 字段（手机号、身份证）采集即脱敏或 token 化。
- 数据访问做 RBAC + 列级权限控制。
- 审计日志覆盖：谁在何时对哪个管道做了什么变更。
- 数据生命周期管理：到期清理、合规留存。
- 跨境数据策略按地区法规执行（数据本地化）。

## 14. 成本与取舍
### 14.1 成本构成
- 消息系统（Kafka/Pulsar）存储与带宽。
- 流计算资源（CPU/Memory/State IO）。
- 数仓存储（热数据+冷数据）。

### 14.2 典型取舍
- 全实时 vs 批流混合：全实时体验好但成本高。
- 长状态窗口 vs 小窗口：窗口越长越耗状态资源。
- 严格 EOS vs 幂等：EOS 更准确但链路复杂和性能成本高。

### 14.3 降本策略
- 热数据近 7 天高性能存储，历史数据归档冷存。
- 统一事件模型减少重复采集与重复清洗。
- 分层算子复用，避免每个业务重复开流任务。

## 15. 关键代码（Java 详细版 + 前端功能代码）
### 15.1 Java：事件幂等去重（Redis/Bloom + DB 双保险）
```java
public class EventDedupService {
    private final RedisClient redis;
    private final EventRepository eventRepository;

    public boolean accept(Event e) {
        String dedupKey = "dedup:event:" + e.getEventId();
        // 先用 Redis SETNX 做快速去重，TTL 防止无限增长
        boolean firstSeen = redis.setNxWithTtl(dedupKey, "1", 48 * 3600);
        if (!firstSeen) {
            return false;
        }

        // 再用 DB 唯一键做最终保险（防 Redis 丢失造成重复）
        try {
            eventRepository.insertRaw(e); // event_id unique
            return true;
        } catch (DuplicateKeyException ex) {
            return false;
        }
    }
}
```

### 15.2 Java：Flink 风格窗口聚合（迟到事件处理）
```java
public class GmvWindowProcessor {
    private static final Duration ALLOWED_LATENESS = Duration.ofMinutes(10);

    public WindowResult process(List<OrderPaidEvent> events, Instant windowStart, Instant windowEnd) {
        BigDecimal gmv = BigDecimal.ZERO;
        long count = 0L;
        long late = 0L;

        for (OrderPaidEvent e : events) {
            if (e.getEventTime().isAfter(windowEnd.plus(ALLOWED_LATENESS))) {
                late++;
                continue; // 过晚数据丢到 side output / DLQ
            }
            if (!e.getEventTime().isBefore(windowStart) && e.getEventTime().isBefore(windowEnd)) {
                gmv = gmv.add(e.getPayAmount());
                count++;
            }
        }
        return new WindowResult(windowStart, windowEnd, count, gmv, late);
    }
}
```

### 15.3 Java：质量规则执行器（规则可配置）
```java
public class DataQualityEngine {
    public List<QualityCheckResult> runChecks(String dataset, List<Map<String, Object>> rows, List<QualityRule> rules) {
        List<QualityCheckResult> results = new ArrayList<>();
        for (QualityRule rule : rules) {
            long badCount = 0;
            for (Map<String, Object> row : rows) {
                if (!rule.test(row)) {
                    badCount++;
                }
            }
            QualityCheckResult r = new QualityCheckResult(dataset, rule.name(), badCount == 0 ? "PASS" : "FAIL", badCount);
            results.add(r);
        }
        return results;
    }
}
```

### 15.4 Java：回放任务控制器（区间回放 + 幂等写）
```java
public class ReplayController {
    private final KafkaReader kafkaReader;
    private final RepairPipeline repairPipeline;

    public ReplaySummary replay(String topic, long fromOffset, long toOffset, String operator) {
        long read = 0, repaired = 0, skipped = 0;
        for (long offset = fromOffset; offset <= toOffset; offset++) {
            Optional<Event> e = kafkaReader.read(topic, offset);
            if (e.isEmpty()) continue;
            read++;
            boolean ok = repairPipeline.processWithIdempotency(e.get());
            if (ok) repaired++;
            else skipped++;
        }
        return new ReplaySummary(topic, fromOffset, toOffset, read, repaired, skipped, operator);
    }
}
```

### 15.5 Java：Schema 兼容校验（上线门禁）
```java
public class SchemaCompatibilityGate {
    public void assertBackwardCompatible(Schema oldSchema, Schema newSchema) {
        for (Field oldField : oldSchema.getFields()) {
            Field nf = newSchema.getField(oldField.getName());
            if (nf == null && !oldField.hasDefaultValue()) {
                throw new IllegalStateException("Breaking change: missing required field " + oldField.getName());
            }
            if (nf != null && !isTypeCompatible(oldField.getType(), nf.getType())) {
                throw new IllegalStateException("Type incompatible for field " + oldField.getName());
            }
        }
    }

    private boolean isTypeCompatible(String oldType, String newType) {
        return oldType.equals(newType) || ("int".equals(oldType) && "long".equals(newType));
    }
}
```

### 15.6 前端（React + TypeScript）：管道监控页（查看状态 + 告警）
```tsx
import { useEffect, useState } from "react";

type PipelineStatus = {
  pipelineId: string;
  state: "RUNNING" | "FAILED" | "PAUSED";
  lagMsP95: number;
  lastCheckpointTs: string;
  qualityScore: number;
};

export function PipelineStatusPanel({ pipelineId }: { pipelineId: string }) {
  const [status, setStatus] = useState<PipelineStatus | null>(null);
  const [error, setError] = useState<string>("");

  useEffect(() => {
    let timer: number;
    const fetchStatus = async () => {
      try {
        const resp = await fetch(`/api/v1/pipelines/${pipelineId}/status`);
        if (!resp.ok) throw new Error(`HTTP ${resp.status}`);
        const data = (await resp.json()) as PipelineStatus;
        setStatus(data);
        setError("");
      } catch (e) {
        setError((e as Error).message);
      } finally {
        timer = window.setTimeout(fetchStatus, 5000);
      }
    };
    fetchStatus();
    return () => window.clearTimeout(timer);
  }, [pipelineId]);

  if (error) return <div>状态拉取失败: {error}</div>;
  if (!status) return <div>加载中...</div>;

  const lagWarn = status.lagMsP95 > 180000;
  const qualityWarn = status.qualityScore < 99.9;

  return (
    <div>
      <h3>Pipeline: {status.pipelineId}</h3>
      <p>状态: {status.state}</p>
      <p style={{ color: lagWarn ? "red" : "inherit" }}>
        延迟P95: {status.lagMsP95} ms {lagWarn ? "(超阈值)" : ""}
      </p>
      <p style={{ color: qualityWarn ? "red" : "inherit" }}>
        质量分: {status.qualityScore} {qualityWarn ? "(需排查)" : ""}
      </p>
      <p>最后检查点: {status.lastCheckpointTs}</p>
    </div>
  );
}
```

### 15.7 前端（React + TypeScript）：回放触发表单（运维功能）
```tsx
import { useState } from "react";

export function ReplayForm({ pipelineId }: { pipelineId: string }) {
  const [topic, setTopic] = useState("ods.order_events");
  const [fromOffset, setFromOffset] = useState("0");
  const [toOffset, setToOffset] = useState("0");
  const [reason, setReason] = useState("");
  const [result, setResult] = useState("");

  const submitReplay = async () => {
    const body = {
      topic,
      fromOffset: Number(fromOffset),
      toOffset: Number(toOffset),
      reason,
      operator: "current_user"
    };
    const resp = await fetch(`/api/v1/pipelines/${pipelineId}/replay`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(body)
    });
    setResult(resp.ok ? "回放任务已提交" : `提交失败: ${resp.status}`);
  };

  return (
    <div>
      <h3>触发回放</h3>
      <input value={topic} onChange={(e) => setTopic(e.target.value)} placeholder="topic" />
      <input value={fromOffset} onChange={(e) => setFromOffset(e.target.value)} placeholder="fromOffset" />
      <input value={toOffset} onChange={(e) => setToOffset(e.target.value)} placeholder="toOffset" />
      <input value={reason} onChange={(e) => setReason(e.target.value)} placeholder="原因" />
      <button onClick={submitReplay}>提交回放</button>
      {result && <p>{result}</p>}
    </div>
  );
}
```

## 16. 测试策略
### 16.1 单元测试
- 去重规则：重复事件、乱序事件、迟到事件覆盖。
- 质量规则：空值、范围、唯一性、跨字段约束。
- Schema 演进：向后兼容与不兼容场景。

### 16.2 集成测试
- 采集 -> Kafka -> Flink -> DWD/DWS 全链路。
- 任务失败后 checkpoint 恢复正确性。
- 回放流程与正常流程幂等一致性。

### 16.3 压测
- 入口 3 倍峰值持续 30 分钟压测。
- 分区倾斜压测（热点 key）。
- 下游限速压测（背压行为验证）。

### 16.4 故障注入
- Kafka broker 下线。
- 状态存储故障。
- Schema 非兼容发布拦截。
- 下游仓库超时与重试风暴。

## 17. 丰富例子（至少 10 个）
1. 支付事件晚到 8 分钟，仍被窗口接受并修正 GMV。  
2. 订单重复上报两次，通过 `event_id` 去重只算一次。  
3. 某字段突然空值率升到 15%，质量规则 1 分钟内报警。  
4. 大促期间消费者 lag 飙升，通过扩容把延迟从 12 分钟降到 2 分钟。  
5. Schema 新增字段未给默认值，发布被兼容门禁阻断。  
6. 某作业重启后自动从 checkpoint 恢复，无需人工补数。  
7. 下游仓库写入限流，数据先进重试队列，超时进入 DLQ。  
8. BI 看板数据异常，通过血缘图快速定位是上游币种换算逻辑出错。  
9. 触发 offset 区间回放，30 分钟内修复昨晚漏算的支付金额。  
10. 非核心报表链路高峰降频，保障核心 GMV 链路 SLA。  
11. 日志采集端 bug 发送非法 JSON，采集层隔离坏消息并打告警。  
12. 冷数据从热存迁移到低成本存储，月成本下降 28%。  

## 18. 面试追问 + 可复述回答
### Q1：Exactly-once 一定要做吗？
可复述：  
“不是所有链路都值得做 EOS。核心财务链路建议做，其他链路用至少一次+幂等可平衡成本。”

### Q2：迟到数据怎么处理？
可复述：  
“用 watermark + allowed lateness。窗口关闭后过晚数据进 side output，再走修复流程。”

### Q3：如何保证可追溯？
可复述：  
“每层资产都登记元数据和血缘，问题出现可从指标反查到作业、再反查到原始 topic。”

### Q4：质量规则要放在哪一层？
可复述：  
“入口做结构合法性，明细层做字段质量，汇总层做口径一致性，三层都要有。”

### Q5：回放会不会把数据算重？
可复述：  
“回放必须走幂等写路径，依赖唯一业务键和 upsert 语义，避免重复入库。”

### Q6：如何讲清实时和离线口径一致？
可复述：  
“统一指标定义和维度字典，实时先给快数，T+1 离线对账出准数，偏差超阈触发修复。”

## 19. 新手学习路线
### 第 1 周：最小链路
- 用 Kafka + Flink 跑通“事件采集 -> 窗口聚合 -> 落库”。
- 理解 event time、watermark、checkpoint 基础概念。

### 第 2 周：质量与治理
- 增加空值/唯一性/范围三类质量规则。
- 学会把作业和表登记到元数据目录。

### 第 3 周：容错与回放
- 做作业故障恢复演练。
- 实现 offset 区间回放和幂等修复。

### 第 4 周：工程化表达
- 加监控告警和 Runbook。
- 准备面试讲稿：采集、处理、落地、质量、血缘、回放六步讲清。

## 20. 上场前 Checklist
- [ ] 我能讲清实时链路与离线链路各自职责。  
- [ ] 我能解释 watermark、迟到数据和窗口补算。  
- [ ] 我能说明 Exactly-once 与幂等方案取舍。  
- [ ] 我能给出至少 3 个可执行告警阈值。  
- [ ] 我能描述一条从异常指标到根因定位的血缘排查路径。  
- [ ] 我能说明回放如何保证不重复入库。  
- [ ] 我能讲清数据质量规则怎么分层落地。  
- [ ] 我能展示前端运维页面如何观察状态和触发回放。  

## 21. 30 秒总结
数据管道高分答案是：  
“把数据稳定采进来，用可恢复的流批计算做加工，用质量规则和血缘保证可追溯，再用回放机制保证出错可修复。”  
如果你还能补上阈值、故障演练、以及前端运维操作闭环，面试官会认为你具备真实生产经验。  
