# Q42 Log Aggregation (日志聚合)

> 来源校验（questions.ts）  
> `title`: Log Aggregation (日志聚合)  
> `tags`: 日志采集, 索引检索, 实时分析, 告警, 可观测性  
> `keyPoints`: 采集链路解耦, 日志结构化, 索引分片, 冷热分层存储, 告警联动  
> `learningCoreId`: 41（母题：Data Pipeline）

## 1. 三句话题目本质
1. 这题核心是把分散在各服务节点的日志，稳定采集、统一检索、快速分析并可告警。
2. 难点是写入洪峰、索引膨胀、查询延迟、以及日志质量不一致。
3. 高分回答要覆盖：采集解耦、索引生命周期、查询隔离、告警闭环和成本治理。

## 2. 一个真实场景故事
某支付平台一次线上事故后，值班同学需要在 10 分钟内定位根因，但日志分散在 200 多台机器，关键请求链路无法快速聚合检索。团队建设日志聚合平台后，实现“5 秒内检索最近 15 分钟错误日志”，并能按 traceId 串联上下游，平均故障定位时间从 35 分钟降到 6 分钟。

## 3. 术语白话表（>=10）
1. Log Shipper：日志采集代理（如 Fluent Bit）。
2. Parsing：将原始文本解析为结构化字段。
3. Enrichment：补充环境、服务、region 等标签。
4. Index Template：索引字段和映射模板。
5. Inverted Index：倒排索引，支持全文检索。
6. Time Partition：按时间分片索引（天/小时）。
7. ILM：索引生命周期管理（热-温-冷）。
8. Hot/Warm/Cold：不同性能与成本层级的存储策略。
9. Trace Correlation：通过 traceId 关联链路日志。
10. Sampling：抽样存储，降低非关键日志成本。
11. Retention：日志保留周期。
12. Cardinality Explosion：高基数字段导致索引膨胀。

## 4. 需求澄清（功能/非功能/不做范围/SLO）
### 4.1 功能需求
1. 支持多来源日志采集（容器、主机、网关、应用）。
2. 支持结构化解析与字段标准化。
3. 支持按时间、服务、级别、traceId 检索。
4. 支持实时告警（错误率、特征关键词、流量突增）。
5. 支持冷热分层与日志保留策略。

### 4.2 非功能需求
1. 写入高吞吐，读查询低延迟。
2. 平台高可用，采集不中断。
3. 可扩展，支持业务线持续增长。
4. 成本可控，冷热分层节省存储。

### 4.3 不做范围
1. 不做 APM 全链路埋点替代（仅日志侧关联）。
2. 不做 SIEM 全量安全分析能力。
3. 不做跨云全球强一致日志复制。

### 4.4 SLO
1. 日志写入成功率 >= 99.9%。
2. 查询 P95 <= 3 秒（近 24 小时热数据）。
3. 告警延迟 P95 <= 30 秒。

## 5. 容量估算（数字推导）
1. 5000 个服务实例，平均每实例 300 行/秒。
2. 平均每行 600B，则入口吞吐约 `5000*300*600B ≈ 900MB/s`。
3. 每日原始日志约 `900MB/s * 86400 ≈ 75.6TB/day`。
4. 解析与索引后放大系数按 1.8 估算，热层约 `136TB/day`。
5. 热保留 3 天：`408TB`；温层 14 天压缩后约 `1.2PB`；冷层归档对象存储。
6. 结论：必须时间分片 + ILM + 采样，否则成本不可控。

## 6. 架构（简版+完整版）
### 6.1 简版
`Service Logs -> Shipper -> Kafka -> Indexer -> Search Cluster -> Alert`

### 6.2 完整版
1. Agent 层：Fluent Bit/Vector 收集容器 stdout 与文件日志。
2. Queue 层：Kafka 解耦采集与索引写入。
3. Processing 层：解析、脱敏、字段规范、trace 关联。
4. Index 层：OpenSearch/Elasticsearch 按时间分片写入。
5. Query 层：检索 API、聚合 API、Saved Query。
6. Alert 层：规则引擎 + 报警通道（钉钉/Slack/Pager）。
7. Storage 层：热温冷分层（SSD/HDD/Object Storage）。
8. Governance：字段模板、保留策略、审计权限。

## 7. API 设计（请求/响应/错误码/幂等）
### 7.1 日志查询
`POST /api/log/v1/search`

请求：
```json
{
  "from": "2026-02-24T10:00:00Z",
  "to": "2026-02-24T10:05:00Z",
  "query": "level:ERROR AND service:payment",
  "page": 1,
  "size": 100
}
```

响应：
```json
{
  "tookMs": 420,
  "total": 1234,
  "hits": [{"ts":"...","service":"payment","msg":"timeout","traceId":"t1"}]
}
```

### 7.2 告警规则创建
`POST /api/log/v1/alerts`

### 7.3 回放重建索引
`POST /api/log/v1/reindex`

错误码：
1. `400_INVALID_TIME_RANGE`
2. `429_QUERY_RATE_LIMITED`
3. `503_INDEX_CLUSTER_DEGRADED`
4. `409_RULE_CONFLICT`

幂等规则：
1. `reindex` 任务用 `requestId` 幂等，避免重复重建。
2. 告警规则名在同租户内唯一。

## 8. 数据模型（实体/索引/分片）
1. `raw_log(event_id, ts, host, service, level, msg, trace_id, attrs)`。
2. `parsed_log(event_id, ts, service, level, keyword_tokens, trace_id, env, region)`。
3. `alert_rule(rule_id, owner, query, threshold, window_sec, status)`。
4. `alert_event(rule_id, trigger_ts, value, severity, handled_by)`。
5. `reindex_task(task_id, index_pattern, from, to, status)`。

索引与分片策略：
1. 时间分片：`logs-YYYY.MM.DD`。
2. 热索引按写入量设置主分片（如 24 shards/day）。
3. 高基数字段（userId）默认 `keyword` 限制长度，避免爆炸。
4. traceId 建倒排索引，支持链路快速定位。

## 9. 核心流程（正常/高峰/故障恢复）
### 9.1 正常流程
1. Agent 收集日志并打包发送 Kafka。
2. Processor 做解析、脱敏、字段增强。
3. Indexer 批量写入索引，查询与告警同步可用。

### 9.2 高峰流程
1. 流量突增时先保护采集队列（磁盘缓冲）。
2. Indexer 启用批量写优化和低优先级日志采样。
3. 查询层对重聚合请求限流，保障故障排查查询优先。

### 9.3 故障恢复流程
1. 索引集群写入失败时，Kafka 积压并告警。
2. 恢复后按 offset 回补写入，保证日志不丢。
3. 若模板错误导致字段冲突，触发 reindex 修复任务。

## 10. 一致性与事务边界
1. 日志平台接受最终一致，核心目标是“尽量不丢”和“可追溯补写”。
2. 采集到 Kafka 成功即视为进入可靠边界。
3. Kafka -> Index 为至少一次语义，依赖 `event_id` 去重。
4. 告警状态与日志写入分离，告警失败可补发不影响日志入库。
5. 合规删除请求需在索引层与归档层双执行并审计。

## 11. 可用性与容错（含 RTO/RPO）
1. Kafka 多副本，Agent 本地缓冲防网络抖动。
2. 索引集群多节点分区，副本保障查询可用。
3. Query 网关限流+熔断，防止大查询拖垮集群。
4. RTO：日志查询能力 15 分钟内恢复。
5. RPO：采集边界后目标接近 0；Agent 本地缓冲窗口内可补。

## 12. 可观测性（指标+阈值+处置动作）
1. `ingest_success_rate` < 99.9%（5 分钟）：排查 agent/queue 网络。
2. `kafka_log_lag` > 200 万（10 分钟）：扩容 indexer 并降采样非核心日志。
3. `search_p95_ms` > 3000ms（5 分钟）：限制重聚合查询并扩容 query 节点。
4. `index_reject_rate` > 1%：检查 shard 压力与批量写参数。
5. `alert_delay_p95_ms` > 30000：优先保障告警规则执行队列。
6. `field_cardinality_topN` 超阈：触发字段治理（降维/禁索引）。

## 13. 安全与合规
1. 采集侧敏感字段脱敏（手机号、证件号、token）。
2. 查询权限按租户/服务分级（RBAC + 字段级权限）。
3. 高敏日志访问全审计，支持事后追溯。
4. 日志传输链路加密（TLS）。
5. 数据保留与删除策略符合合规（如 30/90/180 天分级）。

## 14. 成本与取舍
1. 全量索引查询快但极贵；冷热分层更经济。
2. 更多副本提高可用性但增加存储成本。
3. 全字段索引提升灵活性但放大写入和存储。
4. 取舍建议：核心字段强索引、长尾字段按需索引。

## 15. Java 关键代码（>=5段）
### 15.1 采集事件状态转移（核心算法）
```java
public IngestResult ingest(LogEvent e) {
    if (!validator.valid(e)) return IngestResult.reject("invalid");
    if (!queueProducer.send(e)) return IngestResult.retryable("queue_fail");
    return IngestResult.accepted(e.eventId());
}
```

### 15.2 幂等去重（event_id）
```java
public boolean deduplicateAndIndex(ParsedLog log) {
    String idemKey = "log:idem:" + log.eventId();
    if (!idemRepo.setNx(idemKey, "1", Duration.ofHours(24))) {
        return false;
    }
    indexRepo.bulkInsert(log);
    return true;
}
```

### 15.3 重试退避/失败处理
```java
public void handleIndexFail(ParsedLog log, int attempt) {
    if (attempt >= 5) {
        dlqRepo.save(log.eventId(), log.raw(), "index_failed");
        return;
    }
    long delayMs = Math.min(3000, (1L << attempt) * 100L);
    retryScheduler.enqueue(log, delayMs + ThreadLocalRandom.current().nextLong(0, 60));
}
```

### 15.4 一致性边界（Outbox for alert event）
```java
@Transactional
public void persistAndEmitAlert(AlertEvent event) {
    alertRepo.insert(event);                // 状态落库
    outboxRepo.insert("ALERT_TRIGGERED", event.id()); // 事件同事务写
}
```

### 15.5 观测触发/回滚判定
```java
public void guardClusterHealth() {
    double rejectRate = metrics.gauge("index_reject_rate").value();
    if (rejectRate > 0.01) {
        samplingSwitch.enable("non_critical_info_log");
        alerting.fire("INDEX_REJECT_SPIKE", "rate=" + rejectRate);
    }
    long lag = metrics.gauge("kafka_log_lag").longValue();
    if (lag > 2_000_000) {
        scaler.scaleOut("indexer");
    }
}
```

## 16. 前端功能代码（React JS，仅 API 协作）
### 16.1 日志查询 Hook（loading/error/done）
```javascript
import { useState } from "react";

export function useLogSearch() {
  const [state, setState] = useState({ phase: "idle", data: null, error: "" });

  async function search(params) {
    setState({ phase: "loading", data: null, error: "" });
    try {
      const res = await fetch("/api/log/v1/search", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(params)
      });
      if (!res.ok) throw new Error(`HTTP_${res.status}`);
      const json = await res.json();
      setState({ phase: "done", data: json, error: "" });
    } catch (e) {
      setState({ phase: "error", data: null, error: String(e.message || e) });
    }
  }

  return { state, search };
}
```

### 16.2 Reindex 触发（幂等键 + 失败重试）
```javascript
export async function triggerReindex(indexPattern, from, to) {
  const requestId = `reindex-${Date.now()}-${Math.random().toString(16).slice(2)}`;
  let delay = 200;
  for (let i = 0; i < 3; i++) {
    try {
      const res = await fetch("/api/log/v1/reindex", {
        method: "POST",
        headers: { "Content-Type": "application/json", "X-Idempotency-Key": requestId },
        body: JSON.stringify({ indexPattern, from, to, requestId })
      });
      if (!res.ok) throw new Error(`HTTP_${res.status}`);
      return { ok: true };
    } catch (err) {
      if (i === 2) return { ok: false, error: String(err.message || err) };
      await new Promise((r) => setTimeout(r, delay));
      delay = Math.min(delay * 2, 1200);
    }
  }
}
```

## 17. 测试策略
1. 单元测试：日志解析规则、字段脱敏、去重逻辑。
2. 集成测试：采集->队列->索引->查询全链路。
3. 压测：写入洪峰、查询洪峰、混合负载。
4. 故障测试：Kafka 积压、索引拒写、模板冲突、节点故障。
5. 回归测试：告警误报漏报率、reindex 成功率。

## 18. 丰富例子（>=10）
1. 错误日志突增触发 P1 告警并自动附带 top traceId。
2. 某服务日志格式变更导致解析失败，落入坏消息队列。
3. Kafka 短暂不可达时 Agent 本地缓冲接管。
4. 写入压力过高触发非关键日志采样。
5. 某字段高基数导致索引膨胀，被策略转为 `non-indexed`。
6. 值班通过 traceId 5 秒内定位到超时下游服务。
7. 某天索引模板错误导致字段冲突，reindex 修复。
8. 大查询拖慢集群后，查询网关限流保护核心检索。
9. 合规删除请求触发热层与冷层双删除流程。
10. 热数据 3 天后自动转温层，成本显著下降。
11. 告警规则误配置触发风暴，启用抑制策略快速止血。
12. 归档恢复用于事故复盘，重建特定时间窗口索引。

## 19. 面试追问 + 可复述回答
1. 为什么日志平台要先上 Kafka？
回答：解耦采集与索引，保障写入洪峰下不丢日志并可回补。
2. 如何平衡检索速度和成本？
回答：热温冷分层 + 关键字段索引 + 非关键字段按需检索。
3. 如何避免高基数字段拖垮索引？
回答：字段治理、限制映射、禁索引或降维处理。
4. 告警为什么会漏？
回答：规则窗口、数据延迟、采样策略都会影响，需要质量监控校正。
5. Q42 和 Q41 的关系？
回答：Q41 是通用数据管道母题，Q42 是日志场景下的检索与告警特化。

## 20. 新手学习路线
1. 先搭最小链路：Agent -> Kafka -> Index -> Search。
2. 增加结构化解析与字段模板治理。
3. 实现基础告警和告警抑制策略。
4. 加入 ILM 与冷热分层控制成本。
5. 做故障演练：积压、拒写、查询雪崩、reindex 恢复。

## 21. 上场前 Checklist
1. 能讲清采集、索引、查询、告警四条主链路。
2. 能量化写入吞吐、查询延迟、告警延迟目标。
3. 能说出至少 3 个关键阈值与动作。
4. 能解释日志一致性边界和补写策略。
5. 能讲清高基数字段治理方法。
6. 能区分 Q42 与母题 Q41 的侧重点。

## 22. 与母题差异（对应母题/共性/差异/新增知识/话术）
### 22.1 对应母题
Q41 Data Pipeline。

### 22.2 共性能力
1. 都依赖采集解耦、异步处理、可观测治理。
2. 都需要处理延迟、重试、回放与质量问题。
3. 都强调容量估算和故障恢复闭环。

### 22.3 关键差异
1. Q41 是通用数据加工链路；Q42 聚焦日志检索与告警场景。
2. Q41 更强调数据建模分层（ODS/DWD/DWS）；Q42 更强调索引模板和检索性能。
3. Q42 对高基数字段和全文检索成本更敏感。
4. Q42 需要近实时故障定位能力，查询尾延迟要求更苛刻。
5. Q42 的告警联动和值班流程是核心评分点。

### 22.4 本题新增知识点（>=5）
1. 日志索引模板与字段映射治理。
2. 高基数字段膨胀控制。
3. ILM 热温冷生命周期策略。
4. 检索限流与查询隔离。
5. traceId 关联的故障排查路径。
6. reindex 运维与索引修复流程。

### 22.5 面试差异话术
“如果问 Q41，我先讲通用数据管道；如果问 Q42，我会重点讲日志场景下的索引检索、告警联动和成本治理，这是日志平台的独特难点。”

---

## 单题自审（Q42）
### A. 完整性检查
1. 22 节完整：通过。
2. Java 代码段 5 段：通过。
3. React JS API 协作代码 2 段：通过。

### B. 易懂性检查
1. 术语白话 >=10：通过。
2. 正常/高峰/故障流程完整：通过。

### C. 专属性检查
1. 聚焦日志采集/索引/检索/告警，不泛化成通用 ETL：通过。
2. 包含索引与字段治理等日志专属点：通过。

### D. 工程落地检查
1. 指标阈值+处置动作齐全：通过。
2. RTO/RPO 与 reindex 恢复路径明确：通过。

### E. 代码相关性检查
1. Java 五类点位覆盖：通过。
2. 前端 API 协作满足状态流转和重试幂等：通过。

### F. 母题差异检查
1. 与 Q41 对比具体，不模板化：通过。

### 自评分（100）
1. 完整性：20/20
2. 易懂性：19/20
3. 面试可讲性：19/20
4. 技术深度：19/20
5. 工程落地性：19/20

总分：96/100（通过）
