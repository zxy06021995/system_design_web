# 文件管理系统设计（含断点续传、跨平台同步、去重等核心功能）

# 一、系统核心功能概述

本文件管理系统聚焦大文件高效处理，支持多端协同，核心解决大文件上传下载耗时、跨设备同步不一致、多用户存储冗余、文件冲突等痛点，适配个人及小型团队使用场景。

核心功能清单（均含前后端完整逻辑）：

1. **大文件断点续传**：上传/下载中断后可恢复，无需重复传输，支持Gzip压缩减少带宽消耗

2. **跨平台同步**：基于SSE Push模型，多设备（手机/电脑）实时同步文件状态，自动触发更新

3. **文件冲突处理**：多设备同时修改同一文件时，保存两者版本（创建冲突副本），支持手动合并

4. **状态回滚**：记录文件全生命周期操作日志，支持回滚至任意历史版本，避免误操作丢失数据

5. **数据去重**：多用户上传相同文件时，仅存储1份原始文件（Blob），大幅降低存储成本

6. **冷热数据分离**：按访问频率自动迁移数据至对应存储介质，平衡性能与成本

技术选型：后端（Java + SpringBoot）、前端（JS + HTML5）、存储（MongoDB + Blob存储）、通信（SSE + RESTful API）。

# 二、核心功能详细设计（含前后端代码）

## 1. 文件上传流程（含断点续传/压缩）

**通俗逻辑**：前端将大文件拆分小分片（chunk），压缩后逐个上传，后端校验分片完整性，全部上传完成后合并校验，同时支持中断后恢复上传（仅传缺失分片）。

### 1.1 前后端流程拆解

1. 前端预处理：将文件按固定大小（如5MB）切分chunk，计算每个chunk的MD5值、文件整体MD5值及文件大小，对chunk进行Gzip压缩。

2. 去重校验：前端调用去重API，携带文件MD5和大小，后端判断文件是否已存在（避免重复上传）。

3. 初始化元数据：若文件未存在，前端调用创建文件元数据API，后端生成唯一文件ID和上传ID，记录文件基础信息（状态为“上传中”）。

4. 查询已上传分片：前端调用查询分片API，后端返回已上传的chunk索引，前端确定缺失chunk。

5. 分片上传：前端获取每个缺失chunk的预签名上传URL，并行上传压缩后的chunk，上传完成后记录已上传索引。

6. 上传完成校验：所有chunk上传完成后，前端通知后端，后端逐个校验chunk的存在性和MD5，合并chunk后校验文件整体MD5。

7. 更新状态：校验通过后，后端更新文件元数据状态为“上传完成”，新增去重记录，推送文件更新事件（供跨平台同步）。

### 1.2 前端JS代码（核心逻辑）

```Java

// 1. 文件预处理（拆分+压缩+MD5计算）
async function handleFileUpload(file) {
  const CHUNK_SIZE = 5 * 1024 * 1024; // 5MB每片
  const chunks = [];
  const chunkMd5s = [];
  // 拆分文件
  for (let i = 0; i < file.size; i += CHUNK_SIZE) {
    const chunk = file.slice(i, i + CHUNK_SIZE);
    chunks.push(chunk);
  }
  // 计算每个chunk的MD5 + 压缩
  for (let i = 0; i < chunks.length; i++) {
    const chunk = chunks[i];
    const md5 = await calculateMd5(chunk); // 自定义MD5计算方法
    chunkMd5s.push(md5);
    // Gzip压缩chunk（减少带宽）
    const compressedChunk = await gzipCompress(chunk); // 自定义压缩方法
    chunks[i] = compressedChunk;
  }
  // 计算文件整体MD5
  const fileMd5 = await calculateFileMd5(file);
  // 执行后续上传流程
  await uploadFileProcess(file.name, file.size, fileMd5, chunks, chunkMd5s);
}

// 2. 断点续传核心流程
async function uploadFileProcess(fileName, fileSize, fileMd5, chunks, chunkMd5s) {
  const ownerId = getCurrentUserId(); // 获取当前用户ID
  // 步骤1：去重校验
  const dedupRes = await fetch('/api/file/dedup/check', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ fileMd5, fileSize, ownerId })
  }).then(res => res.json());
  // 若已存在，直接关联，无需上传
  if (dedupRes.isDuplicate) {
    await associateExistingFile(dedupRes.existFileId, fileName, fileMd5, ownerId);
    alert('文件已存在，无需重复上传');
    return;
  }

  // 步骤2：创建文件元数据（获取fileId和uploadId）
  const createRes = await fetch('/api/file/create', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      fileName, fileSize, mimeType: file.type,
      totalChunks: chunks.length, fileMd5, ownerId,
      contentEncoding: 'gzip' // 标记压缩方式
    })
  }).then(res => res.json());
  const { fileId, uploadId } = createRes;

  // 步骤3：查询已上传的chunk（断点续传核心）
  const queryRes = await fetch(`/api/file/chunk/query/${fileId}?uploadId=${uploadId}`, {
    headers: { 'ownerId': ownerId }
  }).then(res => res.json());
  const { missingChunks } = queryRes; // 缺失的chunk索引

  // 步骤4：上传缺失的chunk（并行上传，提升效率）
  const uploadPromises = missingChunks.map(async (index) => {
    // 获取预签名上传URL
    const urlRes = await fetch(`/api/file/chunk/pre-signed-url?fileId=${fileId}&chunkIndex=${index}`, {
      headers: { 'ownerId': ownerId }
    }).then(res => res.json());
    // 上传chunk（PUT请求，携带chunk信息）
    await fetch(urlRes.url, {
      method: 'PUT',
      body: chunks[index],
      headers: { 'Content-Encoding': 'gzip', 'Chunk-Md5': chunkMd5s[index] }
    });
    return index;
  });
  await Promise.all(uploadPromises); // 等待所有缺失chunk上传完成

  // 步骤5：通知后端上传完成，触发校验
  await fetch('/api/file/chunk/upload/complete', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({
      fileId, uploadId, completedChunkIndexes: [...missingChunks],
      chunkMd5s, fileMd5, ownerId
    })
  });
  alert('文件上传完成');
}

// 辅助方法：计算文件/分片MD5（简化版）
function calculateMd5(blob) {
  return new Promise((resolve) => {
    const reader = new FileReader();
    reader.onload = (e) => {
      const hash = CryptoJS.MD5(CryptoJS.enc.Latin1.parse(e.target.result)).toString();
      resolve(hash);
    };
    reader.readAsArrayBuffer(blob);
  });
}
```

### 1.3 后端Java代码（核心服务+接口）

```java

// 1. 上传完成处理服务（核心，负责校验+合并+状态更新）
@Service
public class FileUploadCompleteService {
    @Autowired
    private FileMetadataService metadataService;
    @Autowired
    private FileVerifyService verifyService;
    @Autowired
    private FileDedupService dedupService;
    @Autowired
    private StateManagementService stateService;
    @Autowired
    private MongoTemplate mongoTemplate;

    public UploadCompleteResponse handleUploadComplete(FileUploadCompleteRequest request) {
        try {
            // 1. 基础校验（文件存在性+归属权）
            FileMetadata metadata = mongoTemplate.findById(request.getFileId(), FileMetadata.class);
            if (metadata == null || !metadata.getOwnerId().equals(request.getOwnerId())) {
                return new UploadCompleteResponse(false, "无文件访问权限", "FAILED");
            }

            // 2. 校验：缺失chunk检查 + 分片MD5校验
            List<Integer> missingChunks = calculateMissingChunks(request.getCompletedChunkIndexes(), metadata.getTotalChunks());
            if (!missingChunks.isEmpty()) {
                return new UploadCompleteResponse(false, "存在缺失分片，上传未完成", "FAILED");
            }
            // 校验每个chunk的MD5（通过预签名URL下载校验）
            List<String> chunkUrls = metadata.getChunkUrls();
            for (int i = 0; i < chunkUrls.size(); i++) {
                boolean isVerified = verifyService.verifyChunk(chunkUrls.get(i), request.getChunkMd5s().get(i));
                if (!isVerified) {
                    return new UploadCompleteResponse(false, "分片" + i + "损坏，MD5校验失败", "FAILED");
                }
            }
            // 校验整个文件的MD5（合并分片后校验）
            boolean fileVerified = verifyService.verifyFile(request.getFileId(), chunkUrls, request.getFileMd5());
            if (!fileVerified) {
                return new UploadCompleteResponse(false, "文件合并后损坏，MD5校验失败", "FAILED");
            }

            // 3. 验证通过：更新元数据+记录去重信息
            metadata.setStatus("COMPLETED");
            metadata.setUpdateTime(new Date());
            metadata.setLastAccessTime(new Date());
            mongoTemplate.save(metadata);
            // 新增去重记录
            dedupService.addDedupRecord(request.getFileMd5(), request.getFileId(), metadata.getFileSize());

            // 4. 推送文件更新事件（跨平台同步核心）
            stateService.publishEvent(request.getFileId(), "FILE_UPDATED", metadata.getVersion());

            return new UploadCompleteResponse(true, "上传成功", "COMPLETED");
        } catch (Exception e) {
            return new UploadCompleteResponse(false, "服务异常：" + e.getMessage(), "FAILED");
        }
    }

    // 计算缺失的chunk索引
    private List<Integer> calculateMissingChunks(List<Integer> completed, int total) {
        return IntStream.range(0, total)
                .boxed()
                .filter(index -> !completed.contains(index))
                .collect(Collectors.toList());
    }
}

// 2. 验证服务（MD5+存在性校验）
@Service
public class FileVerifyService {
    @Autowired
    private BlobStorageClient blobStorageClient;

    // 验证单个Chunk
    public boolean verifyChunk(String chunkUrl, String expectedMd5) throws Exception {
        // 1. 校验Chunk是否存在
        if (!blobStorageClient.exists(chunkUrl)) {
            return false;
        }
        // 2. 下载Chunk并计算MD5
        byte[] chunkBytes = blobStorageClient.download(chunkUrl);
        String actualMd5 = DigestUtils.md5DigestAsHex(chunkBytes);
        // 3. 对比MD5
        return actualMd5.equalsIgnoreCase(expectedMd5);
    }

    // 验证整个文件
    public boolean verifyFile(String fileId, List<String> chunkUrls, String expectedFileMd5) throws Exception {
        // 1. 合并所有Chunk
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        for (String url : chunkUrls) {
            byte[] chunkBytes = blobStorageClient.download(url);
            // 解压（上传时压缩了）
            byte[] decompressedBytes = decompressChunk(chunkBytes);
            outputStream.write(decompressedBytes);
        }
        // 2. 计算文件MD5
        String actualFileMd5 = DigestUtils.md5DigestAsHex(outputStream.toByteArray());
        // 3. 对比MD5
        return actualFileMd5.equalsIgnoreCase(expectedFileMd5);
    }

    // 解压Gzip数据
    private byte[] decompressChunk(byte[] compressedBytes) throws IOException {
        try (GZIPInputStream gzipIs = new GZIPInputStream(new ByteArrayInputStream(compressedBytes));
             ByteArrayOutputStream bos = new ByteArrayOutputStream()) {
            byte[] buffer = new byte[1024];
            int len;
            while ((len = gzipIs.read(buffer)) != -1) {
                bos.write(buffer, 0, len);
            }
            return bos.toByteArray();
        }
    }
}

// 3. 状态管理服务 - Push模型（SSE推送）
@Service
@RestController
@RequestMapping("/api/state")
public class StateManagementService {
    // 存储订阅关系：ownerId_deviceId -> SSE发射器
    private final Map<String, SseEmitter> emitters = new ConcurrentHashMap<>();
    @Autowired
    private MongoTemplate mongoTemplate;

    // 客户端订阅接口（建立SSE连接）
    @GetMapping("/subscribe")
    public SseEmitter subscribe(@RequestParam String ownerId, @RequestParam String deviceId,
                                @RequestHeader String Authorization) {
        // 30分钟超时，避免无效连接
        SseEmitter emitter = new SseEmitter(30 * 60 * 1000L);
        String key = ownerId + "_" + deviceId;
        emitters.put(key, emitter);

        // 连接关闭时移除
        emitter.onCompletion(() -> emitters.remove(key));
        emitter.onError(e -> emitters.remove(key));

        // 返回历史未处理事件
        sendHistoryEvents(emitter, ownerId);
        return emitter;
    }

    // 发布事件（文件上传/修改后调用）
    public void publishEvent(String fileId, String eventType, int version) {
        // 1. 记录事件日志（用于回滚）
        FileEventLog event = new FileEventLog();
        event.setFileId(fileId);
        event.setEventType(eventType);
        event.setEventOffset(generateOffset()); // 自增偏移量
        event.setEventData(Map.of("version", version));
        event.setOwnerId(getFileOwner(fileId));
        event.setTimestamp(new Date());
        mongoTemplate.save(event);

        // 2. 推送事件给所有订阅的客户端（跨平台同步）
        String ownerId = event.getOwnerId();
        emitters.keySet().stream()
                .filter(key -> key.startsWith(ownerId + "_"))
                .forEach(key -> {
                    SseEmitter emitter = emitters.get(key);
                    try {
                        emitter.send(SseEmitter.event()
                                .name(eventType)
                                .data(event)
                                .id(String.valueOf(event.getEventOffset())));
                    } catch (IOException e) {
                        emitter.completeWithError(e);
                    }
                });
    }

    // 辅助：获取文件所有者
    private String getFileOwner(String fileId) {
        FileMetadata metadata = mongoTemplate.findById(fileId, FileMetadata.class);
        return metadata != null ? metadata.getOwnerId() : "";
    }

    // 辅助：发送历史事件
    private void sendHistoryEvents(SseEmitter emitter, String ownerId) {
        List<FileEventLog> events = mongoTemplate.find(
                Query.query(Criteria.where("ownerId").is(ownerId))
                        .sort(Sort.by(Sort.Direction.ASC, "timestamp"))
                        .limit(100), // 最多返回100条历史
                FileEventLog.class
        );
        events.forEach(event -> {
            try {
                emitter.send(SseEmitter.event().data(event));
            } catch (IOException e) {
                emitter.completeWithError(e);
            }
        });
    }

    // 生成事件偏移量（自增）
    private int generateOffset() {
        FileEventOffset offset = mongoTemplate.findById("global_offset", FileEventOffset.class);
        if (offset == null) {
            offset = new FileEventOffset("global_offset", 1);
        } else {
            offset.setOffset(offset.getOffset() + 1);
        }
        mongoTemplate.save(offset);
        return offset.getOffset();
    }
}
```

### 1.4 核心API汇总

- POST /api/file/dedup/check：文件去重校验，参数（fileMd5、fileSize、ownerId），返回是否重复及已存在文件ID

- POST /api/file/create：创建文件元数据，参数（fileName、fileSize、mimeType等），返回fileId、uploadId

- GET /api/file/chunk/query/{fileId}：查询已上传分片，参数（uploadId、ownerId），返回缺失分片索引

- GET /api/file/chunk/pre-signed-url：获取分片预签名上传URL，参数（fileId、chunkIndex、ownerId）

- POST /api/file/chunk/upload/complete：通知后端上传完成，触发校验，参数（fileId、uploadId等）

- GET /api/state/subscribe：客户端订阅SSE事件，参数（ownerId、deviceId、Authorization），建立长连接

### 1.5 涉及数据库集合

- file_metadata：存储文件核心元数据（fileId、fileName、存储类型、分片URL等），核心字段与FileMetadata实体类对应

- file_dedup：存储文件去重记录（fileMd5、fileSize、引用计数等），用于多用户同文件复用

- file_event_log：记录文件操作事件（上传、更新等），用于跨平台同步和状态回滚

- file_event_offset：存储事件自增偏移量，确保事件顺序性

### 1.6 示例场景（清晰易懂）

**场景1：首次上传（含断点续传）**

用户A在电脑上传100MB「项目视频.mp4」，流程如下：

1. 前端：切分为20个5MB chunk，压缩后计算每个chunk和文件整体MD5，调用去重API（返回“未存在”）。

2. 后端：创建文件元数据（fileId=uuid123），返回fileId和uploadId。

3. 前端：查询已上传分片（为空），并行上传20个chunk，全部上传完成后通知后端。

4. 后端：校验所有chunk和文件整体MD5，更新状态为“完成”，推送更新事件，新增去重记录。

5. 断点续传补充：若中途关闭浏览器，重新上传时，前端查询已上传分片（假设已传17个），仅上传剩余3个，无需重复传输。

**场景2：文件已存在（去重关联）**

用户B上传相同的100MB「项目视频.mp4」（MD5和大小一致），流程如下：

1. 前端：预处理后调用去重API，后端查询到已存在（用户A上传的uuid123），返回“已存在”和existFileId。

2. 前端：调用关联API，后端为用户B创建新元数据（fileId=uuid789），复用uuid123的分片资源。

3. 完成上传：无需上传任何分片，用户B的文件列表显示该文件，服务器仅存储1份原始分片，节省存储。

## 2. 文件下载流程（含断点续传/压缩解压）

**通俗逻辑**：客户端通过Push事件得知文件更新，获取元数据后查询本地已下载分片，仅下载缺失部分，校验MD5后合并解压，完成下载。

### 2.1 前后端流程拆解

1. 客户端：通过SSE订阅接收FILE_UPDATED事件，触发下载。

2. 前端：调用元数据API，获取fileId、chunkUrls、chunkMD5等核心信息。

3. 前端：查询本地已下载分片，对比元数据，确定缺失分片。

4. 前端：并行下载缺失分片，逐个校验MD5，避免损坏。

5. 前端：合并所有分片，Gzip解压，保存到本地并更新本地记录。

### 2.2 前端JS代码（核心逻辑）

```Java

// 1. 订阅文件更新事件（Push模型核心）
function subscribeFileEvents(userId, userToken, deviceId) {
  // 建立SSE连接
  const eventSource = new EventSource(
    `/api/state/subscribe?ownerId=${userId}&deviceId=${deviceId}`,
    { headers: { 'Authorization': `Bearer ${userToken}` } }
  );

  // 监听文件更新事件，触发下载
  eventSource.addEventListener('FILE_UPDATED', async (e) => {
    const eventData = JSON.parse(e.data);
    const { fileId } = eventData;
    await downloadFile(fileId, userId, userToken);
  });

  // 错误重试机制
  eventSource.onerror = (error) => {
    console.error('订阅失败，重试中...', error);
    eventSource.close();
    setTimeout(() => subscribeFileEvents(userId, userToken, deviceId), 5000);
  };
}

// 2. 断点续传下载核心逻辑
async function downloadFile(fileId, userId, userToken) {
  // 步骤1：获取文件元数据（含分片URL、MD5等）
  const metaRes = await fetch(`/api/file/metadata/${fileId}`, {
    headers: { 'Authorization': `Bearer ${userToken}` }
  }).then(res => res.json());
  const { fileName, mimeType, chunkUrls, chunkMd5Map, totalChunks, contentEncoding } = metaRes;

  // 步骤2：查询本地已下载分片（localStorage存储）
  const localKey = `file_chunks_${fileId}`;
  const localChunks = JSON.parse(localStorage.getItem(localKey) || '[]');
  // 计算缺失分片索引
  const missingChunks = [];
  for (let i = 0; i < totalChunks; i++) {
    if (!localChunks.includes(i)) missingChunks.push(i);
  }

  if (missingChunks.length === 0) {
    alert('文件已完整下载');
    return;
  }

  // 步骤3：并行下载缺失分片，逐个校验MD5
  const downloadPromises = missingChunks.map(async (index) => {
    const chunkUrl = chunkUrls[index];
    const expectedMd5 = chunkMd5Map[index];
    // 下载分片
    const response = await fetch(chunkUrl, {
      headers: { 'Authorization': `Bearer ${userToken}` }
    });
    const blob = await response.blob();
    // MD5校验，避免分片损坏
    const actualMd5 = await calculateMd5(blob);
    if (actualMd5 !== expectedMd5) {
      throw new Error(`Chunk ${index} 损坏，MD5不匹配`);
    }
    return { index, blob };
  });
  const downloadedChunks = await Promise.all(downloadPromises);

  // 步骤4：合并分片并解压（上传时压缩过）
  downloadedChunks.sort((a, b) => a.index - b.index); // 按索引排序
  const mergedBlob = new Blob(downloadedChunks.map(c => c.blob), { 
    type: contentEncoding === 'gzip' ? 'application/gzip' : mimeType 
  });
  // Gzip解压
  let finalBlob = mergedBlob;
  if (contentEncoding === 'gzip') {
    const arrayBuffer = await blobToArrayBuffer(mergedBlob);
    const decompressedBytes = pako.ungzip(arrayBuffer);
    finalBlob = new Blob([decompressedBytes], { type: mimeType });
  }

  // 步骤5：保存文件到本地，更新本地记录
  saveBlobToLocal(finalBlob, fileName);
  const newLocalChunks = [...localChunks, ...missingChunks];
  localStorage.setItem(localKey, JSON.stringify(newLocalChunks));
}

// 辅助：保存Blob到本地（下载完成）
function saveBlobToLocal(blob, fileName) {
  const url = URL.createObjectURL(blob);
  const a = document.createElement('a');
  a.href = url;
  a.download = fileName;
  document.body.appendChild(a);
  a.click();
  document.body.removeChild(a);
  URL.revokeObjectURL(url);
}
```

### 2.3 后端Java代码（元数据接口，核心支撑）

```java

// 元数据查询接口（下载流程核心后端接口）
@RestController
@RequestMapping("/api/file")
public class FileMetadataController {
    @Autowired
    private FileMetadataService metadataService;
    @Autowired
    private FileHotColdService hotColdService; // 关联冷热分离服务
    @Autowired
    private MongoTemplate mongoTemplate;

    /**
     * 获取文件元数据（供前端下载使用）
     * 支持冷热数据透明迁移，前端无感知
     */
    @GetMapping("/metadata/{fileId}")
    public ResponseEntity<FileMetadataResponse> getFileMetadata(
            @PathVariable String fileId,
            @RequestHeader String ownerId,
            @RequestHeader("Authorization") String authorization) {
        // 1. 基础权限校验（验证文件归属）
        FileMetadata metadata = mongoTemplate.findById(fileId, FileMetadata.class);
        if (metadata == null || !metadata.getOwnerId().equals(ownerId)) {
            return ResponseEntity.status(HttpStatus.FORBIDDEN)
                    .body(new FileMetadataResponse(false, "无文件访问权限", null));
        }

        // 2. 冷数据校验：若为冷数据，自动迁回热存储（前端无感知）
        if ("COLD".equals(metadata.getStorageType())) {
            hotColdService.migrateColdToHot(fileId);
            // 迁移后重新查询最新元数据
            metadata = mongoTemplate.findById(fileId, FileMetadata.class);
        }

        // 3. 组装响应数据，适配前端下载需求
        FileMetadataResponse response = new FileMetadataResponse();
        response.setSuccess(true);
        FileMetadataDTO dto = new FileMetadataDTO();
        dto.setFileId(metadata.getFileId());
        dto.setFileName(metadata.getFileName());
        dto.setMimeType(metadata.getMimeType());
        dto.setTotalChunks(metadata.getTotalChunks());
        dto.setChunkUrls(metadata.getChunkUrls());
        dto.setChunkMd5Map(metadata.getChunkMd5Map());
        dto.setContentEncoding(metadata.getContentEncoding());
        dto.setVersion(metadata.getVersion());
        dto.setFileSize(metadata.getFileSize());
        response.setData(dto);

        // 4. 更新最后访问时间（用于冷热分离判断）
        metadata.setLastAccessTime(new Date());
        mongoTemplate.save(metadata);

        return ResponseEntity.ok(response);
    }

    // 响应DTO：适配前端下载所需元数据格式
    @Data
    public static class FileMetadataDTO {
        private String fileId;
        private String fileName;
        private String mimeType;
        private Long fileSize;
        private Integer totalChunks;
        private List<String> chunkUrls;
        private Map<Integer, String> chunkMd5Map;
        private String contentEncoding;
        private Integer version;
    }

    // 统一响应封装
    @Data
    public static class FileMetadataResponse {
        private boolean success;
        private String msg;
        private FileMetadataDTO data;

        public FileMetadataResponse() {}

        public FileMetadataResponse(boolean success, String msg, FileMetadataDTO data) {
            this.success = success;
            this.msg = msg;
            this.data = data;
        }
    }
}
```

### 2.4 核心API汇总

- GET /api/file/metadata/{fileId}：获取文件元数据（供下载使用），参数（ownerId、Authorization），返回分片URL、MD5等信息

- GET /api/state/subscribe：复用订阅接口，接收FILE_UPDATED事件，触发下载（与上传功能共用）

- PUT /{pre-signed-url}：通过预签名URL下载分片（无固定接口路径，URL由后端动态生成）

### 2.5 涉及数据库集合

- file_metadata：核心集合，下载时查询文件元数据、分片信息，同时更新最后访问时间

- file_event_log：接收事件时查询历史事件，确保未同步的文件能正常触发下载（与上传功能共用）

### 2.6 示例场景

用户A的手机已订阅状态事件，当电脑端完成「项目视频.mp4」上传后：

1. 手机端收到FILE_UPDATED事件，自动调用元数据API，获取分片URL、MD5等信息。

2. 查询本地发现未下载任何分片，并行下载20个分片，每个分片下载后校验MD5。

3. 所有分片下载完成后，合并、解压，保存为「项目视频.mp4」到手机本地。

4. 若下载中途断网，重新连接后，仅下载未完成的分片，实现断点续传。

## 3. 跨平台同步（基于Push模型）

**通俗逻辑**：多设备（手机/电脑）都订阅状态服务，当其中一个设备上传/修改文件后，服务端主动推送事件给所有设备，触发各设备下载更新，实现同步。

**核心依赖**：状态管理服务的SSE Push模型（已在上传/下载代码中实现），核心是“事件驱动”——服务端统一推送状态，客户端被动响应。

### 3.1 前后端流程拆解

1. 前端（多设备）：启动后建立SSE长连接，订阅文件状态事件（携带ownerId、deviceId）。

2. 前端（操作设备）：完成上传/修改后，等待服务端推送FILE_UPDATED事件，确认操作生效。

3. 后端：文件操作完成后，推送FILE_UPDATED事件至该用户的所有订阅设备。

4. 前端（其他设备）：接收事件，自动触发下载流程，同步最新文件。

5. 后端：若客户端连接异常，重新订阅时推送历史事件，确保同步不丢失。

### 3.2 核心API汇总

- GET /api/state/subscribe：核心订阅接口，多设备建立SSE长连接，参数（ownerId、deviceId、Authorization）

- （内部调用）publishEvent：后端服务内部方法，无需前端调用，用于推送各类事件（FILE_UPDATED等）

- GET /api/file/metadata/{fileId}：复用元数据接口，接收事件后触发查询，获取同步所需信息（与下载功能共用）

### 3.3 涉及数据库集合

- file_event_log：存储所有文件操作事件，重新订阅时查询历史事件，确保同步不丢失

- file_event_offset：维护事件自增偏移量，确保事件推送和接收的顺序性

- file_metadata：事件推送后，客户端查询该集合获取最新文件信息，完成同步

### 3.4 示例场景

用户A同时登录电脑端、手机端、pad端，三个设备均已订阅事件：

1. 电脑端上传「工作报告.docx」，后端完成校验后，推送FILE_UPDATED事件。

2. 手机端和pad端收到事件，自动触发下载流程，同步下载该文件。

3. 随后用户在手机端修改文档并提交，后端推送新的FILE_UPDATED事件。

4. 电脑端和pad端收到事件，自动下载修改后的分片，更新本地文件，实现三端同步。

关键提示：跨平台同步无需用户手动操作，全靠SSE事件驱动，前端自动响应，体验流畅。

## 4. 文件冲突处理（保存两者方案）

**通俗逻辑**：多设备同时修改同一版本文件时，不拒绝任何修改，为后提交的修改创建“冲突副本”（文件名加时间戳），让用户手动选择保留/合并。

### 4.1 前后端流程拆解

1. 前端：用户修改文件后，发起更新请求，携带fileId、客户端当前版本、修改后的分片信息。

2. 后端：校验文件归属权，对比客户端版本与服务端最新版本，判断是否冲突。

3. 无冲突（版本一致）：正常更新分片，更新版本号，推送FILE_UPDATED事件。

4. 有冲突（客户端版本<服务端版本）：创建冲突副本（新fileId），标记冲突标识，关联原始文件ID。

5. 后端：推送FILE_CONFLICT事件，前端显示冲突提示，提供副本和原文件对比入口。

6. 用户：对比后手动合并修改，重新提交更新，同步所有设备。

### 4.2 核心API汇总

- POST /api/file/update：文件修改提交接口，参数（fileId、clientVersion、chunkUpdates等），返回更新结果或冲突副本ID

- GET /api/state/subscribe：复用订阅接口，接收FILE_CONFLICT、FILE_UPDATED事件，提示冲突或同步更新

- GET /api/file/metadata/{fileId}：查询原文件和冲突副本的元数据，用于前端对比合并

### 4.3 涉及数据库集合

- file_metadata：存储原文件和冲突副本的元数据，副本标记conflictFlag=true，关联originalFileId

- file_event_log：记录FILE_CONFLICT、FILE_UPDATED事件，用于推送冲突提示和同步

### 4.4 示例场景

用户A的电脑端和手机端同时下载版本1的「会议纪要.txt」并修改：

1. 电脑端先提交修改，后端校验版本一致，更新为版本2，推送FILE_UPDATED事件。

2. 5分钟后，手机端提交修改（客户端版本仍为1），后端检测到冲突。

3. 后端自动创建冲突副本，文件名为「会议纪要(冲突202506011530).txt」，推送FILE_CONFLICT事件。

4. 所有设备显示冲突提示，用户打开原文件（版本2）和副本（版本1修改内容），手动合并后重新提交。

### 4.5 后端Java代码（冲突处理核心）

```java

// 文件修改服务 - 冲突处理（保存两者）
@Service
public class FileUpdateService {
    @Autowired
    private MongoTemplate mongoTemplate;
    @Autowired
    private BlobStorageClient blobStorageClient;
    @Autowired
    private StateManagementService stateService;

    public UpdateResponse updateFile(FileUpdateRequest request) {
        // 1. 基础校验（文件存在性+归属权）
        FileMetadata originalMetadata = mongoTemplate.findById(request.getFileId(), FileMetadata.class);
        if (originalMetadata == null) {
            return new UpdateResponse(false, "文件不存在", null);
        }

        // 2. 版本号对比：判断是否冲突
        if (request.getClientVersion() == originalMetadata.getVersion()) {
            // 无冲突：正常更新
            return updateNormal(originalMetadata, request);
        } else {
            // 有冲突：保存两者（创建冲突副本）
            return updateWithConflict(originalMetadata, request);
        }
    }

    // 无冲突：正常更新
    private UpdateResponse updateNormal(FileMetadata metadata, FileUpdateRequest request) {
        // 1. 处理修改的chunk（增量更新）
        List<String> newChunkUrls = updateChunks(metadata, request.getChunkUpdates());

        // 2. 更新元数据版本
        metadata.setChunkUrls(newChunkUrls);
        metadata.setVersion(metadata.getVersion() + 1);
        metadata.setUpdateTime(new Date());
        metadata.setLastAccessTime(new Date());
        mongoTemplate.save(metadata);

        // 3. 推送更新事件
        stateService.publishEvent(metadata.getFileId(), "FILE_UPDATED", metadata.getVersion());

        return new UpdateResponse(true, "更新成功", metadata.getFileId());
    }

    // 有冲突：创建副本
    private UpdateResponse updateWithConflict(FileMetadata originalMetadata, FileUpdateRequest request) {
        // 1. 创建冲突副本的元数据
        FileMetadata conflictMetadata = new FileMetadata();
        conflictMetadata.setFileId(UUID.randomUUID().toString()); // 新文件ID
        // 文件名加冲突时间戳，便于区分
        String conflictFileName = originalMetadata.getFileName() + "(冲突" +
                new SimpleDateFormat("yyyyMMddHHmmss").format(new Date()) + ")";
        conflictMetadata.setFileName(conflictFileName);
        conflictMetadata.setOwnerId(originalMetadata.getOwnerId());
        conflictMetadata.setMimeType(originalMetadata.getMimeType());
        conflictMetadata.setFileSize(originalMetadata.getFileSize());
        conflictMetadata.setStatus("COMPLETED");
        conflictMetadata.setVersion(1); // 副本版本从1开始
        conflictMetadata.setContentEncoding(originalMetadata.getContentEncoding());
        conflictMetadata.setConflictFlag(true); // 标记为冲突文件
        conflictMetadata.setOriginalFileId(originalMetadata.getFileId()); // 关联原始文件
        conflictMetadata.setCreateTime(new Date());
        conflictMetadata.setUpdateTime(new Date());
        conflictMetadata.setLastAccessTime(new Date());
        conflictMetadata.setStorageType("HOT"); // 冲突文件存热存储，便于访问

        // 2. 上传客户端修改的chunk，作为副本的分片
        List<String> conflictChunkUrls = uploadConflictChunks(conflictMetadata.getFileId(), request.getChunkUpdates());
        conflictMetadata.setChunkUrls(conflictChunkUrls);
        conflictMetadata.setChunkMd5Map(request.getChunkMd5Map());
        conflictMetadata.setFileMd5(request.getFileMd5());

        // 3. 保存副本元数据
        mongoTemplate.save(conflictMetadata);

        // 4. 推送冲突事件，通知所有设备
        stateService.publishEvent(conflictMetadata.getFileId(), "FILE_CONFLICT", 1);

        return new UpdateResponse(true, "存在冲突，已创建副本", conflictMetadata.getFileId());
    }

    // 辅助：上传冲突chunk（副本专用）
    private List<String> uploadConflictChunks(String fileId, List<ChunkUpdate> updates) {
        List<String> chunkUrls = new ArrayList<>();
        for (ChunkUpdate update : updates) {
            String chunkUrl = blobStorageClient.upload(
                    update.getChunkBytes(),
                    fileId + "_chunk_" + update.getChunkIndex(),
                    "application/gzip"
            );
            chunkUrls.add(chunkUrl);
        }
        return chunkUrls;
    }

    // 辅助：更新原始文件的chunk（无冲突时）
    private List<String> updateChunks(FileMetadata metadata, List<ChunkUpdate> updates) {
        List<String> oldChunkUrls = metadata.getChunkUrls();
        for (ChunkUpdate update : updates) {
            // 覆盖修改的chunk
            String newChunkUrl = blobStorageClient.upload(
                    update.getChunkBytes(),
                    metadata.getFileId() + "_chunk_" + update.getChunkIndex(),
                    "application/gzip"
            );
            oldChunkUrls.set(update.getChunkIndex(), newChunkUrl);
        }
        return oldChunkUrls;
    }
}
```

## 5. 状态回滚（避免误操作）

**通俗逻辑**：后端记录文件所有操作（上传/修改/删除分片）的事件日志，用户触发回滚时，按事件日志反向执行，支持回滚至任意历史版本。

**核心依赖**：文件事件日志集合（记录每一步操作）、事件偏移量（定位回滚节点），可选快照机制（提升回滚效率）。

### 5.1 核心API汇总

- POST /api/file/rollback：文件回滚接口，参数（fileId、targetOffset、ownerId），返回回滚结果和最新版本

- GET /api/file/event/log/{fileId}：（可选）查询文件所有操作事件，用于前端展示回滚节点（需自行扩展）

- GET /api/state/subscribe：复用订阅接口，接收FILE_ROLLED_BACK事件，同步回滚后的文件状态

### 5.2 涉及数据库集合

- file_event_log：核心集合，存储文件所有操作事件，回滚时反向执行事件日志

- file_metadata：回滚后更新文件元数据（分片URL、MD5、版本号等）

- file_event_offset：定位回滚节点，确保回滚至指定历史事件位置

### 5.3 后端Java代码（回滚核心）

```java

// 状态回滚服务
@Service
public class FileRollbackService {
    @Autowired
    private MongoTemplate mongoTemplate;
    @Autowired
    private StateManagementService stateService;
    @Autowired
    private BlobStorageClient blobStorageClient;

    // 核心回滚方法：根据目标事件偏移量，回滚文件至对应历史版本
    public RollbackResponse rollbackFile(FileRollbackRequest request) {
        try {
            // 1. 基础校验（文件存在性+归属权）
            FileMetadata metadata = mongoTemplate.findById(request.getFileId(), FileMetadata.class);
            if (metadata == null || !metadata.getOwnerId().equals(request.getOwnerId())) {
                return new RollbackResponse(false, "无文件访问权限", null, metadata.getVersion());
            }

            // 2. 校验目标偏移量合法性（不能大于当前最大偏移量，不能小于最小偏移量）
            List<FileEventLog> fileEvents = getFileAllEvents(request.getFileId());
            if (fileEvents.isEmpty()) {
                return new RollbackResponse(false, "文件无操作日志，无法回滚", null, metadata.getVersion());
            }
            int minOffset = fileEvents.stream().mapToInt(FileEventLog::getEventOffset).min().getAsInt();
            int maxOffset = fileEvents.stream().mapToInt(FileEventLog::getEventOffset).max().getAsInt();
            if (request.getTargetOffset() < minOffset || request.getTargetOffset() > maxOffset) {
                return new RollbackResponse(false, "目标回滚节点无效，请选择合法偏移量", null, metadata.getVersion());
            }

            // 3. 筛选需反向执行的事件（当前偏移量 到 目标偏移量之间的事件）
            List<FileEventLog> reverseEvents = fileEvents.stream()
                    .filter(event -> event.getEventOffset() > request.getTargetOffset())
                    .sorted(Comparator.comparingInt(FileEventLog::getEventOffset).reversed()) // 反向排序，从后往前执行回滚
                    .collect(Collectors.toList());

            // 4. 反向执行事件，恢复历史状态（核心逻辑）
            for (FileEventLog event : reverseEvents) {
                executeReverseEvent(event, metadata);
            }

            // 5. 更新文件元数据（版本号、最后访问时间）
            int newVersion = calculateNewVersion(request.getTargetOffset(), fileEvents);
            metadata.setVersion(newVersion);
            metadata.setLastAccessTime(new Date());
            metadata.setUpdateTime(new Date());
            mongoTemplate.save(metadata);

            // 6. 推送回滚事件，同步所有设备
            stateService.publishEvent(request.getFileId(), "FILE_ROLLED_BACK", newVersion);

            return new RollbackResponse(true, "回滚成功", request.getFileId(), newVersion);
        } catch (Exception e) {
            return new RollbackResponse(false, "回滚失败：" + e.getMessage(), null, null);
        }
    }

    // 辅助：获取文件所有操作事件（按偏移量升序）
    private List<FileEventLog> getFileAllEvents(String fileId) {
        return mongoTemplate.find(
                Query.query(Criteria.where("fileId").is(fileId))
                        .sort(Sort.by(Sort.Direction.ASC, "eventOffset")),
                FileEventLog.class
        );
    }

    // 辅助：反向执行单个事件（核心，根据事件类型执行回滚操作）
    private void executeReverseEvent(FileEventLog event, FileMetadata metadata) throws Exception {
        String eventType = event.getEventType();
        Map<String, Object> eventData = event.getEventData();

        // 针对不同事件类型，执行反向操作（覆盖核心操作场景）
        switch (eventType) {
            case "FILE_UPDATED":
                // 反向：恢复更新前的分片URL和MD5（事件数据中存储了更新前的快照）
                List<String> oldChunkUrls = (List<String>) eventData.get("oldChunkUrls");
                Map<Integer, String> oldChunkMd5Map = (Map<Integer, String>) eventData.get("oldChunkMd5Map");
                metadata.setChunkUrls(oldChunkUrls);
                metadata.setChunkMd5Map(oldChunkMd5Map);
                break;
            case "FILE_UPLOADED":
                // 反向：无需删除原始分片（避免影响其他关联文件），仅重置元数据状态（若回滚至上上传前）
                metadata.setStatus("UNUPLOADED");
                metadata.setChunkUrls(new ArrayList<>());
                metadata.setChunkMd5Map(new HashMap<>());
                break;
            case "FILE_CONFLICT":
                // 反向：删除冲突副本（仅删除当前用户的冲突副本，不影响原始文件）
                String conflictFileId = (String) eventData.get("conflictFileId");
                mongoTemplate.remove(Query.query(Criteria.where("fileId").is(conflictFileId)), FileMetadata.class);
                break;
            default:
                throw new Exception("不支持的事件类型：" + eventType + "，无法回滚");
        }
    }

    // 辅助：根据目标偏移量计算回滚后的版本号
    private int calculateNewVersion(int targetOffset, List<FileEventLog> fileEvents) {
        // 版本号与事件偏移量关联：每触发一次FILE_UPDATED/FILE_UPLOADED，版本号+1
        long updateEventCount = fileEvents.stream()
                .filter(event -> event.getEventOffset() <= targetOffset)
                .filter(event -> "FILE_UPDATED".equals(event.getEventType()) || "FILE_UPLOADED".equals(event.getEventType()))
                .count();
        return (int) updateEventCount;
    }

    // 回滚请求DTO
    @Data
    public static class FileRollbackRequest {
        private String fileId;
        private int targetOffset; // 目标回滚节点的事件偏移量
        private String ownerId;
    }

    // 回滚响应DTO
    @Data
    public static class RollbackResponse {
        private boolean success;
        private String msg;
        private String fileId;
        private Integer newVersion;

        public RollbackResponse(boolean success, String msg, String fileId, Integer newVersion) {
            this.success = success;
            this.msg = msg;
            this.fileId = fileId;
            this.newVersion = newVersion;
        }
    }
}

// 回滚接口控制器（对外提供API）
@RestController
@RequestMapping("/api/file")
public class FileRollbackController {
    @Autowired
    private FileRollbackService rollbackService;

    @PostMapping("/rollback")
    public ResponseEntity<FileRollbackService.RollbackResponse> rollbackFile(
            @RequestBody FileRollbackService.FileRollbackRequest request,
            @RequestHeader("Authorization") String authorization) {
        // 此处可添加Token校验（省略，与其他接口统一）
        FileRollbackService.RollbackResponse response = rollbackService.rollbackFile(request);
        return ResponseEntity.ok(response);
    }

    // 可选接口：查询文件所有操作事件，供前端展示回滚节点
    @GetMapping("/event/log/{fileId}")
    public ResponseEntity<List<FileEventLog>> getFileEventLog(
            @PathVariable String fileId,
            @RequestHeader String ownerId) {
        FileMetadata metadata = mongoTemplate.findById(fileId, FileMetadata.class);
        if (metadata == null || !metadata.getOwnerId().equals(ownerId)) {
            return ResponseEntity.status(HttpStatus.FORBIDDEN).body(null);
        }
        List<FileEventLog> eventLogs = mongoTemplate.find(
                Query.query(Criteria.where("fileId").is(fileId))
                        .sort(Sort.by(Sort.Direction.ASC, "timestamp")),
                FileEventLog.class
        );
        return ResponseEntity.ok(eventLogs);
    }
}

```

## 6. 数据去重（降低存储冗余）

**通俗逻辑**：基于文件MD5和文件大小双重校验，多用户（或同一用户多次）上传相同文件时，仅存储1份原始Blob分片，不同用户通过元数据关联复用该分片，大幅降低存储成本，不影响用户正常访问（前端无感知）。

**核心设计**：维护去重记录表，记录文件MD5、大小与原始分片的关联关系，同时记录引用计数（关联该分片的用户/文件数），引用计数为0时删除原始分片，避免无效存储。

### 6.1 前后端流程拆解

1. 前端：文件预处理时，计算文件整体MD5和文件大小（与断点续传预处理复用，无需重复计算）。

2. 前端：上传前调用去重校验API，携带fileMd5、fileSize、ownerId，判断文件是否已存在。

3. 后端：查询去重记录表，若存在相同MD5+文件大小的记录，且原始分片有效，返回“已存在”及对应原始文件ID。

4. 前端：若已存在，调用关联API，无需上传任何分片，仅创建当前用户的文件元数据，关联原始分片。

5. 前端：若不存在，正常执行断点续传流程，上传分片并合并。

6. 后端：文件上传完成后，新增去重记录，引用计数设为1（当前用户关联）。

7. 文件删除时：后端减少去重记录的引用计数，若引用计数为0，删除原始Blob分片和去重记录。

### 6.2 核心API汇总

- POST /api/file/dedup/check：去重校验核心接口，参数（fileMd5、fileSize、ownerId），返回isDuplicate（是否重复）、existFileId（已存在文件ID）

- POST /api/file/dedup/associate：关联已存在文件，参数（existFileId、fileName、ownerId、fileMd5），返回当前用户的fileId

- （内部调用）addDedupRecord：去重记录新增，文件上传完成后由上传服务内部调用

- （内部调用）decreaseDedupCount：引用计数减少，文件删除时由删除服务内部调用

### 6.3 涉及数据库集合

- file_dedup：去重核心集合，存储fileMd5、fileSize、originalFileId（原始文件ID）、referenceCount（引用计数）、createTime

- file_metadata：关联去重记录，每个用户的文件元数据通过fileMd5关联去重记录，复用originalFileId的分片

### 6.4 示例场景

场景：用户A上传100MB「项目视频.mp4」，用户B、C后续上传相同文件（MD5、大小一致）

1. 用户A上传：去重校验返回“未存在”，正常上传分片、合并，后端新增去重记录（fileMd5=xxx，originalFileId=uuid123，引用计数=1）。

2. 用户B上传：去重校验返回“已存在”（existFileId=uuid123），调用关联API，后端创建用户B的文件元数据（fileId=uuid789），去重记录引用计数变为2。

3. 用户C上传：与用户B流程一致，去重记录引用计数变为3，用户C的文件元数据（fileId=uuid456）关联uuid123的分片。

4. 用户A删除文件：去重记录引用计数变为2，原始分片不删除（仍被B、C关联）。

5. 用户B、C均删除文件：引用计数变为0，后端删除原始分片和对应的去重记录，释放存储。

### 6.5 后端Java代码（去重核心）

```java

// 数据去重服务（核心）
@Service
public class FileDedupService {
    @Autowired
    private MongoTemplate mongoTemplate;
    @Autowired
    private BlobStorageClient blobStorageClient;

    // 1. 去重校验：判断文件是否已存在（供前端上传前调用）
    public DedupCheckResponse checkDedup(DedupCheckRequest request) {
        // 双重校验：MD5 + 文件大小（避免MD5碰撞导致误判）
        Query query = Query.query(Criteria.where("fileMd5").is(request.getFileMd5())
                .and("fileSize").is(request.getFileSize()));
        FileDedup dedupRecord = mongoTemplate.findOne(query, FileDedup.class);

        if (dedupRecord != null) {
            // 校验原始文件是否有效（避免原始分片已删除，去重记录未清理的情况）
            FileMetadata originalMetadata = mongoTemplate.findById(dedupRecord.getOriginalFileId(), FileMetadata.class);
            if (originalMetadata != null && "COMPLETED".equals(originalMetadata.getStatus())) {
                // 文件已存在，返回原始文件ID，供前端关联
                return new DedupCheckResponse(true, dedupRecord.getOriginalFileId(), dedupRecord.getReferenceCount());
            } else {
                // 原始文件无效，删除无效去重记录
                mongoTemplate.remove(dedupRecord);
                return new DedupCheckResponse(false, null, 0);
            }
        }
        // 文件未存在，返回false，前端正常上传
        return new DedupCheckResponse(false, null, 0);
    }

    // 2. 新增去重记录（文件上传完成后，内部调用）
    public void addDedupRecord(String fileMd5, String fileId, Long fileSize) {
        // 先查询是否存在（避免并发上传导致重复新增）
        Query query = Query.query(Criteria.where("fileMd5").is(fileMd5)
                .and("fileSize").is(fileSize));
        FileDedup dedupRecord = mongoTemplate.findOne(query, FileDedup.class);

        if (dedupRecord == null) {
            // 不存在，新增去重记录，引用计数=1（当前文件关联）
            FileDedup newDedup = new FileDedup();
            newDedup.setFileMd5(fileMd5);
            newDedup.setFileSize(fileSize);
            newDedup.setOriginalFileId(fileId);
            newDedup.setReferenceCount(1);
            newDedup.setCreateTime(new Date());
            mongoTemplate.save(newDedup);
        } else {
            // 存在（并发上传场景），引用计数+1
            dedupRecord.setReferenceCount(dedupRecord.getReferenceCount() + 1);
            mongoTemplate.save(dedupRecord);
        }
    }

    // 3. 关联已存在文件（供前端调用，无需上传分片）
    public DedupAssociateResponse associateExistingFile(DedupAssociateRequest request) {
        // 校验原始文件是否有效
        FileMetadata originalMetadata = mongoTemplate.findById(request.getExistFileId(), FileMetadata.class);
        if (originalMetadata == null || !"COMPLETED".equals(originalMetadata.getStatus())) {
            return new DedupAssociateResponse(false, "原始文件无效，无法关联", null);
        }

        // 校验去重记录是否存在
        Query dedupQuery = Query.query(Criteria.where("originalFileId").is(request.getExistFileId()));
        FileDedup dedupRecord = mongoTemplate.findOne(dedupQuery, FileDedup.class);
        if (dedupRecord == null) {
            return new DedupAssociateResponse(false, "去重记录不存在", null);
        }

        // 为当前用户创建新的文件元数据，复用原始分片
        FileMetadata newMetadata = new FileMetadata();
        newMetadata.setFileId(UUID.randomUUID().toString());
        newMetadata.setFileName(request.getFileName());
        newMetadata.setOwnerId(request.getOwnerId());
        newMetadata.setMimeType(originalMetadata.getMimeType());
        newMetadata.setFileSize(originalMetadata.getFileSize());
        newMetadata.setFileMd5(request.getFileMd5());
        newMetadata.setTotalChunks(originalMetadata.getTotalChunks());
        newMetadata.setChunkUrls(originalMetadata.getChunkUrls()); // 复用原始分片URL
        newMetadata.setChunkMd5Map(originalMetadata.getChunkMd5Map()); // 复用分片MD5
        newMetadata.setContentEncoding(originalMetadata.getContentEncoding());
        newMetadata.setStatus("COMPLETED"); // 直接设为完成，无需上传
        newMetadata.setVersion(1);
        newMetadata.setCreateTime(new Date());
        newMetadata.setUpdateTime(new Date());
        newMetadata.setLastAccessTime(new Date());
        newMetadata.setStorageType(originalMetadata.getStorageType());
        mongoTemplate.save(newMetadata);

        // 去重记录引用计数+1
        dedupRecord.setReferenceCount(dedupRecord.getReferenceCount() + 1);
        mongoTemplate.save(dedupRecord);

        // 推送文件更新事件，同步当前用户多设备
        stateService.publishEvent(newMetadata.getFileId(), "FILE_UPDATED", 1);

        return new DedupAssociateResponse(true, "关联成功", newMetadata.getFileId());
    }

    // 4. 减少引用计数（文件删除时，内部调用）
    public void decreaseDedupCount(String fileId) {
        // 1. 获取当前文件元数据
        FileMetadata metadata = mongoTemplate.findById(fileId, FileMetadata.class);
        if (metadata == null) {
            return;
        }

        // 2. 查询对应的去重记录
        Query dedupQuery = Query.query(Criteria.where("fileMd5").is(metadata.getFileMd5())
                .and("fileSize").is(metadata.getFileSize()));
        FileDedup dedupRecord = mongoTemplate.findOne(dedupQuery, FileDedup.class);
        if (dedupRecord == null) {
            return;
        }

        // 3. 引用计数-1
        int newCount = dedupRecord.getReferenceCount() - 1;
        if (newCount > 0) {
            dedupRecord.setReferenceCount(newCount);
            mongoTemplate.save(dedupRecord);
        } else {
            // 引用计数为0，删除去重记录 + 删除原始分片
            mongoTemplate.remove(dedupRecord);
            // 删除原始分片（所有关联该去重记录的文件均已删除）
            deleteOriginalChunks(dedupRecord.getOriginalFileId());
            // 删除原始文件元数据
            mongoTemplate.remove(Query.query(Criteria.where("fileId").is(dedupRecord.getOriginalFileId())), FileMetadata.class);
        }
    }

    // 辅助：删除原始分片（Blob存储）
    private void deleteOriginalChunks(String originalFileId) {
        FileMetadata originalMetadata = mongoTemplate.findById(originalFileId, FileMetadata.class);
        if (originalMetadata != null && originalMetadata.getChunkUrls() != null) {
            for (String chunkUrl : originalMetadata.getChunkUrls()) {
                blobStorageClient.delete(chunkUrl);
            }
        }
    }

    // 去重校验请求DTO
    @Data
    public static class DedupCheckRequest {
        private String fileMd5;
        private Long fileSize;
        private String ownerId;
    }

    // 去重校验响应DTO
    @Data
    public static class DedupCheckResponse {
        private boolean isDuplicate;
        private String existFileId;
        private Integer referenceCount;

        public DedupCheckResponse(boolean isDuplicate, String existFileId, Integer referenceCount) {
            this.isDuplicate = isDuplicate;
            this.existFileId = existFileId;
            this.referenceCount = referenceCount;
        }
    }

    // 关联已存在文件请求DTO
    @Data
    public static class DedupAssociateRequest {
        private String existFileId;
        private String fileName;
        private String ownerId;
        private String fileMd5;
    }

    // 关联已存在文件响应DTO
    @Data
    public static class DedupAssociateResponse {
        private boolean success;
        private String msg;
        private String fileId;

        public DedupAssociateResponse(boolean success, String msg, String fileId) {
            this.success = success;
            this.msg = msg;
            this.fileId = fileId;
        }
    }
}

// 去重接口控制器（对外提供API）
@RestController
@RequestMapping("/api/file/dedup")
public class FileDedupController {
    @Autowired
    private FileDedupService dedupService;

    // 去重校验接口（前端上传前调用）
    @PostMapping("/check")
    public ResponseEntity<FileDedupService.DedupCheckResponse> checkDedup(
            @RequestBody FileDedupService.DedupCheckRequest request,
            @RequestHeader("Authorization") String authorization) {
        // Token校验（省略，与其他接口统一）
        FileDedupService.DedupCheckResponse response = dedupService.checkDedup(request);
        return ResponseEntity.ok(response);
    }

    // 关联已存在文件接口（文件已重复时，前端调用）
    @PostMapping("/associate")
    public ResponseEntity<FileDedupService.DedupAssociateResponse> associateExistingFile(
            @RequestBody FileDedupService.DedupAssociateRequest request,
            @RequestHeader("Authorization") String authorization) {
        // Token校验（省略，与其他接口统一）
        FileDedupService.DedupAssociateResponse response = dedupService.associateExistingFile(request);
        return ResponseEntity.ok(response);
    }
}

// 去重集合实体类（file_dedup）
@Data
@Document(collection = "file_dedup")
public class FileDedup {
    @Id
    private String id; // 自增ID，无业务意义
    private String fileMd5; // 文件整体MD5（去重核心标识）
    private Long fileSize; // 文件大小（辅助去重，避免MD5碰撞）
    private String originalFileId; // 原始文件ID（存储原始分片的文件ID）
    private Integer referenceCount; // 引用计数（关联该原始文件的用户/文件数）
    private Date createTime; // 去重记录创建时间
}

```



## 7. 冷热数据分离（平衡性能与成本）

**通俗逻辑**：按文件访问频率和最后访问时间，将文件分为热数据、冷数据，分别存储至不同存储介质——热数据（高频访问）存高性能Blob存储（读取速度快），冷数据（低频访问）存低成本Blob存储（容量大、成本低），自动迁移、前端无感知，平衡访问性能和存储成本。

**核心设计**：设定冷热数据判断阈值（可配置），定时任务扫描文件元数据，根据最后访问时间、访问频率，自动将冷数据迁移至低成本存储，热数据（冷数据被访问后）迁移回高性能存储。

### 7.1 核心配置（可动态调整）

- 热数据阈值：最后访问时间<30天，或近30天访问次数>5次（满足其一即为热数据）

- 冷数据阈值：最后访问时间≥30天，且近30天访问次数≤5次（同时满足即为冷数据）

- 迁移定时任务：每天凌晨2点执行（低峰期，避免影响业务）

- 存储介质：热存储（高性能Blob，如阿里云OSS标准型）、冷存储（低成本Blob，如阿里云OSS归档型）

### 7.2 前后端流程拆解

1. 后端：定时任务每天凌晨扫描所有文件元数据，判断文件是热数据还是冷数据。

2. 冷数据迁移：符合冷数据阈值，且当前存储类型为热存储，将分片从热存储迁移至冷存储，更新文件元数据的存储类型、分片URL。

3. 热数据迁移：冷数据被访问（下载/查看）时，自动将分片从冷存储迁移回热存储，更新元数据，前端无感知（迁移期间暂用冷存储分片，迁移完成后切换）。

4. 前端：无需任何额外操作，正常调用下载、查看接口，后端透明处理数据迁移，不影响用户体验。

### 7.3 核心API汇总

- （内部调用）migrateHotToCold：热数据转冷数据，定时任务调用

- （内部调用）migrateColdToHot：冷数据转热数据，文件访问时调用（已在下载接口中关联）

- GET /api/file/hot-cold/status/{fileId}：（可选）查询文件冷热状态，参数（fileId、ownerId），返回存储类型、最后访问时间

### 7.4 涉及数据库集合

- file_metadata：新增storageType（存储类型：HOT/COLD）、accessCount（近30天访问次数）、lastAccessTime（最后访问时间）字段，用于判断冷热数据

- file_hot_cold_log：（可选）存储数据迁移日志，记录fileId、迁移类型（HOT→COLD/COLD→HOT）、迁移时间、迁移状态

### 7.5 示例场景

场景1：冷数据迁移

用户A上传「旧项目文档.pdf」，最后访问时间为60天前，近30天访问次数为0次，符合冷数据阈值：

1. 凌晨定时任务扫描到该文件，判断为冷数据，当前存储类型为HOT。

2. 后端自动将该文件的所有分片从热存储迁移至冷存储，更新元数据storageType为COLD，更新分片URL为冷存储URL。

3. 迁移完成，存储成本降低，用户后续访问时，后端自动判断并迁移回热存储。

场景2：冷数据转热数据

1. 用户A访问已迁移为冷数据的「旧项目文档.pdf」，触发下载接口。

2. 后端检测到该文件为冷数据，自动启动迁移任务，将分片从冷存储迁移至热存储。

3. 迁移期间，前端暂时从冷存储下载分片（不影响访问），迁移完成后，更新元数据storageType为HOT，后续访问从热存储读取。

### 7.6 后端Java代码（冷热分离核心）

```Java

// 冷热数据分离服务（核心）
@Service
public class FileHotColdService {
    @Autowired
    private MongoTemplate mongoTemplate;
    @Autowired
    private BlobStorageClient hotBlobClient; // 热存储客户端（高性能）
    @Autowired
    private BlobStorageClient coldBlobClient; // 冷存储客户端（低成本）

    // 1. 热数据转冷数据（定时任务调用）
    public void migrateHotToCold() {
        // 筛选符合条件的热数据：最后访问时间≥30天 + 近30天访问次数≤5次 + 存储类型为HOT
        Date thirtyDaysAgo = new Date(System.currentTimeMillis() - 30L * 24 * 60 * 60 * 1000);
        Query query = Query.query(Criteria.where("lastAccessTime").lte(thirtyDaysAgo)
                .and("accessCount").lte(5)
                .and("storageType").is("HOT")
                .and("status").is("COMPLETED"));

        List<FileMetadata> hotToColdFiles = mongoTemplate.find(query, FileMetadata.class);
        if (hotToColdFiles.isEmpty()) {
            return;
        }

        // 批量迁移分片至冷存储
        for (FileMetadata file : hotToColdFiles) {
            try {
                // 迁移所有分片：从热存储下载，上传至冷存储
                List<String> coldChunkUrls = new ArrayList<>();
                for (String hotChunkUrl : file.getChunkUrls()) {
                    // 从热存储下载分片
                    byte[] chunkBytes = hotBlobClient.download(hotChunkUrl);
                    // 上传至冷存储，生成冷存储URL
                    String coldChunkUrl = coldBlobClient.upload(
                            chunkBytes,
                            "cold_" + file.getFileId() + "_" + UUID.randomUUID(),
                            file.getMimeType()
                    );
                    coldChunkUrls.add(coldChunkUrl);
                    // 删除热存储中的分片（迁移完成后删除，避免重复存储）
                    hotBlobClient.delete(hotChunkUrl);
                }

                // 更新文件元数据：存储类型、分片URL、迁移时间
                file.setStorageType("COLD");
                file.setChunkUrls(coldChunkUrls);
                file.setUpdateTime(new Date());
                mongoTemplate.save(file);

                // 记录迁移日志（可选）
                recordMigrateLog(file.getFileId(), "HOT_TO_COLD", "SUCCESS");
            } catch (Exception e) {
                // 迁移失败，记录日志，下次定时任务重新尝试
                recordMigrateLog(file.getFileId(), "HOT_TO_COLD", "FAILED: " + e.getMessage());
                continue;
            }
        }
    }

    // 2. 冷数据转热数据（文件访问时调用，已在下载接口中关联）
    public void migrateColdToHot(String fileId) {
        // 获取文件元数据
        FileMetadata file = mongoTemplate.findById(fileId, FileMetadata.class);
        if (file == null || !"COLD".equals(file.getStorageType()) || !"COMPLETED".equals(file.getStatus())) {
            return;
        }

        try {
            // 迁移所有分片：从冷存储下载，上传至热存储
            List<String> hotChunkUrls = new ArrayList<>();
            for (String coldChunkUrl : file.getChunkUrls()) {
                // 从冷存储下载分片（冷存储可能需要解冻，此处省略解冻逻辑，根据存储类型适配）
                byte[] chunkBytes = coldBlobClient.download(coldChunkUrl);
                // 上传至热存储，生成热存储URL
                String hotChunkUrl = hotBlobClient.upload(
                        chunkBytes,
                        "hot_" + file.getFileId() + "_" + UUID.randomUUID(),
                        file.getMimeType()
                );
                hotChunkUrls.add(hotChunkUrl);
                // 删除冷存储中的分片
                coldBlobClient.delete(coldChunkUrl);
            }

            // 更新文件元数据：存储类型、分片URL、最后访问时间、访问次数+1
            file.setStorageType("HOT");
            file.setChunkUrls(hotChunkUrls);
            file.setLastAccessTime(new Date());
            file.setAccessCount(file.getAccessCount() + 1);
            file.setUpdateTime(new Date());
            mongoTemplate.save(file);

            // 记录迁移日志（可选）
            recordMigrateLog(fileId, "COLD_TO_HOT", "SUCCESS");
        } catch (Exception e) {
            recordMigrateLog(fileId, "COLD_TO_HOT", "FAILED: " + e.getMessage());
        }
    }

    // 3. 定时任务：每天凌晨2点执行热转冷迁移
    @Scheduled(cron = "0 0 2 * * ?")
    public void hotColdMigrateSchedule() {
        // 执行热数据转冷数据迁移
        migrateHotToCold();
        // 重置近30天访问次数（每月1号执行，可选）
        resetAccessCount();
    }

    // 辅助：重置近30天访问次数（每月1号执行）
    @Scheduled(cron = "0 0 0 1 * ?")
    public void resetAccessCount() {
        Query query = Query.query(Criteria.where("status").is("COMPLETED"));
        Update update = new Update().set("accessCount", 0);
        mongoTemplate.updateMulti(query, update, FileMetadata.class);
    }

    // 辅助：记录迁移日志（可选）
    private void recordMigrateLog(String fileId, String migrateType, String status) {
        FileHotColdLog log = new FileHotColdLog();
        log.setId(UUID.randomUUID().toString());
        log.setFileId(fileId);
        log.setMigrateType(migrateType);
        log.setStatus(status);
        log.setMigrateTime(new Date());
        mongoTemplate.save(log);
    }

    // 可选：查询文件冷热状态接口
    public HotColdStatusResponse getHotColdStatus(String fileId, String ownerId) {
        FileMetadata file = mongoTemplate.findById(fileId, FileMetadata.class);
        if (file == null || !file.getOwnerId().equals(ownerId)) {
            return new HotColdStatusResponse(false, "无文件访问权限", null, null, null);
        }
        return new HotColdStatusResponse(
                true,
                "查询成功",
                file.getStorageType(),
                file.getLastAccessTime(),
                file.getAccessCount()
        );
    }

    // 冷热状态响应DTO
    @Data
    public static class HotColdStatusResponse {
        private boolean success;
        private String msg;
        private String storageType; // HOT/COLD
        private Date lastAccessTime;
        private Integer accessCount;

        public HotColdStatusResponse(boolean success, String msg, String storageType, Date lastAccessTime, Integer accessCount) {
            this.success = success;
            this.msg = msg;
            this.storageType = storageType;
            this.lastAccessTime = lastAccessTime;
            this.accessCount = accessCount;
        }
    }
}

// 冷热数据迁移日志实体类（file_hot_cold_log）
@Data
@Document(collection = "file_hot_cold_log")
public class FileHotColdLog {
    @Id
    private String id;
    private String fileId; // 关联文件ID
    private String migrateType; // 迁移类型：HOT_TO_COLD/COLD_TO_HOT
    private String status; // 迁移状态：SUCCESS/FAILED
    private Date migrateTime; // 迁移时间
}

// 冷热数据状态查询接口控制器
@RestController
@RequestMapping("/api/file/hot-cold")
public class FileHotColdController {
    @Autowired
    private FileHotColdService hotColdService;

    // 查询文件冷热状态接口
    @GetMapping("/status/{fileId}")
    public ResponseEntity<FileHotColdService.HotColdStatusResponse> getHotColdStatus(
            @PathVariable String fileId,
            @RequestHeader String ownerId,
            @RequestHeader("Authorization") String authorization) {
        // Token校验（省略，与其他接口统一）
        FileHotColdService.HotColdStatusResponse response = hotColdService.getHotColdStatus(fileId, ownerId);
        return ResponseEntity.ok(response);
    }
}

// 补充：FileMetadata实体类新增冷热分离相关字段（之前省略，此处补充完整）
@Data
@Document(collection = "file_metadata")
public class FileMetadata {
    @Id
    private String fileId;
    private String fileName;
    private String ownerId;
    private String mimeType;
    private Long fileSize;
    private String fileMd5;
    private Integer totalChunks;
    private List<String> chunkUrls;
    private Map<Integer, String> chunkMd5Map;
    private String contentEncoding;
    private String status; // UPLOADING/COMPLETED/UNUPLOADED
    private Integer version;
    private Date createTime;
    private Date updateTime;
    private Date lastAccessTime; // 最后访问时间（冷热分离核心字段）
    private Integer accessCount; // 近30天访问次数（冷热分离核心字段）
    private String storageType; // 存储类型：HOT/COLD（冷热分离核心字段）
    private boolean conflictFlag; // 冲突文件标记（冲突处理字段）
    private String originalFileId; // 关联原始文件ID（冲突处理/去重字段）
}

```
> （注：文档部分内容可能由 AI 生成）