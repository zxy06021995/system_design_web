# Q32：Google Search Engine 设计（95分面试版）

## 1. 三句话题目本质
1. 搜索引擎本质是两件事：离线把互联网内容“整理成可查的索引”，在线把用户问题“快速变成高相关结果”。  
2. 真正难点不在单次查询，而在“网页规模极大、内容持续变化、延迟要求很低”三者同时成立。  
3. 面试高分要讲清楚：抓取（Crawler）-> 索引（Index）-> 查询（Recall+Rank）-> 增量更新（Freshness）-> 质量闭环（评估与反作弊）。  

## 2. 一个真实场景故事
用户早上 8:00 搜“某手机发布会参数”，8:05 发布会官网更新了新配置。  
你希望 8:20 再搜时，用户已经看到新内容，而不是昨天旧页面。  
同时这个词是热点词，QPS 飙升，系统不能卡顿。

这就同时考验三条链路：
- 抓取链路：能否快速发现网页更新。
- 索引链路：能否把更新高效写进新索引段。
- 查询链路：能否在毫秒级返回并按相关性排序。

## 3. 术语白话表（至少 10 项）
| 术语 | 白话解释 | 面试可复述 |
|---|---|---|
| Crawler | 网络爬虫 | “把网页内容抓回来” |
| Frontier | 待抓取队列 | “下一批要抓哪些 URL” |
| Robots.txt | 站点抓取规则 | “站长告诉你哪里能抓哪里不能抓” |
| Politeness | 抓取礼貌策略 | “同一站点不要抓太猛，防止打挂对方” |
| Canonical URL | 规范 URL | “把同一页面不同参数地址归一” |
| Inverted Index | 倒排索引 | “词 -> 出现在哪些文档” |
| Posting List | 倒排链 | “某词命中的文档列表” |
| BM25 | 经典文本相关性算法 | “词频+逆文档频率+文档长度” |
| Query Understanding | 查询理解 | “分词、纠错、同义词扩展” |
| Recall | 召回 | “先找一批候选文档” |
| Ranking | 排序 | “再把候选按分数排前后” |
| Freshness | 新鲜度 | “新内容在某些查询上应提权” |
| Snippet | 摘要片段 | “搜索结果下面那两行解释文字” |
| Sharding | 分片 | “索引分到多机器并行查” |
| Merge | 段合并 | “小索引段并成大段，提高查询效率” |

## 4. 需求澄清（功能/非功能/不做范围）
### 4.1 功能需求
- 抓取网页并遵守 robots 规则。
- 网页解析、去重、抽取正文和标题。
- 构建倒排索引，支持关键词搜索。
- 查询理解（分词、拼写纠错、同义词扩展）。
- 结果排序（相关性 + 权威性 + 新鲜度）。
- 返回结果页：标题、URL、摘要、时间。

### 4.2 非功能需求（SLO 示例）
- 查询延迟：`P95 <= 200ms`，`P99 <= 400ms`。
- 搜索服务可用性：`>= 99.95%`。
- 抓取成功率：`>= 98%`（去掉不可达站点）。
- 热点查询缓存命中率：`>= 70%`。
- 新内容可见性：热门站点 `<= 15min`，普通站点 `<= 24h`。

### 4.3 Out of Scope（首版不做）
- 不做全网秒级实时索引（成本极高）。
- 不做复杂多模态搜索（图文/视频联合召回）。
- 不做深度个性化（可先弱化为地域和语言层面的轻个性化）。

## 5. 容量估算（含数字推导）
### 5.1 假设
- 可抓取文档总量：`12B`（120 亿）。
- 平均解析后文本：`15KB/doc`。
- 查询日请求：`15B/day`（150 亿次）。
- 峰值系数：`6x`。
- 索引膨胀系数（含倒排、位置信息、压缩后）：`1.3x~2.0x`。

### 5.2 存储估算
- 原始文本规模：`12B * 15KB ≈ 180PB`（原始层可分层存储）。
- 索引层规模（按 1.5x）：`~270PB`（逻辑规模，需分片+副本）。
- 若查询副本 2 份：查询索引总规模 `~540PB`。

### 5.3 查询流量估算
- 平均 QPS：`15B / 86400 ≈ 173,611 qps`。
- 峰值 QPS：`~1,041,666 qps`。
- 若单查询 fanout 到 64 分片，内部请求吞吐巨大，必须做缓存、分片路由和 early termination。

### 5.4 关键结论
- 在线查询层必须“内存+SSD 混合”，不能只靠磁盘随机读。
- 热词缓存和结果页缓存是生死线，不是优化项。
- 增量索引必须分层（热段快更新，冷段慢合并）。

## 6. 架构（简版 + 完整版）
### 6.1 简版架构
```text
Crawler -> Parser -> Index Builder -> Index Shards
User Query -> Query Service -> Recall -> Rank -> Merge -> Response
```

### 6.2 完整版架构
```text
[URL Frontier Scheduler]
  -> [Crawler Workers]
  -> [Raw Page Store]
  -> [Parser/Cleaner/Language Detector]
  -> [Dedup/Canonicalization]
  -> [Document Store]
  -> [Indexer Pipeline]
      -> [Segment Writer]
      -> [Segment Merge Service]
      -> [Shard Distributor]

[Query Gateway]
  -> [Query Understanding]
  -> [Recall Coordinator]
      -> [Inverted Index Shards]
  -> [Ranker Service]
  -> [Result Aggregator]
  -> [Snippet Service]
  -> [Cache Layer]
  -> [Search API]

[Offline Evaluation + Spam/Fraud + Metrics/Alert]
```

### 6.3 模块职责
- Frontier：控制抓取顺序、优先级和礼貌策略。
- Indexer：把文档转成可检索结构（词项、权重、位置信息）。
- Recall：快速缩小候选集。
- Ranker：更精细打分，输出 TopK。
- Evaluator：离线评估 NDCG、MRR，防止排序退化。

## 7. API 设计（含请求/响应样例）
### 7.1 搜索 API（用户）
`GET /api/v1/search?q=iphone%2017%20spec&page=1&size=10&lang=zh-CN`

Response:
```json
{
  "query": "iphone 17 spec",
  "correctedQuery": "iphone 17 specs",
  "tookMs": 128,
  "totalEstimate": 1820000,
  "results": [
    {
      "docId": 91342411,
      "title": "iPhone 17 官方参数",
      "url": "https://example.com/iphone17/spec",
      "snippet": "包含屏幕、芯片、续航等完整参数...",
      "score": 18.37,
      "publishTime": "2026-02-24T07:58:00Z"
    }
  ]
}
```

### 7.2 索引写入 API（内部）
`POST /internal/index/documents/batch`

Request:
```json
{
  "batchId": "idx_20260224_0900_01",
  "documents": [
    {
      "docId": 91342411,
      "url": "https://example.com/iphone17/spec",
      "title": "iPhone 17 官方参数",
      "body": "..."
    }
  ]
}
```

### 7.3 增量刷新 API（内部）
`POST /internal/index/refresh`

Request:
```json
{
  "targetShard": 18,
  "segmentId": "seg_20260224_0915_18"
}
```

### 7.4 错误码约定
- `429_QUERY_RATE_LIMITED`：单用户/单 IP 高频刷查。
- `503_SHARD_OVERLOADED`：分片过载触发保护。
- `206_PARTIAL_RESULT`：部分分片超时，返回降级结果。

## 8. 数据模型（核心表/索引）
### 8.1 文档元数据表
```sql
CREATE TABLE doc_meta (
  doc_id BIGINT PRIMARY KEY,
  url VARCHAR(1024) NOT NULL,
  canonical_url VARCHAR(1024) NOT NULL,
  site_host VARCHAR(256) NOT NULL,
  lang VARCHAR(16) NOT NULL,
  title VARCHAR(512),
  publish_time TIMESTAMP,
  crawl_time TIMESTAMP NOT NULL,
  static_score DOUBLE NOT NULL DEFAULT 0.0,
  is_deleted BOOLEAN NOT NULL DEFAULT FALSE
);
CREATE UNIQUE INDEX uk_doc_canonical ON doc_meta(canonical_url);
CREATE INDEX idx_doc_host_crawl ON doc_meta(site_host, crawl_time DESC);
```

### 8.2 抓取任务表
```sql
CREATE TABLE crawl_task (
  task_id BIGINT PRIMARY KEY,
  url VARCHAR(1024) NOT NULL,
  host VARCHAR(256) NOT NULL,
  priority INT NOT NULL,
  next_fetch_at TIMESTAMP NOT NULL,
  state VARCHAR(16) NOT NULL, -- READY/RUNNING/SUCCEED/FAILED/BLOCKED
  retry_count INT NOT NULL DEFAULT 0,
  last_error VARCHAR(512)
);
CREATE INDEX idx_crawl_ready ON crawl_task(state, next_fetch_at, priority DESC);
```

### 8.3 倒排索引逻辑结构
- `term_dictionary(term -> term_id, df, idf, shard_hint)`
- `posting(term_id -> [doc_id, tf, positions, field_boost])`
- `forward_index(doc_id -> title/body_len/lang/static_score/flags)`

### 8.4 查询日志（评估与训练）
```sql
CREATE TABLE query_log (
  query_id BIGINT PRIMARY KEY,
  query_text VARCHAR(256) NOT NULL,
  user_region VARCHAR(32),
  result_doc_ids TEXT,
  clicked_doc_id BIGINT,
  took_ms INT,
  created_at TIMESTAMP NOT NULL
);
CREATE INDEX idx_query_created ON query_log(created_at DESC);
```

## 9. 核心流程（至少 3 条）
### 9.1 正常查询流程
1. 用户输入查询词，Query Understanding 做分词、纠错、同义词扩展。
2. Recall Coordinator 并行请求多个分片，拿到候选文档。
3. Ranker 按 BM25 + static_score + freshness 等信号打分。
4. Aggregator 合并 TopK，生成摘要并返回。

### 9.2 增量更新流程（热点新闻）
1. Crawler 检测到页面内容 hash 变化。
2. Parser 清洗后生成新文档版本。
3. Indexer 写入新 segment，并标记旧版本失效。
4. Search 节点 refresh segment，15 分钟内对查询可见。

### 9.3 故障恢复流程（分片超时）
1. Recall 某些分片超时。
2. Aggregator 触发降级：先返回已有分片结果（`206_PARTIAL_RESULT`）。
3. 并行重试慢分片，后台补齐缓存。
4. 若持续超时，自动摘除异常副本并切健康副本。

### 9.4 抓取礼貌流程
1. Frontier 读取 host 的 politeness 配置（例如每 2 秒 1 请求）。
2. 若某 host 返回 429/503，动态拉长回访间隔。
3. 高优先站点（新闻、官方公告）可提高抓取优先级但仍遵守速率限制。

## 10. 一致性与事务边界
### 10.1 一致性级别
- 查询结果允许最终一致（索引刷新不是全局瞬时）。
- 文档删除（法律下架）要求强一致传播优先级更高。

### 10.2 事务边界
- 抓取存储与索引写入采用异步事件，避免强耦合同步事务。
- 索引段发布走“两阶段”：`build -> validate -> publish`，失败可回滚旧段。

### 10.3 去重与幂等
- 文档幂等键可用 `canonical_url + content_hash`。
- 重复抓取不应重复写段；重复段发布要可检测并忽略。

## 11. 可用性与容错
### 11.1 关键故障模式
- 热点查询导致部分分片过载。
- 某机房网络抖动导致 fanout 失败。
- 索引段发布错误导致相关性突降。

### 11.2 容错策略
- 分片多副本，查询优先打本地可用副本。
- 结果缓存和 query rewrite 缓解热点。
- 排序服务熔断时退化到简化排序（BM25 + freshness）。
- 索引版本开关可一键回滚到上一个稳定段集合。

### 11.3 RTO / RPO
- 查询面 RTO：`<= 5 分钟`（副本切换）。
- 索引发布 RTO：`<= 15 分钟`（版本回退）。
- 索引可见性 RPO：热点 <= 15 分钟，普通 <= 24 小时。

## 12. 可观测性（指标 + 告警阈值）
### 12.1 抓取指标
- `crawl_success_rate`
- `frontier_backlog_size`
- `robots_block_rate`

阈值示例：
- `crawl_success_rate < 95%` 持续 10 分钟 -> P1
- `frontier_backlog_size > 2x baseline` 持续 30 分钟 -> P2

### 12.2 查询指标
- `search_p95_ms`, `search_p99_ms`
- `query_error_rate`
- `partial_result_ratio`
- `cache_hit_ratio`

阈值示例：
- `search_p95_ms > 200` 持续 10 分钟 -> P1
- `query_error_rate > 1%` 持续 5 分钟 -> P1
- `partial_result_ratio > 3%` 持续 10 分钟 -> P1

### 12.3 质量指标
- `zero_result_rate`
- `ctr@1`, `ctr@10`
- `ndcg@10`

阈值示例：
- `zero_result_rate > 12%` 持续 1 小时 -> P2
- `ctr@1` 较昨日同小时下降 > 15% -> P1（需排查排序回归）

## 13. 安全与合规
- 抓取合规：严格遵守 robots 和法律下架要求。
- 反滥用：查询端限流、防机器刷查、防爬结果页。
- 隐私处理：日志中脱敏用户标识、IP 区段化存储。
- 内容安全：恶意页面、钓鱼页面打低权或过滤。
- 审计能力：索引发布、规则变更、下架操作全链路审计。

## 14. 成本与取舍
### 14.1 成本大头
- 存储成本（原始页+多版本索引）。
- 计算成本（抓取、解析、排序模型）。
- 网络成本（分片 fanout 与机房间流量）。

### 14.2 降本策略
- 热冷分层：热门索引段驻内存，冷段放 SSD。
- 两阶段召回：先轻量召回，再对小候选做重排序。
- 热词缓存：query cache + result cache。
- 增量优先：减少全量重建频率。

### 14.3 取舍表达
- 更高新鲜度意味着更高抓取和索引成本。
- 更复杂排序意味着更好质量但更高延迟。
- 实战里通常设“延迟预算”：先保障时延，再逐步加质量特征。

## 15. Java 关键代码（至少 4 段，点位不同）
### 15.1 查询理解：分词 + 拼写纠错 + 同义词扩展
```java
public class QueryUnderstandingService {
    public QueryPlan buildPlan(String rawQuery) {
        List<String> tokens = tokenizer.tokenize(rawQuery.toLowerCase());
        String corrected = spellCorrector.correct(rawQuery);
        Set<String> expanded = new LinkedHashSet<>(tokens);
        for (String t : tokens) {
            expanded.addAll(synonymRepo.getSynonyms(t));
        }
        return new QueryPlan(rawQuery, corrected, new ArrayList<>(expanded));
    }
}
```

### 15.2 召回协调：分片并发 + 超时控制
```java
public class RecallCoordinator {
    private final ExecutorService pool = Executors.newFixedThreadPool(128);

    public List<DocCandidate> recall(QueryPlan plan, List<Integer> shards) {
        List<Future<List<DocCandidate>>> futures = new ArrayList<>();
        for (Integer shardId : shards) {
            futures.add(pool.submit(() -> shardClient.searchShard(shardId, plan, 80)));
        }

        List<DocCandidate> merged = new ArrayList<>();
        for (Future<List<DocCandidate>> f : futures) {
            try {
                merged.addAll(f.get(80, TimeUnit.MILLISECONDS));
            } catch (TimeoutException te) {
                metrics.counter("recall.shard.timeout").increment();
            } catch (Exception e) {
                metrics.counter("recall.shard.error").increment();
            }
        }
        return merged;
    }
}
```

### 15.3 排序：BM25 + 静态分 + 新鲜度加权
```java
public class RankService {
    public double score(DocCandidate c, QueryStats q) {
        double bm25 = bm25(c.getTf(), c.getDf(), c.getDocLen(), q.getAvgDocLen(), q.getTotalDocs());
        double freshness = freshnessBoost(c.getPublishTimeEpochSec(), q.getNowEpochSec());
        return 0.65 * bm25 + 0.25 * c.getStaticScore() + 0.10 * freshness;
    }

    private double bm25(int tf, int df, int docLen, int avgDocLen, int totalDocs) {
        double idf = Math.log((totalDocs - df + 0.5) / (df + 0.5) + 1);
        double k1 = 1.2, b = 0.75;
        return idf * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * docLen / (double) avgDocLen));
    }

    private double freshnessBoost(long publishTs, long nowTs) {
        long ageHours = Math.max(1, (nowTs - publishTs) / 3600);
        return 1.0 / Math.log(ageHours + 2.0);
    }
}
```

### 15.4 索引段发布：验证后原子切换版本
```java
public class SegmentPublishService {
    public void publish(String shardId, String newSegmentId) {
        if (!validator.segmentHealthy(shardId, newSegmentId)) {
            throw new IllegalStateException("segment validation failed");
        }
        String oldVersion = versionRepo.currentVersion(shardId);
        try {
            versionRepo.swapVersion(shardId, newSegmentId); // 原子切换
            cacheService.invalidateShard(shardId);
        } catch (Exception e) {
            versionRepo.swapVersion(shardId, oldVersion); // 快速回滚
            throw e;
        }
    }
}
```

### 15.5 抓取礼貌策略：host 级速率控制
```java
public class PolitenessLimiter {
    private final ConcurrentHashMap<String, Long> hostNextAllowedTs = new ConcurrentHashMap<>();

    public boolean allow(String host, long nowMs, long minIntervalMs) {
        long next = hostNextAllowedTs.getOrDefault(host, 0L);
        if (nowMs < next) return false;
        hostNextAllowedTs.put(host, nowMs + minIntervalMs);
        return true;
    }
}
```

## 16. 测试策略
### 16.1 单元测试
- Query Understanding：纠错、同义词、分词边界。
- BM25 分数单调性和边界值。
- Host 限流器在并发下是否正确。

### 16.2 集成测试
- 抓取 -> 解析 -> 写段 -> 发布 -> 查询可见全链路。
- 分片超时降级返回是否符合协议（206 partial）。
- 索引版本切换失败回滚是否可用。

### 16.3 压测
- 查询层 100 万 QPS 场景压测。
- 热点词 Zipf 分布压测（模拟真实流量偏斜）。
- 抓取高峰 + 索引合并并发场景压测。

### 16.4 质量评估测试
- 离线样本集评估 NDCG@10、MRR、Recall@50。
- A/B 测试新排序策略，观察 CTR 和停留时长变化。

## 17. 丰富例子（至少 10 个）
1. 搜“苹果发布会”时，今天新闻比三年前内容更靠前（freshness 提权）。  
2. 用户把 `iphnoe` 拼错，系统纠错成 `iphone` 并返回正确结果。  
3. 同一文章有 `?utm=...` 参数 URL，canonical 归一后去重。  
4. 某站点返回 429，Frontier 降低抓取频率避免封禁。  
5. 某分片超时，系统先返回部分结果并标记降级。  
6. 热词“天气”高峰时 query cache 命中，延迟显著下降。  
7. 页面被站长删除，删除标记优先传播并从结果中下线。  
8. 垃圾 SEO 页面词频很高，但被质量分和反作弊信号压低。  
9. 新闻站点每 5 分钟抓一次，企业官网每 24 小时抓一次。  
10. 索引段发布后 CTR 降低，快速回滚到上个版本恢复。  
11. 用户搜“Python 教程”，同义词扩展召回“入门指南”类文档。  
12. 查询“今天美元汇率”时优先展示更近发布时间的权威来源。  

## 18. 面试追问 + 可复述回答
### Q1：为什么倒排索引适合搜索？
可复述：  
“因为用户输入的是词，倒排索引能直接从词定位文档集合，避免扫描全部文档，时间复杂度更可控。”

### Q2：召回和排序为什么要拆开？
可复述：  
“召回负责快，排序负责准。先用轻量方法缩小候选，再用复杂特征精排，才能同时满足时延和质量。”

### Q3：怎么做增量更新而不影响查询？
可复述：  
“新文档写入新 segment，验证通过后原子切换版本；查询读当前稳定版本，失败随时回滚旧版本。”

### Q4：如何处理热点查询导致过载？
可复述：  
“先命中 query/result cache，再限流异常流量，必要时降级排序复杂度，优先保障核心 SLA。”

### Q5：如何评估排序质量是否变好？
可复述：  
“离线看 NDCG/MRR，在线看 CTR、长点击和停留时长，必须 A/B 双验证。”

### Q6：抓取会不会把目标网站压垮？
可复述：  
“我们有 host 级 politeness 限速，遵守 robots，并在 429/503 时自动退避。”

## 19. 新手学习路线
### 第 1 周：做最小可用搜索
- 手写一个 mini 倒排索引（term -> docIds）。
- 实现基础查询 + TopK 返回。

### 第 2 周：补齐抓取与解析
- 写简单 crawler，处理 robots 和去重。
- 做正文抽取和 URL 归一。

### 第 3 周：补齐排序和缓存
- 实现 BM25。
- 加 query cache、result cache。
- 做分片并发查询。

### 第 4 周：工程化和面试化
- 实现 segment publish + rollback。
- 加监控告警和故障演练。
- 用“抓取-索引-查询-增量-容错”结构讲 10 分钟答案。

## 20. 上场前 Checklist
- [ ] 我能画出抓取、索引、查询三条主链路。  
- [ ] 我能解释为什么召回和排序要分层。  
- [ ] 我能说清增量索引发布和回滚机制。  
- [ ] 我能给出至少 3 个告警阈值（延迟、错误率、部分结果率）。  
- [ ] 我能说明热点查询时的止血策略。  
- [ ] 我能回答如何评估“排序变好”而不是只看主观感受。  
- [ ] 我能讲出 robots/politeness 的合规与工程意义。  

## 21. 30 秒总结
搜索引擎高分答案可以浓缩为一句话：  
“离线把互联网内容持续转成可检索索引，在线通过查询理解、召回、排序在毫秒级返回最相关结果，并用增量发布、缓存和降级策略保证新鲜度与稳定性。”  
面试时只要把这句话拆成链路、指标、阈值、故障与取舍，你就不是在背概念，而是在讲可落地系统。  
