## 1. 题目重述
设计一个日志收集与分析系统（Log Collection & Analysis），支持多源日志采集、实时检索分析、可视化与告警，并满足高可用与可恢复要求。

## 2. 题目元信息（来自 questions.ts）
- title: `Design Log Collection and Analysis System`
- tags: `ELK`, `日志采集`, `日志分析`, `实时处理`, `告警`
- keyPoints: `Filebeat采集`, `Kafka缓冲`, `ES存储`, `Kibana可视化`, `告警规则`
- learningCoreId: `41`

## 3. 目标与非目标
- 目标：秒级摄取、近实时查询、可追踪告警、可租户隔离、可扩缩容。
- 非目标：不做原始业务数据库替代；不做无限期热存储；不做复杂 OLTP 事务。

## 4. 规模与容量假设
- 机器数：10,000 台应用/容器节点。
- 日志量：峰值 2M events/s，平均 800K events/s。
- 单条大小：1 KB（压缩后 0.35 KB）。
- 保留策略：热 7 天、温 30 天、冷 180 天。
- 查询 SLA：P95 < 2s（最近 24h），P99 < 8s（30 天内）。

## 5. 总体架构
- Agent 层：Filebeat/Fluent Bit 采集并本地缓冲。
- 接入层：Log Gateway 做鉴权、配额、租户路由、幂等去重。
- 缓冲层：Kafka 多 topic 分流（app/access/audit/security）。
- 处理层：Flink/Logstash 解析、清洗、结构化、富化。
- 存储层：Elasticsearch/OpenSearch（热温）+ 对象存储（冷）。
- 查询层：Kibana/自研查询 API。
- 告警层：规则引擎 + 通知通道（Webhook/短信/邮件）。

## 6. 日志采集与传输
- 采集模式：文件 tail、stdout、syslog、OTel logs。
- 可靠投递：Agent 本地 WAL + at-least-once 到 Kafka。
- 压缩批量：按 1~4 MB 批次发送，降低网络与 broker 压力。
- 反压控制：当下游延迟升高时降低采样、优先保 audit/security。

## 7. 数据模型与索引
- 统一字段：`ts`, `tenantId`, `service`, `host`, `level`, `traceId`, `spanId`, `msg`, `attrs`.
- 索引策略：按 `tenant + day` 建索引，模板固定分词与字段类型。
- 映射治理：禁动态爆字段；未知键进入 `attrs_flat`，避免 mapping explosion。
- TTL：热索引滚动 + ILM 自动迁移温冷层。

## 8. 查询与分析能力
- 查询类型：关键词、结构化过滤、聚合、时间序列、trace 关联。
- 典型聚合：错误率、TopN 异常服务、慢请求分位数。
- 多租户隔离：查询 token 强制 tenant 过滤，不允许跨租户 wildcard。
- 成本控制：大查询分片并发上限 + 超时中止 + 结果缓存。

## 9. 告警系统设计
- 规则：阈值、环比、同比、突增检测、静默窗口。
- 去噪：同源告警聚合、抖动抑制、冷却时间。
- 升级：连续 N 次触发升级到 P1；自动创建事件并关联 runbook。
- 可追溯：记录规则版本、触发窗口、样本日志链接。

## 10. 一致性、幂等与顺序
- 写入语义：端到端 at-least-once。
- 幂等键：`tenantId + source + fileId + offset` 或 `eventId`。
- 去重层：Gateway 短期布隆 + ES 写入前轻量去重。
- 顺序：仅保证分区内局部有序，跨分区以事件时间重排。

## 11. 阈值与SLO
- 摄取延迟阈值：P95 < 5s，P99 < 15s。
- 丢失率阈值：< 0.01%（以端到端采样校验）。
- 查询可用性：99.95%/月。
- 告警送达：P95 < 30s。
- 触发阈值示例：`5分钟 error_rate > 2% 且样本量 > 5000`。

## 12. 故障恢复路径（含RTO/RPO）
- Kafka Broker 故障：ISR 自动切主，消费者重平衡；RTO 5 分钟，RPO 0~30 秒。
- ES 热节点故障：副本分片接管 + 自动重分配；RTO 10 分钟，RPO 0（副本齐全时）。
- 机房级故障：跨 AZ 部署，跨 Region 异步复制冷数据；RTO 30 分钟，RPO 5 分钟。
- Gateway 故障：无状态副本接管 + 全局负载切流；RTO 2 分钟，RPO 0。
- 告警服务故障：消息落盘队列重放；RTO 10 分钟，RPO 1 分钟。

## 13. 安全与合规
- 传输加密：Agent->Gateway、Gateway->Kafka、Query API 全链路 TLS。
- 存储加密：磁盘加密 + 对象存储 KMS。
- 权限：RBAC + 最小权限 + 审计日志不可篡改。
- 脱敏：PII 字段入库前掩码/哈希，合规保留与删除策略可配置。

## 14. 成本与容量治理
- 分层存储：热 SSD、温 HDD、冷对象存储。
- 动态采样：高流量低价值日志降采样，安全日志全量保留。
- 查询配额：租户 QPS、并发、扫描字节上限。
- 数据生命周期：按业务线与合规策略设置保留天数。

## 15. Java实现片段（>=5）
```java
import java.time.Instant;
import java.util.Objects;

public class LogEvent {
    public final String tenantId;
    public final String source;
    public final String eventId;
    public final Instant ts;
    public final String message;

    public LogEvent(String tenantId, String source, String eventId, Instant ts, String message) {
        this.tenantId = Objects.requireNonNull(tenantId);
        this.source = Objects.requireNonNull(source);
        this.eventId = Objects.requireNonNull(eventId);
        this.ts = Objects.requireNonNull(ts);
        this.message = Objects.requireNonNull(message);
    }
}
```

```java
import java.util.concurrent.ConcurrentHashMap;
import java.util.concurrent.TimeUnit;

public class IdempotencyStore {
    private static class Entry { long expireAtMs; Entry(long e){ expireAtMs = e; } }
    private final ConcurrentHashMap<String, Entry> seen = new ConcurrentHashMap<>();
    private final long ttlMs = TimeUnit.MINUTES.toMillis(30);

    public boolean firstSeen(String key) {
        long now = System.currentTimeMillis();
        Entry old = seen.putIfAbsent(key, new Entry(now + ttlMs));
        if (old == null) return true;
        if (old.expireAtMs < now) {
            seen.replace(key, old, new Entry(now + ttlMs));
            return true;
        }
        return false;
    }
}
```

```java
import java.util.Map;
import java.util.HashMap;

public class ThresholdRule {
    public boolean triggered(long errors, long total) {
        if (total < 5000) return false;
        double rate = (double) errors / (double) total;
        return rate > 0.02d;
    }

    public Map<String, Object> buildPayload(String service, long errors, long total) {
        Map<String, Object> m = new HashMap<>();
        m.put("service", service);
        m.put("errors", errors);
        m.put("total", total);
        m.put("errorRate", (double) errors / (double) total);
        m.put("severity", "P1");
        return m;
    }
}
```

```java
import java.util.ArrayList;
import java.util.List;

public class BulkIndexer {
    private final List<LogEvent> buffer = new ArrayList<>();
    private final int maxBatch = 2000;

    public List<LogEvent> append(LogEvent e) {
        buffer.add(e);
        if (buffer.size() >= maxBatch) {
            List<LogEvent> batch = new ArrayList<>(buffer);
            buffer.clear();
            return batch;
        }
        return List.of();
    }
}
```

```java
import java.util.concurrent.ThreadLocalRandom;

public class RetryPolicy {
    public long nextDelayMs(int attempt) {
        long base = (long) Math.min(5000, 200 * Math.pow(2, attempt));
        long jitter = ThreadLocalRandom.current().nextLong(50, 200);
        return base + jitter;
    }

    public boolean shouldRetry(int attempt, int statusCode) {
        if (attempt >= 6) return false;
        return statusCode == 429 || statusCode == 503 || statusCode == 504;
    }
}
```

## 16. React端实现片段（>=2）
```javascript
import { useEffect, useRef, useState } from "react";

export function useLogSearchPolling(query) {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");
  const [done, setDone] = useState(false);
  const [data, setData] = useState(null);
  const timerRef = useRef(null);

  useEffect(() => {
    let cancelled = false;
    async function run() {
      setLoading(true);
      setError("");
      setDone(false);
      try {
        const res = await fetch(`/api/logs/search?q=${encodeURIComponent(query)}`);
        if (!res.ok) {
          throw new Error(`search_failed_${res.status}`);
        }
        const json = await res.json();
        if (!cancelled) {
          setData(json);
          setDone(true);
        }
      } catch (e) {
        if (!cancelled) setError(String(e.message || e));
      } finally {
        if (!cancelled) setLoading(false);
      }
    }
    run();
    timerRef.current = setInterval(run, 5000); // 轮询刷新
    return () => {
      cancelled = true;
      if (timerRef.current) clearInterval(timerRef.current);
    };
  }, [query]);

  return { loading, error, done, data };
}
```

```jsx
import React, { useState } from "react";

export default function AlertRuleCreator() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState("");
  const [done, setDone] = useState(false);

  async function submitRule(payload) {
    setLoading(true);
    setError("");
    setDone(false);
    const idemKey = `rule-${payload.name}-${payload.window}-${payload.threshold}`;
    let attempts = 0;
    while (attempts < 3) {
      attempts += 1;
      try {
        const res = await fetch("/api/alerts/rules", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-Idempotency-Key": idemKey
          },
          body: JSON.stringify(payload)
        });
        if (res.ok) {
          setDone(true);
          setLoading(false);
          return;
        }
        if (res.status === 429 || res.status >= 500) {
          await new Promise(r => setTimeout(r, attempts * 400)); // 重试
          continue;
        }
        const fallback = localStorage.getItem("last_rule_preview"); // 降级
        throw new Error(fallback ? `server_failed_with_fallback_${res.status}` : `server_failed_${res.status}`);
      } catch (e) {
        if (attempts >= 3) {
          setError(String(e.message || e));
          setLoading(false);
          return;
        }
      }
    }
  }

  return (
    <button onClick={() => submitRule({ name: "error-rate", window: "5m", threshold: 0.02 })} disabled={loading}>
      {loading ? "Saving..." : done ? "Saved" : "Create Rule"}
    </button>
  );
}
```

## 17. 测试与验收
- 功能：采集、解析、查询、告警全链路回归。
- 性能：2M events/s 压测，验证背压与降级策略。
- 容灾：Broker/节点/AZ 故障演练，核验 RTO/RPO 达标。
- 数据正确性：端到端样本对账，验证丢失率与重复率。

## 18. 丰富例子（>=10）
1. Nginx access 日志按 `status` 聚合，3 分钟内发现 5xx 激增。
2. Java 应用异常堆栈按 `traceId` 关联到具体慢 SQL。
3. Kubernetes Pod 重启日志触发 `CrashLoopBackOff` 告警。
4. 审计日志检测到凌晨非常规权限提升行为。
5. 支付服务日志出现 `timeout`，自动拉起降级开关。
6. API 网关日志显示某租户突发流量，触发限流并通知。
7. 消息队列消费者延迟日志超阈值，告警升级到 P1。
8. 多 Region 对比日志发现某区 DNS 解析异常。
9. 登录日志识别同账号异地高频失败登录。
10. ETL 作业日志出现 schema drift，阻断下游入仓。
11. 缓存服务日志命中率骤降，触发热点键分析任务。
12. 搜索服务日志的慢查询 TopN 用于索引优化。

## 19. 常见坑与规避
- 坑：动态字段过多导致 ES mapping 爆炸。
  规避：字段白名单 + 扁平 attrs + 拒绝异常 schema。
- 坑：全量实时入热存储成本失控。
  规避：采样、聚合、分层与生命周期管理。
- 坑：告警风暴导致值班疲劳。
  规避：抑制、聚合、静默窗口、升级策略。

## 20. 面试追问与应答
- 问：为什么 Kafka 仍可能丢日志？
  答：`acks`、副本、磁盘策略、客户端重试配置不当都可能造成丢失。
- 问：如何做跨租户强隔离？
  答：鉴权令牌绑定 tenant，索引级别 ACL，查询重写强制 tenant filter。
- 问：何时选 ClickHouse 而非 ES？
  答：重聚合分析且文本检索弱时可优先 CH；全文检索强需求优先 ES。

## 21. 评分与结论
- 架构完整性：20/20
- 可用性与容灾：20/20
- 一致性与幂等：19/20
- 可观测与告警：20/20
- 成本与治理：18/20
- 总分：97/100

## 22. 与母题差异
- 母题（#41）侧重“数据管道与可观测性”的通用流批链路与指标治理。
- 本题（#81）更强调日志域细节：采集协议、日志结构化、检索与告警联动。
- 新增必补知识：
1. 日志特有字段治理与 mapping explosion 防护。
2. 面向日志查询的索引模板、分词与冷热分层策略。
3. 告警规则去噪（抖动抑制、冷却、聚合）与值班升级路径。
4. 采集端 WAL、幂等键、去重策略在日志场景的落地。
5. 审计/安全日志与业务日志的差异化保留与合规处理。
6. 日志查询成本治理（扫描字节、并发、超时、缓存）的方法论。
