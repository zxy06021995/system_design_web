# Q73：ETL Pipeline (ETL管道)

## 1. 题目元信息（强制对齐）
- title：ETL Pipeline (ETL管道)
- tags：ETL、数据清洗、任务调度、数据校验、血缘
- keyPoints：抽取策略、数据清洗规则、任务依赖编排、质量校验、元数据与血缘
- learningCoreId：72
- 总分：97/100

## 2. 题目目标
设计一条可扩展的 ETL 管道，完成多源抽取、清洗转换、装载入仓，并保证可观测、可回溯、可恢复。重点不是“能跑一次”，而是“长期稳定跑、出错可修、口径可追踪”。

## 3. 业务场景与边界
输入侧包含 OLTP 库、日志流、第三方 API；输出侧包含 DWD/DWS/ADS、BI 看板、下游数据服务。边界：不做跨地域强一致事务，采用最终一致+补偿回放。

## 4. 需求澄清
功能需求：多源抽取、规则清洗、依赖编排、质量校验、血缘记录、回放修复。  
非功能需求：高可用、低延迟、高正确性、可审计。  
不做范围：不在本题实现 BI 前端建模与复杂权限域治理。

## 5. 容量与SLO
- 日常：2000 万行/天，峰值 3 倍。
- 调度任务：2 万 DAG 节点/小时，峰值并发 2000。
- 数据延迟 SLO：T+5 分钟内可见率 >= 99.5%。
- 数据正确率 SLO：关键指标偏差 <= 0.1%。
- 可用性 SLO：月度 99.95%。

## 6. 架构总览
```text
Source DB/Logs/API
   -> Extractor(批/流)
   -> Staging(ODS)
   -> Transformer(规则/维表/去重)
   -> Validator(质量门禁)
   -> Loader(DWD/DWS/ADS)
   -> Metadata & Lineage
   -> Query/BI/Serving
```

## 7. 抽取策略设计
全量+增量组合：首次全量，后续 CDC/水位增量。  
防漏防重：`source_offset + batch_id + checksum` 三元组。  
抽取失败策略：先重试 3 次，失败入隔离区，触发人工与自动回放。

## 8. 数据清洗规则设计
规则分层：字段级、记录级、批次级。  
常见规则：空值补全、枚举归一、时间标准化、脏数据隔离。  
规则版本化：`rule_version` 与结果绑定，支持回滚与重算。

## 9. 任务依赖编排
DAG 编排，节点粒度为“数据集+分区+版本”。  
依赖类型：强依赖、软依赖、时间窗依赖。  
调度控制：优先级队列、并发配额、租户隔离，避免抢占雪崩。

## 10. 数据模型与血缘
- `etl_job(job_id, dag_id, status, retry_count, started_at, ended_at)`
- `etl_batch(batch_id, source, watermark, checksum, status)`
- `dq_result(batch_id, rule_id, pass_rate, bad_count, created_at)`
- `lineage_edge(from_dataset, to_dataset, transform_id, version)`
- `replay_task(task_id, scope, reason, status, operator)`

## 11. 一致性与幂等
批次幂等键：`source + partition + watermark + rule_version`。  
写入采用 UPSERT 或 MERGE，防止重复装载。  
跨组件通过 Outbox + 幂等消费实现最终一致。

## 12. 阈值与告警
- `extract_lag_minutes > 10` 持续 5 分钟 -> P1。
- `dq_pass_rate < 99.9%`（核心表）持续 2 个批次 -> P1。
- `scheduler_backlog > 5000` 持续 10 分钟 -> P1。
- `lineage_coverage < 98%` 持续 30 分钟 -> P2。
- `load_fail_rate > 0.5%` 持续 10 分钟 -> P1。

## 13. 故障恢复路径（含RTO/RPO）
目标：RTO <= 30 分钟，RPO <= 5 分钟。  
恢复路径：
1. 告警触发后 3 分钟内自动止血：冻结新批次、保留核心链路。
2. 5 分钟内定位故障域：抽取、转换、校验、装载四段分诊。
3. 10 分钟内执行恢复动作：重试/切换备用连接/降级规则集。
4. 20 分钟内启动差量回放：按 `watermark` 重放失败批次。
5. 30 分钟内完成服务恢复并输出对账报告；超时升级到人工应急。
数据保护策略：关键位点每 1 分钟落盘，保证 RPO 不超过 5 分钟。

## 14. 成本与取舍
低价值表采用批处理压缩资源，高价值核心表保留准实时链路。  
规则计算优先向量化/列式执行，减少 CPU 成本。  
血缘采集选择异步落库，降低主链路延迟。

## 15. Java 实现要点（>=5）
```java
public class IdempotencyKeyBuilder {
    public String build(String source, String partition, String watermark, String ruleVersion) {
        return source + "|" + partition + "|" + watermark + "|" + ruleVersion;
    }
}
```

```java
public class ExtractService {
    public ExtractResult extract(SourceClient client, String watermark) {
        List<Record> rows = client.fetchIncremental(watermark);
        if (rows.isEmpty()) {
            return ExtractResult.empty(watermark);
        }
        long checksum = rows.stream().mapToLong(Record::hash).sum();
        return ExtractResult.success(rows, checksum, watermark);
    }
}
```

```java
public class DqValidator {
    public DqReport validate(List<Record> records) {
        long total = records.size();
        long bad = records.stream().filter(r -> r.getUserId() <= 0 || r.getEventTime() == null).count();
        double passRate = total == 0 ? 1.0 : (double) (total - bad) / total;
        String level = passRate >= 0.999 ? "PASS" : "BLOCK";
        return new DqReport(total, bad, passRate, level);
    }
}
```

```java
public class DagScheduler {
    public List<JobNode> nextRunnable(List<JobNode> nodes, int quota) {
        return nodes.stream()
            .filter(JobNode::depsDone)
            .sorted(Comparator.comparingInt(JobNode::priority).reversed())
            .limit(quota)
            .toList();
    }
}
```

```java
public class ReplayService {
    public ReplayResult replayFailedBatches(List<String> batchIds) {
        int ok = 0;
        int fail = 0;
        for (String batchId : batchIds) {
            try {
                reload(batchId);
                ok++;
            } catch (Exception ex) {
                markReplayFailed(batchId, ex.getMessage());
                fail++;
            }
        }
        return new ReplayResult(ok, fail, ok + fail);
    }

    private void reload(String batchId) {
        // reload by persisted watermark and rule version snapshot
        BatchSnapshot snapshot = loadSnapshot(batchId);
        runPipeline(snapshot);
    }
}
```

## 16. React JavaScript 实现（>=2）
```javascript
import React, { useEffect, useRef, useState } from "react";

export function PipelineHealthPanel() {
  const [status, setStatus] = useState("loading"); // loading | done | error
  const [data, setData] = useState(null);
  const [error, setError] = useState("");
  const timerRef = useRef(null);

  useEffect(() => {
    const fetchHealth = async () => {
      setStatus("loading");
      try {
        const resp = await fetch("/api/etl/health");
        if (!resp.ok) {
          setStatus("error");
          setError("health api failed");
          return;
        }
        const body = await resp.json();
        setData(body);
        setStatus("done");
      } catch (e) {
        setStatus("error");
        setError(String(e));
      } finally {
        timerRef.current = setTimeout(fetchHealth, 5000); // polling
      }
    };
    fetchHealth();
    return () => timerRef.current && clearTimeout(timerRef.current);
  }, []);

  if (status === "loading") return <div>loading...</div>;
  if (status === "error") return <div>error: {error}</div>;
  return <div>done: lag={data.extractLagMinutes}m dq={data.dqPassRate}</div>;
}
```

```jsx
import React, { useState } from "react";

export function ReplayTrigger() {
  const [status, setStatus] = useState("done"); // loading | done | error
  const [error, setError] = useState("");
  const [message, setMessage] = useState("");

  const triggerReplay = async (batchId) => {
    const idempotencyKey = `${batchId}-manual-replay`; // idempotent
    setStatus("loading");
    setError("");
    setMessage("");

    for (let i = 0; i < 3; i++) {
      try {
        const resp = await fetch("/api/etl/replay", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "Idempotency-Key": idempotencyKey
          },
          body: JSON.stringify({ batchId })
        });
        if (resp.ok) {
          const body = await resp.json();
          setStatus("done");
          setMessage(`success: ${body.taskId}`);
          return;
        }
        if (i === 2) {
          setStatus("error");
          setError(`failed with status ${resp.status}`);
          return;
        }
      } catch (e) {
        if (i === 2) {
          setStatus("error");
          setError(String(e));
          return;
        }
      }
      await new Promise((r) => setTimeout(r, 500 * (i + 1))); // retry
    }
  };

  return (
    <div>
      <button onClick={() => triggerReplay("b_2026_02_24_001")}>replay</button>
      {status === "loading" && <p>loading...</p>}
      {status === "error" && <p>error: {error}</p>}
      {status === "done" && <p>done: {message || "idle"}</p>}
    </div>
  );
}
```

## 17. 测试与演练
单元测试：规则函数、幂等键、DAG 依赖判定。  
集成测试：抽取->转换->校验->装载全链路。  
混沌演练：源库超时、调度器崩溃、校验规则误配、消息重复。  
恢复演练：季度演练 RTO/RPO 达标并复盘。

## 18. 丰富例子（>=10）
1. 订单 CDC 重复到达，通过幂等键去重后仅落地一次。  
2. 用户生日字段格式混乱，清洗规则统一为 `yyyy-MM-dd`。  
3. 第三方 API 限流，抽取器自动降频并补齐水位。  
4. DQ 发现手机号缺失率突增，自动阻断 ADS 发布。  
5. DAG 上游延迟，软依赖任务先产出“带风险标记”快照。  
6. 维表晚到导致事实表关联缺失，夜间差量回放修复。  
7. 校验规则版本误发，30 分钟内回滚到上个稳定版本。  
8. 调度积压超过阈值，按租户优先级分配并发配额。  
9. 血缘缺边导致影响面不清，补建 lineage 后精确回溯。  
10. 装载目标库抖动，写入从实时切批量并开启重试。  
11. 跨天分区边界错位，通过 watermark 校正后重算。  
12. 运营手工触发回放，使用幂等键避免重复副作用。

## 19. 面试高频追问
为什么 ETL 不是只讲离线批任务：因为核心链路通常是批流一体，延迟和正确性都要保证。  
怎么控制数据污染：质量门禁+隔离区+回放修复，而不是直接放行。  
如何讲清闭环：告警阈值、责任人、止血动作、回放对账、复盘改进。

## 20. 一页话术
我会先给出四段链路（抽取、转换、校验、装载），再给出五个阈值和 P1 触发条件，最后用 RTO/RPO 的恢复路径证明方案可落地。若面试官深挖，我补充幂等键、规则版本化和回放策略。

## 21. Checklist
- 是否明确 `learningCoreId=72` 并说明母题关系。  
- 是否给出可量化阈值（不是“高/低”口头描述）。  
- 是否给出故障恢复路径与 RTO/RPO。  
- 是否说明幂等、重试、降级、回放如何协同。  
- 是否覆盖血缘与审计，保证可追溯。

## 22. 与母题差异
母题是 Q72（Data Warehouse），偏“仓模型与指标体系”；本题 Q73 偏“管道执行与运维恢复”。  
差异点：
1. 本题强调任务编排与运行态治理，母题强调模型设计与口径治理。  
2. 本题故障形态主要是抽取延迟、调度积压、校验阻断；母题更偏维度建模与指标一致性。  
3. 本题更依赖水位、批次、幂等键；母题更依赖维度层次与主题域划分。  
4. 本题要求明确 RTO/RPO 恢复剧本；母题通常先讲数仓分层和指标定义。  
5. 本题需要把血缘用于“故障影响面定位”，而不仅是“数据资产管理”。  

新增必补知识：
1. CDC/增量抽取中的水位与断点续传策略。  
2. 清洗规则版本化与回滚机制。  
3. DAG 强软依赖混合编排与并发配额控制。  
4. 数据质量门禁阈值设计与自动阻断策略。  
5. 回放修复的幂等保障与对账闭环。  
6. 血缘驱动的故障定位与影响半径分析。
