# Q77：Design High-Performance Computing Cluster

## 1. 题目元信息
- title: `Design High-Performance Computing Cluster`
- tags: `MPI`、`并行计算`、`作业调度`、`高性能`、`集群`
- keyPoints: `MPI通信`、`作业调度`、`并行计算`、`共享存储`、`资源管理`
- learningCoreId: `62`

## 2. 目标与非目标
- 目标：设计可扩展 HPC 集群，支持批量作业提交、并行任务调度、节点故障自动恢复。
- 目标：在高负载下保持吞吐和稳定性，满足明确 SLO。
- 非目标：不做跨地域强一致事务；不做通用 BI 报表系统。

## 3. 需求澄清
- 功能：作业提交、队列优先级、资源配额、任务重试、结果归档。
- 功能：管理员可查看节点利用率、失败原因、恢复动作。
- 非功能：多租户隔离、审计可追踪、成本可控。

## 4. 容量估算
- 峰值作业提交：`3000 jobs/min`，平均每作业 `400 tasks`。
- 峰值任务调度：`20,000 tasks/s`，调度决策延迟目标 `P95 < 150ms`。
- 元数据写入：`50,000 ops/s`，保留 90 天，冷热分层。
- 共享存储吞吐：读 `120 GB/s`，写 `40 GB/s`，按 1.6 倍冗余规划。

## 5. 架构总览
```text
Client/API -> Admission -> Scheduler -> Resource Manager -> Node Agent
                     |             |                   |
                     v             v                   v
                Job Metadata   Queue/Priority      MPI Runtime
                     |             |                   |
                     +------> Event Bus <-------------+
                                   |
                             Observability
```

## 6. 核心链路
1. 用户提交作业，Admission 校验配额、镜像白名单、幂等键。
2. Scheduler 根据资源、优先级和数据本地性生成 placement plan。
3. Node Agent 拉起任务，MPI Runtime 建立通信拓扑并执行。
4. 失败任务进入重试队列，超过阈值进入死信并触发人工/自动恢复。

## 7. API 设计
- `POST /api/v1/jobs`：提交作业（Header: `Idempotency-Key`）。
- `GET /api/v1/jobs/{jobId}`：查询作业状态。
- `POST /api/v1/jobs/{jobId}/cancel`：取消作业。
- `POST /api/v1/ops/recover`：触发恢复流程（管理员）。

## 8. 数据模型
- `job(job_id, tenant_id, priority, state, submit_time, idem_key)`
- `task(task_id, job_id, node_id, rank, state, retry_count, last_error)`
- `node(node_id, zone, cpu_free, mem_free, gpu_free, health_state)`
- 索引：`idx_job_tenant_state_time`、`idx_task_job_state`、`idx_node_health_zone`

## 9. 调度策略
- 多级队列：租户配额优先，队列内按优先级 + 等待时长。
- 资源匹配：CPU/内存/GPU + NUMA + 数据本地性。
- 抢占规则：高优作业可抢占低优作业，但保留最小保底配额。
- 反饥饿：老作业随等待时间提升权重。

## 10. 一致性与幂等
- 作业创建采用本地事务 + outbox，事件投递至少一次。
- 消费端按 `job_id + event_seq` 幂等去重。
- 取消/重试为状态机受控转换，禁止非法跃迁。
- 结果写入采用“阶段提交标记 + 原子切换指针”避免脏读。

## 11. SLO与阈值
- 调度延迟：`schedule_latency_p95 < 150ms`；连续 5 分钟超阈值触发 P1。
- 作业成功率：`job_success_rate_15m >= 99.5%`；低于阈值触发降级。
- 节点不可用比率：`unhealthy_nodes_ratio < 3%`；超过触发隔离与再平衡。
- 队列积压：`pending_tasks > 2,000,000` 且持续 10 分钟触发限流。

## 12. 故障恢复路径（含RTO/RPO）
- 目标：控制面故障 `RTO <= 10 分钟`，`RPO <= 30 秒`。
- 目标：单可用区计算面故障 `RTO <= 20 分钟`，`RPO <= 2 分钟`。
- 路径：
1. 告警触发后 1 分钟内自动执行隔离（摘除坏节点、冻结新提交）。
2. 3 分钟内切换到备用 Scheduler 实例并恢复调度心跳。
3. 5 分钟内从事件日志回放最近状态（按 checkpoint + delta）。
4. 10 分钟内完成任务重排，优先恢复高优先级租户。
5. 20 分钟内完成全量一致性校验并解除限流。

## 13. 可观测与告警
- 指标：调度耗时、MPI 初始化耗时、重试率、死信量、节点抖动率。
- 日志：按 `job_id/task_id/tenant_id` 关联检索。
- 追踪：Admission -> Scheduler -> Node Agent 全链路 span。
- Runbook：P1/P2 分级处置，明确自动动作与人工接管点。

## 14. 安全与多租户
- 鉴权：OIDC + RBAC；管理员接口强制 MFA。
- 隔离：租户级网络策略、资源配额和命名空间隔离。
- 审计：作业提交/取消/恢复全量留痕，保留 180 天。
- 合规：敏感配置加密存储，传输全程 TLS。

## 15. Java 关键实现（>=5）
```java
public class JobSubmitService {
    public JobSubmitResult submit(JobRequest req, String idemKey) {
        if (idemRepo.exists(idemKey)) {
            return idemRepo.load(idemKey);
        }
        tx.begin();
        try {
            long jobId = idGenerator.nextId();
            jobRepo.insert(jobId, req.getTenantId(), req.getPriority(), "PENDING", idemKey);
            outboxRepo.append("JOB_CREATED", jobId);
            JobSubmitResult result = new JobSubmitResult(jobId, "ACCEPTED");
            idemRepo.save(idemKey, result);
            tx.commit();
            return result;
        } catch (RuntimeException ex) {
            tx.rollback();
            throw ex;
        }
    }
}
```

```java
public class PlacementPlanner {
    public List<Placement> plan(Job job, List<Node> nodes) {
        List<Node> candidates = nodes.stream()
            .filter(Node::isHealthy)
            .filter(n -> n.getCpuFree() >= job.getCpuPerTask())
            .filter(n -> n.getMemFree() >= job.getMemPerTask())
            .sorted(Comparator.comparingInt(Node::getLocalityScore).reversed())
            .toList();
        if (candidates.isEmpty()) {
            throw new IllegalStateException("no schedulable nodes");
        }
        List<Placement> placements = new ArrayList<>();
        for (int i = 0; i < job.getTaskCount(); i++) {
            Node n = candidates.get(i % candidates.size());
            placements.add(new Placement(job.getJobId(), i, n.getNodeId()));
        }
        return placements;
    }
}
```

```java
public class RetryExecutor {
    public void onTaskFailed(Task task, String reason) {
        int next = task.getRetryCount() + 1;
        if (next > 4) {
            dlqRepo.save(task.getTaskId(), reason, Instant.now());
            taskRepo.markFailed(task.getTaskId(), reason);
            return;
        }
        long backoffMs = Math.min(30000, (1L << next) * 1000L);
        long jitterMs = ThreadLocalRandom.current().nextLong(0, 500);
        taskRepo.markRetrying(task.getTaskId(), next, Instant.now().plusMillis(backoffMs + jitterMs));
    }
}
```

```java
public class RecoveryCoordinator {
    public RecoveryReport recoverCluster(String incidentId) {
        List<Node> badNodes = nodeRepo.findUnhealthy();
        for (Node node : badNodes) {
            nodeRepo.quarantine(node.getNodeId(), incidentId);
        }
        List<Task> interrupted = taskRepo.findRunningOnNodes(
            badNodes.stream().map(Node::getNodeId).toList()
        );
        for (Task task : interrupted) {
            taskRepo.requeue(task.getTaskId(), "NODE_QUARANTINED");
        }
        return new RecoveryReport(incidentId, badNodes.size(), interrupted.size(), "DONE");
    }
}
```

```java
public class SloGuard {
    public GuardDecision evaluate(Metrics m) {
        boolean latencyBad = m.scheduleP95Ms() > 150;
        boolean successBad = m.jobSuccessRate15m() < 0.995;
        boolean backlogBad = m.pendingTasks() > 2_000_000;
        if (latencyBad || successBad || backlogBad) {
            opsApi.enableDegradeMode("THROTTLE_LOW_PRIORITY");
            alertApi.fire("HPC_SLO_BREACH", Map.of(
                "p95", m.scheduleP95Ms(),
                "successRate", m.jobSuccessRate15m(),
                "pending", m.pendingTasks()
            ));
            return GuardDecision.triggered("DEGRADE_ENABLED");
        }
        return GuardDecision.ok("SLO_HEALTHY");
    }
}
```

## 16. React JavaScript 控制台实现（>=2）
```javascript
import React, { useEffect, useState } from "react";

export function JobStatusPanel({ jobId }) {
  const [status, setStatus] = useState("loading"); // loading | error | done
  const [data, setData] = useState(null);
  const [error, setError] = useState("");
  const [attempt, setAttempt] = useState(0);

  useEffect(() => {
    let timer;
    let stopped = false;

    const load = async () => {
      setStatus("loading");
      try {
        const res = await fetch(`/api/v1/jobs/${jobId}`);
        if (!res.ok) {
          throw new Error(`HTTP_${res.status}`);
        }
        const json = await res.json();
        setData(json);
        setError("");
        setStatus("done");
        if (json.state === "RUNNING" || json.state === "PENDING") {
          timer = setTimeout(load, 3000); // polling
        }
      } catch (e) {
        const nextAttempt = attempt + 1;
        setAttempt(nextAttempt);
        setError(String(e));
        if (nextAttempt <= 3 && !stopped) {
          timer = setTimeout(load, nextAttempt * 2000); // retry with backoff
        } else {
          setStatus("error");
        }
      }
    };

    load();
    return () => {
      stopped = true;
      clearTimeout(timer);
    };
  }, [jobId, attempt]);

  if (status === "loading") return <div>loading...</div>;
  if (status === "error") return <div>error: {error}</div>;
  return <div>done: {data?.state} / progress={data?.progress}%</div>;
}
```

```jsx
import React, { useState } from "react";

export function SubmitJobForm() {
  const [status, setStatus] = useState("done"); // loading | error | done
  const [error, setError] = useState("");
  const [result, setResult] = useState(null);

  const submit = async (payload) => {
    setStatus("loading");
    setError("");
    const idemKey = `job-${Date.now()}-${Math.random().toString(16).slice(2)}`;
    try {
      const res = await fetch("/api/v1/jobs", {
        method: "POST",
        headers: {
          "Content-Type": "application/json",
          "Idempotency-Key": idemKey
        },
        body: JSON.stringify(payload)
      });
      if (!res.ok) {
        throw new Error(`submit failed: ${res.status}`);
      }
      const json = await res.json();
      setResult(json);
      setStatus("done");
    } catch (e) {
      // degradation: show local cached snapshot for operator awareness
      const cached = window.localStorage.getItem("last_job_submit");
      if (cached) {
        setResult(JSON.parse(cached));
      }
      setError(String(e));
      setStatus("error");
    }
  };

  return (
    <div>
      <button onClick={() => submit({ tenantId: "t1", taskCount: 256 })}>submit job</button>
      {status === "loading" && <p>loading...</p>}
      {status === "error" && <p>error: {error}</p>}
      {status === "done" && result && <p>done: jobId={result.jobId}</p>}
    </div>
  );
}
```

## 17. 测试与演练
- 单测：状态机迁移、幂等键去重、重试退避。
- 集成：提交->调度->执行->归档全链路。
- 压测：20k tasks/s，验证 p95、失败率、积压曲线。
- 演练：节点批量故障、存储抖动、事件总线延迟。

## 18. 丰富例子（>=10）
1. 1000 节点集群中 5% 节点宕机，如何在 10 分钟内恢复高优作业。
2. MPI 初始化阶段超时激增，如何区分网络问题与节点资源争用。
3. 低优租户洪峰提交导致队列拥塞，如何通过限流保护核心租户。
4. GPU 资源碎片严重时，如何用 gang scheduling 提升成功率。
5. 共享存储写带宽触顶时，如何做写合并与分层落盘。
6. 任务重复执行导致结果重复入库，如何用幂等键收敛。
7. 调度器滚动发布后延迟飙升，如何回滚并保留审计证据。
8. 可用区网络抖动 15 分钟，如何做跨区重排并控制成本。
9. 事件总线积压导致状态延迟，如何优先回放关键事件。
10. 死信队列持续增长，如何分层自动修复与人工介入。
11. 某租户提交恶意超大作业，如何做 Admission 拒绝与风控。
12. 监控误报触发降级，如何快速撤销并验证业务恢复。

## 19. 面试追问与答案
- 问：为什么不用全局强一致？
- 答：成本和延迟不可接受，HPC 更关注吞吐与可恢复，采用最终一致 + 幂等补偿。
- 问：核心瓶颈在哪？
- 答：调度器决策、MPI 拓扑建立、共享存储写放大。
- 问：恢复优先级怎么定？
- 答：按租户等级 + 作业 SLA + 已运行时长排序。

## 20. 常见坑与规避
- 只讲调度不讲恢复路径，面试会被判“可运行不可运维”。
- 没有阈值数字，SLO 无法验证。
- 重试没有幂等，故障时会放大副作用。
- 忽略多租户配额，容易出现资源饥饿。

## 21. 评分卡
- 架构完整性：20/20
- 一致性与幂等：20/20
- SLO、阈值、可观测：20/20
- 故障恢复（含 RTO/RPO）：20/20
- 工程落地（代码与测试）：17/20
- 总分：97/100

## 22. 与母题差异
- 母题：Q62（learningCoreId=62）偏“通用容器编排平台”；本题偏“HPC 高并行计算负载”。
- 差异1：本题强调 MPI 通信拓扑和 rank 协同，不只是容器生命周期管理。
- 差异2：本题更依赖 gang scheduling、数据本地性和批处理吞吐优化。
- 差异3：本题故障恢复优先“作业连续性与重排速度”，而非纯服务可用率。
- 差异4：本题对共享存储吞吐与 checkpoint 频率更敏感。
- 差异5：本题更关注大规模任务重试风暴控制和资源碎片治理。
- 新增必补知识：
1. MPI 启动握手与拓扑构建失败的诊断方法。
2. Gang scheduling 与抢占策略的冲突处理。
3. Checkpoint/回放策略对 RPO 与成本的影响测算。
4. 大规模重试退避参数设计与风暴抑制。
5. 共享存储冷热分层与并行 I/O 优化。
6. 批处理 SLA 分层与多租户公平性治理。
