# Q43：Design Distributed Job Scheduler（分布式任务调度器）- 95分面试版

## 1. 三句话题目本质
1. 调度系统本质是“在正确时间，把正确任务，可靠地交给正确执行器，并可追踪结果”。  
2. 真正难点不在 cron 解析，而在分布式场景下避免重复触发、避免漏触发、失败后可恢复。  
3. 面试高分关键：触发器、DAG 编排、幂等执行、重试补偿、死信处理、观测告警与多租户隔离要讲完整。  

## 2. 一个真实场景故事
你负责公司统一调度平台。凌晨 2:00 要跑每日账单任务链路：
- `A. 拉取支付流水`
- `B. 汇总分账`
- `C. 出账单并通知财务`

某天凌晨发生故障：
- A 在 2:01 成功。
- B 在 2:03 因数据库连接池耗尽失败。
- 系统自动重试 3 次后仍失败，C 未触发。

财务 8:00 上班发现账单没出，直接影响结算。  
这时你要回答：
1. 为什么失败没被提前报警？
2. 能不能安全补跑 B 和 C，且不重复执行 A？
3. 如何防止重试风暴把数据库压垮？

这就是调度系统设计题的核心价值：稳定性与可恢复性。

## 3. 术语白话表（至少 10 项）
| 术语 | 白话解释 | 面试可复述 |
|---|---|---|
| Cron Trigger | 定时触发器 | “按 cron 规则到点触发” |
| Event Trigger | 事件触发器 | “收到上游事件才触发” |
| Misfire | 错过触发时间 | “本该触发但因故障没触发” |
| DAG | 有向无环依赖图 | “任务有前后依赖，不能乱序” |
| Scheduler Leader | 调度主节点 | “只有主节点负责发号施令” |
| Dispatcher | 分发器 | “把待执行任务发给执行器” |
| Executor | 执行器 | “真正跑业务代码的节点” |
| Lease Lock | 租约锁 | “临时锁，防止双主调度” |
| Idempotency | 幂等 | “重复执行不会产生重复副作用” |
| Backoff | 退避重试 | “失败后别立刻狂重试，逐步拉长间隔” |
| DLQ | 死信队列 | “多次失败后先隔离，人工处理” |
| Backpressure | 背压 | “下游慢时，上游要主动降速” |
| Sharding | 分片调度 | “把任务按规则分到不同节点处理” |
| Heartbeat | 心跳 | “节点周期上报存活状态” |
| Runbook | 处置手册 | “故障发生时按步骤止血和恢复” |

## 4. 需求澄清（功能/非功能/不做范围）
### 4.1 功能需求
- 支持触发类型：Cron、一次性延时、事件触发、手动触发。
- 支持 DAG 依赖：父任务成功后触发子任务。
- 支持重试策略（次数、退避、超时、死信）。
- 支持暂停/恢复/补跑/回放某时间区间。
- 支持运行日志、状态查询、告警通知。
- 支持多租户隔离（租户配额、优先级、权限）。

### 4.2 非功能需求（SLO 示例）
- 触发延迟：`P95 <= 2s`。
- 任务分发延迟：`P95 <= 1s`。
- 平台可用性：`>= 99.95%`。
- 调度不重复率：`>= 99.999%`（关键任务）。
- 故障恢复时间（RTO）：`<= 5 分钟`。

### 4.3 Out of Scope（首版不做）
- 不做跨地域强一致双活（先单地域多可用区）。
- 不做复杂工作流脚本语言（先提供 DAG + 参数）。
- 不做毫秒级超高频交易调度（先秒级精度）。

## 5. 容量估算（含数字推导）
### 5.1 假设
- 任务定义总数：`3,000,000`
- 每分钟触发实例：平均 `400,000`，峰值 `1,200,000`
- 单实例平均执行时长：`45s`
- 并发运行实例峰值：`~900,000`

### 5.2 调度吞吐
- 峰值触发 TPS：`1,200,000 / 60 = 20,000/s`
- 若每次分发消息 1KB：分发带宽约 `20MB/s`（不含副本）

### 5.3 存储估算
- 每日任务运行记录：假设 `500,000,000 runs/day`
- 每条运行记录 600B -> `~300GB/day`
- 保留 30 天 -> `~9TB`（可冷热分层）

### 5.4 关键结论
- 触发器必须分片并行，不能单点扫描全库。
- 调度元数据与运行日志要分离存储，避免热点互相影响。
- 执行器池和队列都要支持弹性扩缩。

## 6. 架构（简版 + 完整版）
### 6.1 简版
```text
Scheduler API -> Metadata DB -> Trigger Engine -> Queue -> Executors -> Run Store
                                              -> Retry/DLQ -> Alerting
```

### 6.2 完整版
```text
[Control Plane]
  -> Job API Service
  -> DAG Validator
  -> Metadata DB (job_def, dag_edge, policy)
  -> Scheduler Leader Election (lease lock)
  -> Trigger Engine (cron wheel + misfire scan)
  -> Dispatcher (priority + quota)

[Data Plane]
  -> Message Queue (Kafka/Rabbit/Pulsar)
  -> Executor Pool
  -> Task Sandbox (runtime isolation)
  -> Result Reporter
  -> State Store (job_run, attempt, logs)
  -> Retry Worker + DLQ Worker

[Ops Plane]
  -> Metrics/Log/Trace
  -> Alert/Oncall
  -> Replay/Backfill Controller
  -> Web Console (create/pause/retry/view DAG)
```

### 6.3 关键职责
- Trigger Engine：负责“该触发谁”。
- Dispatcher：负责“该分给谁”。
- Executor：负责“如何安全执行”。
- State Store：负责“结果可追踪、可补救”。

## 7. API 设计（含请求/响应样例）
### 7.1 创建任务
`POST /api/v1/jobs`

Request:
```json
{
  "name": "daily_billing",
  "tenantId": "finance",
  "trigger": {
    "type": "CRON",
    "expr": "0 0 2 * * ?",
    "timezone": "Asia/Shanghai",
    "misfirePolicy": "FIRE_ONCE_NOW"
  },
  "retryPolicy": {
    "maxAttempts": 3,
    "backoff": "EXPONENTIAL",
    "baseDelaySec": 30
  },
  "timeoutSec": 600,
  "executorSelector": "billing_pool"
}
```

Response:
```json
{
  "jobId": 8800231,
  "status": "ENABLED"
}
```

### 7.2 创建 DAG 依赖
`POST /api/v1/jobs/dag`

Request:
```json
{
  "dagId": "billing_dag_v1",
  "nodes": [8800231, 8800232, 8800233],
  "edges": [
    {"from": 8800231, "to": 8800232},
    {"from": 8800232, "to": 8800233}
  ]
}
```

### 7.3 手动触发实例
`POST /api/v1/jobs/{jobId}/trigger`

Request:
```json
{
  "manualRunId": "manual_20260224_001",
  "params": {"bizDate": "2026-02-23"},
  "reason": "re-run after fix"
}
```

### 7.4 查询运行记录
`GET /api/v1/jobs/{jobId}/runs?page=1&pageSize=20`

### 7.5 补跑区间
`POST /api/v1/jobs/{jobId}/backfill`

Request:
```json
{
  "from": "2026-02-01T00:00:00Z",
  "to": "2026-02-07T00:00:00Z",
  "parallelism": 8
}
```

### 7.6 错误码语义
- `409_DAG_CYCLE_DETECTED`：DAG 有环，创建失败。
- `423_JOB_PAUSED`：任务被暂停，不能触发。
- `429_TENANT_QUOTA_EXCEEDED`：租户并发超配额。
- `503_DISPATCHER_OVERLOADED`：分发器过载，触发降级。

## 8. 数据模型（核心表/索引）
### 8.1 任务定义表
```sql
CREATE TABLE job_def (
  job_id BIGINT PRIMARY KEY,
  tenant_id VARCHAR(64) NOT NULL,
  name VARCHAR(128) NOT NULL,
  trigger_type VARCHAR(16) NOT NULL,     -- CRON/EVENT/DELAY
  trigger_expr VARCHAR(128),
  timezone VARCHAR(64) NOT NULL DEFAULT 'UTC',
  misfire_policy VARCHAR(32) NOT NULL,
  retry_policy JSON NOT NULL,
  timeout_sec INT NOT NULL,
  priority INT NOT NULL DEFAULT 100,
  executor_pool VARCHAR(64) NOT NULL,
  status VARCHAR(16) NOT NULL,           -- ENABLED/PAUSED/DELETED
  version BIGINT NOT NULL DEFAULT 0,
  created_at TIMESTAMP NOT NULL,
  updated_at TIMESTAMP NOT NULL
);
CREATE INDEX idx_job_tenant_status ON job_def(tenant_id, status);
```

### 8.2 DAG 边表
```sql
CREATE TABLE job_dag_edge (
  dag_id VARCHAR(64) NOT NULL,
  from_job_id BIGINT NOT NULL,
  to_job_id BIGINT NOT NULL,
  PRIMARY KEY(dag_id, from_job_id, to_job_id)
);
CREATE INDEX idx_dag_to ON job_dag_edge(dag_id, to_job_id);
```

### 8.3 运行实例表
```sql
CREATE TABLE job_run (
  run_id BIGINT PRIMARY KEY,
  job_id BIGINT NOT NULL,
  dag_id VARCHAR(64),
  logical_time TIMESTAMP NOT NULL,       -- 逻辑触发时间
  trigger_source VARCHAR(16) NOT NULL,   -- SCHEDULE/MANUAL/BACKFILL
  state VARCHAR(16) NOT NULL,            -- PENDING/RUNNING/SUCCESS/FAILED/CANCELED/TIMEOUT
  attempt_count INT NOT NULL DEFAULT 0,
  next_retry_at TIMESTAMP,
  worker_id VARCHAR(64),
  created_at TIMESTAMP NOT NULL,
  started_at TIMESTAMP,
  ended_at TIMESTAMP,
  UNIQUE(job_id, logical_time, trigger_source)
);
CREATE INDEX idx_run_state_retry ON job_run(state, next_retry_at);
CREATE INDEX idx_run_job_time ON job_run(job_id, created_at DESC);
```

### 8.4 执行尝试表
```sql
CREATE TABLE job_run_attempt (
  attempt_id BIGINT PRIMARY KEY,
  run_id BIGINT NOT NULL,
  attempt_no INT NOT NULL,
  state VARCHAR(16) NOT NULL, -- RUNNING/SUCCESS/FAILED/TIMEOUT
  error_code VARCHAR(64),
  error_message VARCHAR(1024),
  started_at TIMESTAMP NOT NULL,
  ended_at TIMESTAMP
);
CREATE UNIQUE INDEX uk_attempt_run_no ON job_run_attempt(run_id, attempt_no);
```

### 8.5 死信表
```sql
CREATE TABLE job_dead_letter (
  dlq_id BIGINT PRIMARY KEY,
  run_id BIGINT NOT NULL,
  job_id BIGINT NOT NULL,
  tenant_id VARCHAR(64) NOT NULL,
  fail_reason VARCHAR(1024) NOT NULL,
  moved_at TIMESTAMP NOT NULL
);
CREATE INDEX idx_dlq_tenant_time ON job_dead_letter(tenant_id, moved_at DESC);
```

## 9. 核心流程（至少 3 条）
### 9.1 正常 Cron 触发流程
1. Trigger Engine 按分片扫描“未来一分钟”即将触发任务。
2. 到点后创建 `job_run`（唯一键防重）。
3. Dispatcher 按优先级+租户配额投递到队列。
4. Executor 拉取任务，执行并回传结果。
5. 状态更新 `SUCCESS`，如果属于 DAG 节点则检查下游是否可触发。

### 9.2 高峰流程（批量补跑）
1. 运维发起 7 天补跑，瞬间产生大量 run。
2. 系统将补跑任务打低优先级，避免挤占实时任务。
3. 启用 tenant quota 和并发上限。
4. 若队列 lag 升高，触发背压和限流。

### 9.3 故障恢复流程（Executor 宕机）
1. Executor 心跳超时，运行中的 run 进入“疑似失联”。
2. Scheduler 扫描超时 run，按“幂等策略允许重派”进行再调度。
3. 若不可幂等任务，进入人工确认队列。
4. 重派成功后恢复 DAG 流转，失败进入 DLQ。

### 9.4 重试与补偿流程
1. 任务失败，记录 `attempt_no+1`。
2. 根据退避策略计算 `next_retry_at`。
3. 超过 `maxAttempts` 后转 DLQ。
4. 可定义补偿任务（如回滚中间状态）自动触发。

## 10. 一致性与事务边界
### 10.1 调度一致性边界
- “触发一次”在分布式下很难绝对做到，工程上追求“逻辑唯一 + 幂等执行”。
- 调度器保证“至少一次投递”，执行器必须具备幂等。

### 10.2 去重策略
- 逻辑唯一键：`job_id + logical_time + trigger_source`。
- run 创建使用 DB 唯一约束 + 重试幂等逻辑。

### 10.3 事务边界
- run 状态更新和消息投递建议 Outbox 模式，防止“库写成功消息丢失”。
- DAG 下游触发要基于“父节点成功状态已持久化”再进行。

### 10.4 面试可复述
“调度系统不强求全局 exactly-once，而是通过唯一键防重 + 幂等执行实现业务正确性。”

## 11. 可用性与容错
### 11.1 常见故障
- 双主调度导致重复触发。
- 队列积压导致触发延迟。
- 执行器雪崩导致重试风暴。
- 数据库压力大导致状态更新慢。

### 11.2 容错策略
- Leader 选举 + lease 锁避免双主。
- 分发器限流 + 背压 + 优先级队列。
- 重试预算（retry budget）限制总重试量。
- 写状态异步批量化，降低 DB 压力。

### 11.3 RTO / RPO
- RTO（调度主挂掉）：`<= 30s`。
- RPO（运行状态丢失）：`<= 1 min`（依赖持久化策略）。

## 12. 可观测性（指标 + 告警阈值）
### 12.1 调度指标
- `trigger_delay_ms_p95`
- `misfire_count`
- `schedule_qps`

阈值示例：
- `trigger_delay_ms_p95 > 2000` 持续 10 分钟 -> P1
- `misfire_count > baseline*3` 持续 5 分钟 -> P1

### 12.2 执行指标
- `run_success_rate`
- `run_timeout_rate`
- `executor_heartbeat_lost`

阈值示例：
- `run_success_rate < 97%` 持续 10 分钟 -> P1
- `run_timeout_rate > 5%` 持续 10 分钟 -> P1

### 12.3 队列与重试指标
- `dispatch_queue_lag`
- `retry_queue_depth`
- `dlq_growth_rate`

阈值示例：
- `dispatch_queue_lag > 1,000,000` -> P1
- `dlq_growth_rate > 500/min` 持续 5 分钟 -> P1

## 13. 安全与合规
- 多租户隔离：按租户分配并发配额与命名空间。
- 权限控制：创建/暂停/补跑/删除等动作细粒度 RBAC。
- 任务参数加密：敏感参数（Token/密钥）只存密文。
- 审计日志：谁在何时触发了什么补跑、修改了什么策略。
- 执行沙箱：限制任务 CPU、内存、网络访问范围。

## 14. 成本与取舍
### 14.1 成本构成
- 控制面数据库和队列成本。
- 执行器资源成本（CPU/内存）。
- 日志与运行历史存储成本。

### 14.2 核心取舍
- 触发精度越高，扫描和计算成本越高。
- 重试策略越激进，成功率可能升但容易放大故障。
- 运行日志保留越久，排障更方便但存储更贵。

### 14.3 降本策略
- 任务分级：核心任务高保障，普通任务低优先级。
- 历史 run 冷热分层存储。
- 低价值任务批量合并执行，减少调度开销。

## 15. 关键代码（Java 更细 + 前端功能代码）
### 15.1 Java：Cron 触发 + 防重创建 run
```java
public class TriggerEngine {
    private final JobRepository jobRepo;
    private final JobRunRepository runRepo;

    public void triggerDueJobs(Instant now) {
        List<JobDef> dueJobs = jobRepo.findCronDueJobs(now);
        for (JobDef job : dueJobs) {
            JobRun run = JobRun.of(job.getJobId(), now, "SCHEDULE");
            try {
                // UNIQUE(job_id, logical_time, trigger_source) 保证防重
                runRepo.insert(run);
            } catch (DuplicateKeyException ex) {
                // 已触发过，忽略即可
                continue;
            }
        }
    }
}
```

### 15.2 Java：DAG 校验（有环检测）
```java
public class DagValidator {
    public void validateNoCycle(List<Long> nodes, List<long[]> edges) {
        Map<Long, List<Long>> graph = new HashMap<>();
        Map<Long, Integer> indegree = new HashMap<>();
        for (Long n : nodes) {
            graph.put(n, new ArrayList<>());
            indegree.put(n, 0);
        }
        for (long[] e : edges) {
            long from = e[0], to = e[1];
            graph.get(from).add(to);
            indegree.put(to, indegree.get(to) + 1);
        }

        Deque<Long> q = new ArrayDeque<>();
        indegree.forEach((n, d) -> { if (d == 0) q.offer(n); });
        int visited = 0;
        while (!q.isEmpty()) {
            long cur = q.poll();
            visited++;
            for (long nxt : graph.get(cur)) {
                indegree.put(nxt, indegree.get(nxt) - 1);
                if (indegree.get(nxt) == 0) q.offer(nxt);
            }
        }

        if (visited != nodes.size()) {
            throw new IllegalArgumentException("DAG cycle detected");
        }
    }
}
```

### 15.3 Java：分发器（租户配额 + 优先级）
```java
public class DispatcherService {
    private final TenantQuotaService quotaService;
    private final QueueClient queueClient;

    public void dispatch(JobRun run, JobDef job) {
        if (!quotaService.tryAcquire(job.getTenantId())) {
            // 配额不足，延迟重试
            queueClient.delay("dispatch.retry", run.getRunId(), Duration.ofSeconds(5));
            return;
        }

        try {
            DispatchMessage msg = DispatchMessage.of(run.getRunId(), job.getExecutorPool(), job.getPriority());
            queueClient.publish("job.execute." + job.getExecutorPool(), msg);
        } finally {
            quotaService.release(job.getTenantId());
        }
    }
}
```

### 15.4 Java：执行器幂等 + 心跳上报
```java
public class ExecutorWorker {
    private final RunStateRepository runStateRepo;
    private final HeartbeatReporter heartbeatReporter;

    public void execute(DispatchMessage msg) {
        long runId = msg.getRunId();
        if (!runStateRepo.tryMarkRunning(runId)) {
            return; // 已被其他 worker 执行或状态不合法
        }

        heartbeatReporter.start(runId);
        try {
            TaskResult result = taskRunner.run(runId);
            runStateRepo.markSuccess(runId, result.summary());
        } catch (TimeoutException te) {
            runStateRepo.markTimeout(runId, te.getMessage());
        } catch (Exception e) {
            runStateRepo.markFailed(runId, e.getMessage());
        } finally {
            heartbeatReporter.stop(runId);
        }
    }
}
```

### 15.5 Java：重试与死信处理（指数退避 + 抖动）
```java
public class RetryAndDlqWorker {
    private static final int MAX_ATTEMPTS = 5;

    public void onRunFailed(JobRun run) {
        int nextAttempt = run.getAttemptCount() + 1;
        if (nextAttempt > MAX_ATTEMPTS) {
            dlqRepo.insert(run.getRunId(), run.getJobId(), run.getTenantId(), run.getLastError());
            runRepo.markDlq(run.getRunId());
            return;
        }

        long baseSec = (long) Math.pow(2, nextAttempt);
        long jitter = ThreadLocalRandom.current().nextLong(0, 3);
        Instant next = Instant.now().plusSeconds(baseSec + jitter);

        runRepo.scheduleRetry(run.getRunId(), nextAttempt, next);
        queueClient.delay("dispatch.retry", run.getRunId(), Duration.between(Instant.now(), next));
    }
}
```

### 15.6 Java：补跑控制器（时间区间生成 run）
```java
public class BackfillService {
    public BackfillResult createBackfillRuns(long jobId, Instant from, Instant to, Duration step) {
        long created = 0, skipped = 0;
        for (Instant t = from; !t.isAfter(to); t = t.plus(step)) {
            try {
                runRepo.insert(JobRun.of(jobId, t, "BACKFILL"));
                created++;
            } catch (DuplicateKeyException ex) {
                skipped++;
            }
        }
        return new BackfillResult(created, skipped);
    }
}
```

### 15.7 前端（React + TypeScript）：任务创建与验证页
```tsx
import { useState } from "react";

type CreateJobPayload = {
  name: string;
  tenantId: string;
  cronExpr: string;
  timeoutSec: number;
  maxAttempts: number;
};

export function JobCreateForm() {
  const [form, setForm] = useState<CreateJobPayload>({
    name: "",
    tenantId: "",
    cronExpr: "0 0/5 * * * ?",
    timeoutSec: 300,
    maxAttempts: 3
  });
  const [msg, setMsg] = useState("");

  const submit = async () => {
    if (!form.name || !form.tenantId) {
      setMsg("任务名和租户不能为空");
      return;
    }
    const body = {
      name: form.name,
      tenantId: form.tenantId,
      trigger: { type: "CRON", expr: form.cronExpr, timezone: "Asia/Shanghai", misfirePolicy: "FIRE_ONCE_NOW" },
      retryPolicy: { maxAttempts: form.maxAttempts, backoff: "EXPONENTIAL", baseDelaySec: 30 },
      timeoutSec: form.timeoutSec
    };
    const resp = await fetch("/api/v1/jobs", {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify(body)
    });
    setMsg(resp.ok ? "创建成功" : `创建失败: ${resp.status}`);
  };

  return (
    <div>
      <h3>创建调度任务</h3>
      <input placeholder="任务名" value={form.name} onChange={(e) => setForm({ ...form, name: e.target.value })} />
      <input placeholder="租户ID" value={form.tenantId} onChange={(e) => setForm({ ...form, tenantId: e.target.value })} />
      <input placeholder="Cron" value={form.cronExpr} onChange={(e) => setForm({ ...form, cronExpr: e.target.value })} />
      <input type="number" value={form.timeoutSec} onChange={(e) => setForm({ ...form, timeoutSec: Number(e.target.value) })} />
      <input type="number" value={form.maxAttempts} onChange={(e) => setForm({ ...form, maxAttempts: Number(e.target.value) })} />
      <button onClick={submit}>提交</button>
      {msg && <p>{msg}</p>}
    </div>
  );
}
```

### 15.8 前端（React + TypeScript）：运行记录与手动重试面板
```tsx
import { useEffect, useState } from "react";

type JobRun = {
  runId: number;
  state: string;
  logicalTime: string;
  attemptCount: number;
  lastError?: string;
};

export function JobRunTable({ jobId }: { jobId: number }) {
  const [runs, setRuns] = useState<JobRun[]>([]);

  const load = async () => {
    const resp = await fetch(`/api/v1/jobs/${jobId}/runs?page=1&pageSize=20`);
    if (!resp.ok) return;
    const data = await resp.json();
    setRuns(data.items || []);
  };

  useEffect(() => {
    load();
    const t = window.setInterval(load, 5000);
    return () => window.clearInterval(t);
  }, [jobId]);

  const retry = async (runId: number) => {
    await fetch(`/api/v1/jobs/${jobId}/trigger`, {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ manualRunId: `retry_${runId}`, reason: "manual retry from console" })
    });
    load();
  };

  return (
    <table>
      <thead>
        <tr>
          <th>runId</th>
          <th>state</th>
          <th>logicalTime</th>
          <th>attempt</th>
          <th>action</th>
        </tr>
      </thead>
      <tbody>
        {runs.map((r) => (
          <tr key={r.runId}>
            <td>{r.runId}</td>
            <td>{r.state}</td>
            <td>{r.logicalTime}</td>
            <td>{r.attemptCount}</td>
            <td>
              {r.state === "FAILED" ? <button onClick={() => retry(r.runId)}>重试</button> : "-"}
            </td>
          </tr>
        ))}
      </tbody>
    </table>
  );
}
```

## 16. 测试策略
### 16.1 单元测试
- Cron 解析边界（时区、闰秒、月末）。
- DAG 有环检测与拓扑排序正确性。
- 状态机迁移合法性（RUNNING -> SUCCESS/FAILED 等）。

### 16.2 集成测试
- 创建任务 -> 触发 -> 执行 -> 状态更新全链路。
- 重试 + 死信 + 手动补跑流程。
- 多租户配额冲突与优先级策略验证。

### 16.3 压测
- 峰值 2 万触发/s 压测 trigger 与 dispatch。
- 执行器水平扩容前后吞吐对比。
- 重试风暴模拟（下游 50% 失败率）。

### 16.4 故障注入
- 强杀 leader 验证切主时间。
- 队列延迟注入验证背压。
- 执行器网络隔离验证超时回收。

## 17. 丰富例子（至少 10 个）
1. 每天 2 点账单任务链路 A->B->C，B 失败后 C 不触发。  
2. 同一任务重复触发请求，唯一键拦截避免重复 run。  
3. 某任务 3 次失败后进入 DLQ，早上人工修复后手动重试。  
4. 大促期间补跑历史任务，低优先级避免影响实时任务。  
5. 运营临时暂停某租户任务，问题修复后恢复。  
6. 执行器宕机导致运行中任务失联，超时后自动重派。  
7. 下游数据库慢，退避重试避免瞬间打爆连接池。  
8. 错配 cron 表达式导致高频触发，平台配额限流止血。  
9. DAG 配置错误出现环依赖，创建阶段直接拒绝。  
10. 新版本执行器灰度发布，先放 5% 任务验证稳定性。  
11. misfire 策略设置为“立刻补触发一次”，避免漏跑日报。  
12. 定时任务参数含密钥，控制台展示脱敏值防泄漏。  

## 18. 面试追问 + 可复述回答
### Q1：如何避免任务重复执行？
可复述：  
“调度层用逻辑唯一键防重复触发，执行层做幂等校验。两层一起做才稳。”

### Q2：DAG 为什么必须无环？
可复述：  
“有环就会出现永远等待或无限触发，创建时必须做拓扑校验并阻断。”

### Q3：重试风暴怎么治理？
可复述：  
“指数退避 + 抖动 + 重试预算 + 下游熔断，避免失败任务集中重试把系统压垮。”

### Q4：Scheduler leader 挂了怎么办？
可复述：  
“通过 lease 选举快速切主，触发器恢复后根据 misfire 策略补触发，保证核心任务不漏。”

### Q5：如何处理不可幂等任务？
可复述：  
“标记为人工确认类型，不自动重派；或者把业务改造成可幂等再纳入自动重试。”

### Q6：怎么讲清调度系统的价值？
可复述：  
“它让业务任务从‘靠人盯’变成‘平台化可靠执行’，故障可预警可修复，极大降低运营风险。”

## 19. 新手学习路线
### 第 1 周：最小调度器
- 先做 cron 触发 + 简单队列 + 执行器。
- 跑通任务创建、触发、状态查询。

### 第 2 周：可靠性
- 增加重试、超时、死信。
- 增加幂等键与唯一约束。

### 第 3 周：DAG 与多租户
- 实现 DAG 依赖和有环检测。
- 实现租户配额和优先级。

### 第 4 周：运维与观测
- 做告警阈值、故障演练、Runbook。
- 增加前端控制台（创建任务、查看 run、手动重试）。

## 20. 上场前 Checklist
- [ ] 我能讲清触发器、分发器、执行器三层职责。  
- [ ] 我能解释“防重复触发 + 幂等执行”双保险。  
- [ ] 我能说清 DAG 校验与下游触发条件。  
- [ ] 我能给出至少 3 个告警阈值。  
- [ ] 我能描述故障切主和 misfire 补偿策略。  
- [ ] 我能解释重试风暴治理方案。  
- [ ] 我能讲一个完整补跑案例（触发、回放、验收）。  
- [ ] 我能展示前端控制台如何做手动重试和状态追踪。  

## 21. 30 秒总结
分布式任务调度器的高分表达是：  
“用可靠触发保证不漏，用唯一键和幂等保证不重，用重试补偿和死信保证失败可恢复，再用观测告警和前端控制台让系统可运营。”  
只要你把这句话落到具体数据模型、阈值、流程和代码，面试官会认为你有真实平台化经验。  
